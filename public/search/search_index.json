{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"index.html","text":"Documentation for Partisia Blockchain Mainnet Beta Start with the basics Introduction - Learn the blockchain fundamentals Create an account on Partisia Blockchain (PBC) Getting started as a Node Operator What is a Node Operator? Run a node on PBC Getting started as a developer What is a Smart Contract Download SDK for contract development Programmer's Guide to PBC smart contract SDK ABI specification (latest) Create a Smart Contract for a specific scenario Zero Knowledge Contracts Connect a dApp to the wallet extension (dApp SDK)","title":"Home"},{"location":"index.html#documentation-for-partisia-blockchain-mainnet-beta","text":"","title":"Documentation for Partisia Blockchain Mainnet Beta"},{"location":"index.html#start-with-the-basics","text":"Introduction - Learn the blockchain fundamentals Create an account on Partisia Blockchain (PBC)","title":"Start with the basics"},{"location":"index.html#getting-started-as-a-node-operator","text":"What is a Node Operator? Run a node on PBC","title":"Getting started as a Node Operator"},{"location":"index.html#getting-started-as-a-developer","text":"What is a Smart Contract Download SDK for contract development Programmer's Guide to PBC smart contract SDK ABI specification (latest) Create a Smart Contract for a specific scenario Zero Knowledge Contracts Connect a dApp to the wallet extension (dApp SDK)","title":"Getting started as a developer"},{"location":"abiv3_1.html","text":"Partisia Blockchain Smart Contract Binary Formats A Partisia Smart Contract utilizes three distinct binary formats, which are described in detail below. RPC Format : When an action of the smart function is invoked, the payload is sent to the action as binary data. The payload identifies which action is invoked and the values for all parameters to the action. State Format : The state of a smart contract is stored as binary data in the blockchain state. The state holds the value of all smart contract state variables. ABI Format : Meta-information about the smart contract is also stored as binary data, The ABI holds the list of available actions and their parameters and information about the different state variables. ABI Version changes Version 2.0 to 3.1 : Shortnames are now encoded as LEB128; ShortnameLength field have been removed. Added explicit, easily extensible return result format. RPC Binary Format The RPC payload identifies which action is invoked and the values for all parameters of the action. To decode the payload binary format you have to know which argument types each action expects, since the format of the argument values depends on the argument type. The ABI Format holds exactly the meta-data needed for finding types of the arguments for each action. The RPC payload contains the short name identifying the action being called followed by each of the arguments for the action. \\[ \\definecolor{mathcolor}{RGB}{33,33,33} \\definecolor{mathgray}{RGB}{100,100,100} \\newcommand{\\Rightarrowx}{{\\color{mathgray} \\ \\Rightarrow \\ \\ }} \\newcommand{\\hexi}[1]{{\\color{mathcolor}\\mathtt{0x}}{\\color{mathgray}}{\\color{mathcolor}\\mathtt{#1}}} \\newcommand{\\nnhexi}[1]{{\\color{mathcolor}\\mathtt{0x}}{\\color{mathgray}}{\\color{mathcolor} #1}} \\newcommand{\\repeat}[2]{#1\\text{*}#2} \\newcommand{\\byte}{\\nnhexi{nn}} \\newcommand{\\bytes}[1]{\\repeat{\\byte{}}{\\text{#1}}} \\] \\[ \\textcolor{mathcolor}{ \\begin{align*} \\text{<PayloadRpc>} \\ := \\ & \\text{action:}\\text{ShortName}\\ \\text{arguments:}\\text{ArgumentRpc}\\text{*} \\Rightarrowx \\text{action(arguments)} \\\\ \\end{align*} } \\] The short name of an action is an u32 integer identifier that uniquely identifies the action within the smart contract. The short name is encoded as unsigned LEB128 format , which means that short names have variable lengths. It is easy to determine how many bytes a LEB128 encoded number contains by examining bit 7 of each byte. \\[ \\textcolor{mathcolor}{ \\begin{align*} \\text{<ShortName>} \\ := \\ & \\text{pre:}\\nnhexi{nn}\\text{*}\\ \\text{last:}\\nnhexi{nn}\\ \\Rightarrowx \\text{Action} &\\text{(where pre is 0-4 bytes that are \u22650x80 and last<0x80)} \\\\ \\end{align*} } \\] The argument binary format depends on the type of the argument. The argument types for each action is defined by the contract, and can be read from the ABI format. \\[ \\textcolor{mathcolor}{ \\begin{align*} \\text{<ArgumentRpc>} \\ := \\ & \\byte{} \\ \\Rightarrowx \\text{u8/i8} & \\text{(i8 is twos complement)} \\\\ | \\ & \\bytes{2} \\ \\Rightarrowx \\text{u16/i16} & \\text{(big endian, i16 is two's complement)} \\\\ | \\ & \\bytes{4} \\ \\Rightarrowx \\text{u32/i32} & \\text{(big endian, i32 is two's complement)} \\\\ | \\ & \\bytes{8} \\ \\Rightarrowx \\text{u64/i64} & \\text{(big endian, i64 is two's complement)} \\\\ | \\ & \\bytes{16} \\ \\Rightarrowx \\text{u128/i128} & \\text{(big endian, i128 is two's complement)} \\\\ | \\ & \\text{b:}\\byte{} \\ \\Rightarrowx \\text{bool} & \\text{(false if b==0, true otherwise)} \\\\ | \\ & \\bytes{21} \\ \\Rightarrowx \\text{Address} \\\\ | \\ & \\bytes{len} \\ \\Rightarrowx \\text{Array }\\text{[u8;len]} & \\text{(containing the len u8 values)} \\\\ | \\ & \\text{len:}\\text{LengthRpc} \\ \\text{utf8:}\\bytes{len} \\ \\Rightarrowx \\text{String} & \\text{(with len UTF-8 encoded bytes)} \\\\ | \\ & \\text{len:}\\text{LengthRpc} \\ \\text{elems:}\\repeat{\\text{ArgumentRpc}}{\\text{len}} \\ \\Rightarrowx \\text{Vec<>} & \\text{(containing the len elements)} \\\\ | \\ & \\text{b:}\\byte{} \\ \\text{arg:}\\text{ArgumentRpc} \\ \\Rightarrowx \\text{Option<>} & \\text{(None if b==0, Some(arg) otherwise)} \\\\ \\end{align*} } \\] Only arrays of lengths between (including) 0 and 127 are supported. The high bit in length is reserved for later extensions. For arguments with variable lengths, such as Vecs or Strings the number of elements is represented as a big endian 32-bit unsigned integer. \\[ \\textcolor{mathcolor}{ \\begin{align*} \\text{<LengthRpc>} \\ := \\ & \\bytes{4} \\ \\Rightarrowx \\text{u32} \\text{( big endian)} \\\\ \\end{align*} } \\] State Binary Format Integers are stored as little-endian. Signed integers are stored as two's complement. Note that lengths are also stored as little-endian. \\[ \\textcolor{mathcolor}{ \\begin{align*} \\text{<State>} \\ := \\ & \\nnhexi{nn} \\ \\Rightarrowx \\text{u8/i8} & \\text{(i8 is twos complement)} \\\\ | \\ & \\bytes{2} \\ \\Rightarrowx \\text{u16/i16} & \\text{(little endian, i16 is two's complement)} \\\\ | \\ & \\bytes{4} \\ \\Rightarrowx \\text{u32/i32} & \\text{(little endian, i32 is two's complement)} \\\\ | \\ & \\bytes{8} \\ \\Rightarrowx \\text{u64/i64} & \\text{(little endian, i64 is two's complement)} \\\\ | \\ & \\bytes{16} \\ \\Rightarrowx \\text{u128/i128} & \\text{(little endian, i128 is two's complement)} \\\\ | \\ & \\text{b:}\\byte{} \\ \\Rightarrowx \\text{bool} & \\text{(false if b==0, true otherwise)} \\\\ | \\ & \\bytes{21} \\ \\Rightarrowx \\text{Address} \\\\ | \\ & \\bytes{len} \\ \\Rightarrowx \\text{Array }\\text{[u8;len]} & \\text{(containing the len u8 values)} \\\\ | \\ & \\text{len:}\\text{LengthState} \\ \\text{utf8:}\\bytes{len} \\ \\Rightarrowx \\text{String} & \\text{(with len UTF-8 encoded bytes)} \\\\ | \\ & \\text{len:}\\text{LengthState} \\ \\text{elems:}\\repeat{\\text{State}}{\\text{len}} \\ \\Rightarrowx \\text{Vec<>} & \\text{(containing the len elements)} \\\\ | \\ & \\text{b:}\\byte{} \\ \\text{arg:}\\text{State} \\ \\Rightarrowx \\text{Option<>} & \\text{(None if b==0, Some(arg) otherwise)} \\\\ | \\ & f_1 \\text{:State} \\dots f_n \\text{:State} \\Rightarrowx \\text{Struct S}\\ \\{ f_1, f_2, \\dots, f_n \\} & \\\\ \\end{align*} } \\] Only arrays of lengths between (including) 0 and 127 are supported. The high bit in length is reserved for later extensions. For arguments with variable lengths, such as Vecs or Strings the number of elements is represented as a little endian 32-bit unsigned integer. \\[ \\textcolor{mathcolor}{ \\begin{align*} \\text{<LengthState>} \\ := \\ & \\bytes{4} \\ \\Rightarrowx \\text{u32} \\text{(little endian)} \\\\ \\end{align*} } \\] CopySerializable A state type is said to be CopySerializable, if it's serialization is identical to it's in-memory representation, and thus require minimal serialization overhead. PBC have efficient handling for types that are CopySerializable. Internal pointers are the main reason that types are not CopySerializable. \\[ \\textcolor{mathcolor}{ \\begin{align*} \\text{<CopySerializable>} \\ := \\ & \\text{uXXX} \\Rightarrowx \\text{true}\\\\ | \\ & \\text{iXXX} \\Rightarrowx \\text{true}\\\\ | \\ & \\text{bool} \\Rightarrowx \\text{true}\\\\ | \\ & \\text{Address} \\Rightarrowx \\text{true}\\\\ | \\ & \\text{[u8;N]} \\Rightarrowx \\text{true}\\\\ | \\ & \\text{String} \\Rightarrowx \\text{false}\\\\ | \\ & \\text{Vec<T>} \\Rightarrowx \\text{false}\\\\ | \\ & \\text{Option<T>} \\Rightarrowx \\text{false}\\\\ | \\ & \\text{BTreeMap<K, V>} \\Rightarrowx \\text{false}\\\\ | \\ & \\text{BTreeSet<T>} \\Rightarrowx \\text{false}\\\\ | \\ & \\text{Struct S}\\ \\{ f_1: T_1, \\dots, f_n: T_n \\} \\Rightarrowx \\text{CopySerializable}(T_1) \\wedge \\dots \\wedge \\text{CopySerializable}(T_n) \\wedge \\text{WellAligned(S)} \\\\ \\end{align*} } \\] The WellAligned constraint on Struct CopySerializable is to guarentee that struct layouts are identical to serialization. \\(\\text{Struct S}\\ \\{ f_1: T_1, \\dots, f_n: T_n \\}\\) is WellAligned if following points hold: Annotated with #[repr(C)] . Read the Rust Specification for details on this representation. No padding: \\(\\text{size_of}(S) = \\text{size_of}(T_1) + ... + \\text{size_of}(T_n)\\) No wasted bytes when stored in array: \\(\\text{size_of}(S) \\mod \\text{align_of}(T_n) = 0\\) It may be desirable to manually add \"padding\" fields structs in order to achieve CopySerializable. While this will use extra unneeded bytes for the serialized state, it may significantly improve serialization speed and lower gas costs. A future version of the SDK may automatically add padding fields. Examples These structs are CopySerializable: Struct E1 { /* empty */ } Struct E2 { f1: u32 } Struct E3 { f1: u32, f2: u32 } These structs are not CopySerializable: Struct E4 { f1: u8, f2: u16 } due to padding between f1 and f2. Struct E5 { f1: u16, f2: u8 } due to alignment not dividing size. Struct E6 { f1: Vec<u8> } due to non-CopySerializable subfield. ABI Binary Format Type Specifier binary format \\[ \\textcolor{mathcolor}{ \\begin{align*} \\text{<TypeSpec>} \\ := \\ &\\text{SimpleTypeSpec} \\\\ | \\ &\\text{CompositeTypeSpec} \\\\ | \\ &\\text{StructTypeSpec} \\\\ \\\\ \\text{<StructTypeSpec>} \\ := \\ &\\hexi{00} \\ \\text{Index}:\\nnhexi{nn} \\Rightarrowx StructTypes(\\text{Index}) \\\\ \\\\ \\text{<SimpleTypeSpec>} \\ := \\ &\\hexi{01} \\ \\Rightarrowx \\text{u8} \\\\ | \\ &\\hexi{02} \\ \\Rightarrowx \\text{u16} \\\\ | \\ &\\hexi{03} \\ \\Rightarrowx \\text{u32} \\\\ | \\ &\\hexi{04} \\ \\Rightarrowx \\text{u64} \\\\ | \\ &\\hexi{05} \\ \\Rightarrowx \\text{u128} \\\\ | \\ &\\hexi{06} \\ \\Rightarrowx \\text{i8} \\\\ | \\ &\\hexi{07} \\ \\Rightarrowx \\text{i16} \\\\ | \\ &\\hexi{08} \\ \\Rightarrowx \\text{i32} \\\\ | \\ &\\hexi{09} \\ \\Rightarrowx \\text{i64} \\\\ | \\ &\\hexi{0a} \\ \\Rightarrowx \\text{i128} \\\\ | \\ &\\hexi{0b} \\ \\Rightarrowx \\text{String} \\\\ | \\ &\\hexi{0c} \\ \\Rightarrowx \\text{bool} \\\\ | \\ &\\hexi{0d} \\ \\Rightarrowx \\text{Address} \\\\ \\\\ \\text{<CompositeTypeSpec>} \\ := \\ &\\hexi{0e} \\text{ T:}\\text{TypeSpec} \\Rightarrowx \\text{Vec<}\\text{T>} \\\\ | \\ &\\hexi{0f} \\text{ K:}\\text{TypeSpec}\\text{ V:}\\text{TypeSpec} \\Rightarrowx \\text{Map <}\\text{K}, \\text{V>} \\\\ | \\ &\\hexi{10} \\text{ T:}\\text{TypeSpec} \\Rightarrowx \\text{Set<}\\text{T>} \\\\ | \\ &\\hexi{11} \\text{ L:}\\nnhexi{nn} \\Rightarrowx \\text{[u8; }\\text{L}\\text{]} & (\\hexi{00} \\leq L \\leq \\hexi{7F}) \\\\ | \\ &\\hexi{12} \\text{ T:}\\text{TypeSpec} \\Rightarrowx \\text{Option<}\\text{T>} \\\\ \\\\ \\end{align*} } \\] NOTE: Map and Set cannot be used as RPC arguments since it's not possible for a caller to check equality and sort order of the elements without running the code. Only arrays of lengths between (including) 0 and 127 are supported. The high bit in length is reserved for later extensions. ABI File binary format All Identifier names must be valid Rust identifiers ; other strings are reserved for future extensions. \\[ \\textcolor{mathcolor}{ \\begin{align*} \\text{<FileAbi>} \\ := \\ \\{ \\ &\\text{Header: } \\bytes{6}, \\text{The header is always \"PBCABI\" in ASCII}\\\\ &\\text{VersionBinder: } \\bytes{3} \\ \\\\ &\\text{VersionClient: } \\bytes{3} \\ \\\\ &\\text{Contract: ContractAbi} \\ \\} \\\\ \\\\ \\text{<ContractAbi>} \\ := \\ \\{ \\ &\\text{StructTypes: List<StructTypeAbi>}, \\\\ &\\text{Init: FnAbi}, \\\\ &\\text{Actions: List<FnAbi>}, \\\\ &\\text{StateType: TypeSpec} \\ \\} \\\\ \\text{<StructTypeAbi>} \\ := \\ \\{ \\ &\\text{Name: Identifier}, \\\\ &\\text{Fields: List<FieldAbi>} \\ \\} \\\\ \\\\ \\text{<FnAbi>} \\ := \\ \\{ \\ &\\text{Name: Identifier}, \\\\ &\\text{Shortname: LEB128}, \\\\ &\\text{Arguments: List<ArgumentAbi>} \\ \\} \\\\ \\\\ \\text{<FieldAbi>} \\ := \\ \\{ \\ &\\text{Name: Identifier}, \\\\ &\\text{Type: TypeSpec} \\ \\} \\\\ \\\\ \\text{<ArgumentAbi>} \\ := \\ \\{ \\ &\\text{Name: Identifier}, \\\\ &\\text{Type: TypeSpec} \\ \\} \\\\ \\\\ \\text{<Identifier>} \\ := \\ \\phantom{\\{} \\ &\\text{len:}\\bytes{4} \\ \\text{utf8:}\\bytes{len} \\text{ utf8 must be Rust identifier, len is big endian} \\\\ \\\\ \\text{<LEB128>} \\ := \\ \\phantom{\\{} \\ &\\text{A LEB128 encoded unsigned 32 bit integer (1-5 bytes).} \\\\ \\end{align*} } \\] Wasm contract result format The format used by Wasm contracts to return results is a section-based format defined as following: \\[ \\textcolor{mathcolor}{ \\begin{align*} \\text{<Result>} \\ := \\ & \\text{section}_0\\text{: Section} \\ \\dots \\ \\text{section}_n\\text{: Section} \\\\ \\text{<Section >} \\ := \\ & \\text{id:}\\byte{} \\ \\text{len:}\\bytes{4} \\ \\text{data:}\\bytes{len} \\ \\text{(len is big endian)} \\\\ \\end{align*} } \\] Note that section must occur in order of increasing ids. Two ids are \"well-known\" and specially handled by the interpreter: 0x01 : Stores event information. 0x02 : Stores state. Section ids 0x00 to 0x0F are reserved for \"well-known\" usage. All others are passed through the interpreter without modification.","title":"ABI 3.1 specification"},{"location":"abiv3_1.html#partisia-blockchain-smart-contract-binary-formats","text":"A Partisia Smart Contract utilizes three distinct binary formats, which are described in detail below. RPC Format : When an action of the smart function is invoked, the payload is sent to the action as binary data. The payload identifies which action is invoked and the values for all parameters to the action. State Format : The state of a smart contract is stored as binary data in the blockchain state. The state holds the value of all smart contract state variables. ABI Format : Meta-information about the smart contract is also stored as binary data, The ABI holds the list of available actions and their parameters and information about the different state variables.","title":"Partisia Blockchain Smart Contract Binary Formats"},{"location":"abiv3_1.html#abi-version-changes","text":"Version 2.0 to 3.1 : Shortnames are now encoded as LEB128; ShortnameLength field have been removed. Added explicit, easily extensible return result format.","title":"ABI Version changes"},{"location":"abiv3_1.html#rpc-binary-format","text":"The RPC payload identifies which action is invoked and the values for all parameters of the action. To decode the payload binary format you have to know which argument types each action expects, since the format of the argument values depends on the argument type. The ABI Format holds exactly the meta-data needed for finding types of the arguments for each action. The RPC payload contains the short name identifying the action being called followed by each of the arguments for the action. \\[ \\definecolor{mathcolor}{RGB}{33,33,33} \\definecolor{mathgray}{RGB}{100,100,100} \\newcommand{\\Rightarrowx}{{\\color{mathgray} \\ \\Rightarrow \\ \\ }} \\newcommand{\\hexi}[1]{{\\color{mathcolor}\\mathtt{0x}}{\\color{mathgray}}{\\color{mathcolor}\\mathtt{#1}}} \\newcommand{\\nnhexi}[1]{{\\color{mathcolor}\\mathtt{0x}}{\\color{mathgray}}{\\color{mathcolor} #1}} \\newcommand{\\repeat}[2]{#1\\text{*}#2} \\newcommand{\\byte}{\\nnhexi{nn}} \\newcommand{\\bytes}[1]{\\repeat{\\byte{}}{\\text{#1}}} \\] \\[ \\textcolor{mathcolor}{ \\begin{align*} \\text{<PayloadRpc>} \\ := \\ & \\text{action:}\\text{ShortName}\\ \\text{arguments:}\\text{ArgumentRpc}\\text{*} \\Rightarrowx \\text{action(arguments)} \\\\ \\end{align*} } \\] The short name of an action is an u32 integer identifier that uniquely identifies the action within the smart contract. The short name is encoded as unsigned LEB128 format , which means that short names have variable lengths. It is easy to determine how many bytes a LEB128 encoded number contains by examining bit 7 of each byte. \\[ \\textcolor{mathcolor}{ \\begin{align*} \\text{<ShortName>} \\ := \\ & \\text{pre:}\\nnhexi{nn}\\text{*}\\ \\text{last:}\\nnhexi{nn}\\ \\Rightarrowx \\text{Action} &\\text{(where pre is 0-4 bytes that are \u22650x80 and last<0x80)} \\\\ \\end{align*} } \\] The argument binary format depends on the type of the argument. The argument types for each action is defined by the contract, and can be read from the ABI format. \\[ \\textcolor{mathcolor}{ \\begin{align*} \\text{<ArgumentRpc>} \\ := \\ & \\byte{} \\ \\Rightarrowx \\text{u8/i8} & \\text{(i8 is twos complement)} \\\\ | \\ & \\bytes{2} \\ \\Rightarrowx \\text{u16/i16} & \\text{(big endian, i16 is two's complement)} \\\\ | \\ & \\bytes{4} \\ \\Rightarrowx \\text{u32/i32} & \\text{(big endian, i32 is two's complement)} \\\\ | \\ & \\bytes{8} \\ \\Rightarrowx \\text{u64/i64} & \\text{(big endian, i64 is two's complement)} \\\\ | \\ & \\bytes{16} \\ \\Rightarrowx \\text{u128/i128} & \\text{(big endian, i128 is two's complement)} \\\\ | \\ & \\text{b:}\\byte{} \\ \\Rightarrowx \\text{bool} & \\text{(false if b==0, true otherwise)} \\\\ | \\ & \\bytes{21} \\ \\Rightarrowx \\text{Address} \\\\ | \\ & \\bytes{len} \\ \\Rightarrowx \\text{Array }\\text{[u8;len]} & \\text{(containing the len u8 values)} \\\\ | \\ & \\text{len:}\\text{LengthRpc} \\ \\text{utf8:}\\bytes{len} \\ \\Rightarrowx \\text{String} & \\text{(with len UTF-8 encoded bytes)} \\\\ | \\ & \\text{len:}\\text{LengthRpc} \\ \\text{elems:}\\repeat{\\text{ArgumentRpc}}{\\text{len}} \\ \\Rightarrowx \\text{Vec<>} & \\text{(containing the len elements)} \\\\ | \\ & \\text{b:}\\byte{} \\ \\text{arg:}\\text{ArgumentRpc} \\ \\Rightarrowx \\text{Option<>} & \\text{(None if b==0, Some(arg) otherwise)} \\\\ \\end{align*} } \\] Only arrays of lengths between (including) 0 and 127 are supported. The high bit in length is reserved for later extensions. For arguments with variable lengths, such as Vecs or Strings the number of elements is represented as a big endian 32-bit unsigned integer. \\[ \\textcolor{mathcolor}{ \\begin{align*} \\text{<LengthRpc>} \\ := \\ & \\bytes{4} \\ \\Rightarrowx \\text{u32} \\text{( big endian)} \\\\ \\end{align*} } \\]","title":"RPC Binary Format"},{"location":"abiv3_1.html#state-binary-format","text":"Integers are stored as little-endian. Signed integers are stored as two's complement. Note that lengths are also stored as little-endian. \\[ \\textcolor{mathcolor}{ \\begin{align*} \\text{<State>} \\ := \\ & \\nnhexi{nn} \\ \\Rightarrowx \\text{u8/i8} & \\text{(i8 is twos complement)} \\\\ | \\ & \\bytes{2} \\ \\Rightarrowx \\text{u16/i16} & \\text{(little endian, i16 is two's complement)} \\\\ | \\ & \\bytes{4} \\ \\Rightarrowx \\text{u32/i32} & \\text{(little endian, i32 is two's complement)} \\\\ | \\ & \\bytes{8} \\ \\Rightarrowx \\text{u64/i64} & \\text{(little endian, i64 is two's complement)} \\\\ | \\ & \\bytes{16} \\ \\Rightarrowx \\text{u128/i128} & \\text{(little endian, i128 is two's complement)} \\\\ | \\ & \\text{b:}\\byte{} \\ \\Rightarrowx \\text{bool} & \\text{(false if b==0, true otherwise)} \\\\ | \\ & \\bytes{21} \\ \\Rightarrowx \\text{Address} \\\\ | \\ & \\bytes{len} \\ \\Rightarrowx \\text{Array }\\text{[u8;len]} & \\text{(containing the len u8 values)} \\\\ | \\ & \\text{len:}\\text{LengthState} \\ \\text{utf8:}\\bytes{len} \\ \\Rightarrowx \\text{String} & \\text{(with len UTF-8 encoded bytes)} \\\\ | \\ & \\text{len:}\\text{LengthState} \\ \\text{elems:}\\repeat{\\text{State}}{\\text{len}} \\ \\Rightarrowx \\text{Vec<>} & \\text{(containing the len elements)} \\\\ | \\ & \\text{b:}\\byte{} \\ \\text{arg:}\\text{State} \\ \\Rightarrowx \\text{Option<>} & \\text{(None if b==0, Some(arg) otherwise)} \\\\ | \\ & f_1 \\text{:State} \\dots f_n \\text{:State} \\Rightarrowx \\text{Struct S}\\ \\{ f_1, f_2, \\dots, f_n \\} & \\\\ \\end{align*} } \\] Only arrays of lengths between (including) 0 and 127 are supported. The high bit in length is reserved for later extensions. For arguments with variable lengths, such as Vecs or Strings the number of elements is represented as a little endian 32-bit unsigned integer. \\[ \\textcolor{mathcolor}{ \\begin{align*} \\text{<LengthState>} \\ := \\ & \\bytes{4} \\ \\Rightarrowx \\text{u32} \\text{(little endian)} \\\\ \\end{align*} } \\]","title":"State Binary Format"},{"location":"abiv3_1.html#copyserializable","text":"A state type is said to be CopySerializable, if it's serialization is identical to it's in-memory representation, and thus require minimal serialization overhead. PBC have efficient handling for types that are CopySerializable. Internal pointers are the main reason that types are not CopySerializable. \\[ \\textcolor{mathcolor}{ \\begin{align*} \\text{<CopySerializable>} \\ := \\ & \\text{uXXX} \\Rightarrowx \\text{true}\\\\ | \\ & \\text{iXXX} \\Rightarrowx \\text{true}\\\\ | \\ & \\text{bool} \\Rightarrowx \\text{true}\\\\ | \\ & \\text{Address} \\Rightarrowx \\text{true}\\\\ | \\ & \\text{[u8;N]} \\Rightarrowx \\text{true}\\\\ | \\ & \\text{String} \\Rightarrowx \\text{false}\\\\ | \\ & \\text{Vec<T>} \\Rightarrowx \\text{false}\\\\ | \\ & \\text{Option<T>} \\Rightarrowx \\text{false}\\\\ | \\ & \\text{BTreeMap<K, V>} \\Rightarrowx \\text{false}\\\\ | \\ & \\text{BTreeSet<T>} \\Rightarrowx \\text{false}\\\\ | \\ & \\text{Struct S}\\ \\{ f_1: T_1, \\dots, f_n: T_n \\} \\Rightarrowx \\text{CopySerializable}(T_1) \\wedge \\dots \\wedge \\text{CopySerializable}(T_n) \\wedge \\text{WellAligned(S)} \\\\ \\end{align*} } \\] The WellAligned constraint on Struct CopySerializable is to guarentee that struct layouts are identical to serialization. \\(\\text{Struct S}\\ \\{ f_1: T_1, \\dots, f_n: T_n \\}\\) is WellAligned if following points hold: Annotated with #[repr(C)] . Read the Rust Specification for details on this representation. No padding: \\(\\text{size_of}(S) = \\text{size_of}(T_1) + ... + \\text{size_of}(T_n)\\) No wasted bytes when stored in array: \\(\\text{size_of}(S) \\mod \\text{align_of}(T_n) = 0\\) It may be desirable to manually add \"padding\" fields structs in order to achieve CopySerializable. While this will use extra unneeded bytes for the serialized state, it may significantly improve serialization speed and lower gas costs. A future version of the SDK may automatically add padding fields.","title":"CopySerializable"},{"location":"abiv3_1.html#examples","text":"These structs are CopySerializable: Struct E1 { /* empty */ } Struct E2 { f1: u32 } Struct E3 { f1: u32, f2: u32 } These structs are not CopySerializable: Struct E4 { f1: u8, f2: u16 } due to padding between f1 and f2. Struct E5 { f1: u16, f2: u8 } due to alignment not dividing size. Struct E6 { f1: Vec<u8> } due to non-CopySerializable subfield.","title":"Examples"},{"location":"abiv3_1.html#abi-binary-format","text":"","title":"ABI Binary Format"},{"location":"abiv3_1.html#type-specifier-binary-format","text":"\\[ \\textcolor{mathcolor}{ \\begin{align*} \\text{<TypeSpec>} \\ := \\ &\\text{SimpleTypeSpec} \\\\ | \\ &\\text{CompositeTypeSpec} \\\\ | \\ &\\text{StructTypeSpec} \\\\ \\\\ \\text{<StructTypeSpec>} \\ := \\ &\\hexi{00} \\ \\text{Index}:\\nnhexi{nn} \\Rightarrowx StructTypes(\\text{Index}) \\\\ \\\\ \\text{<SimpleTypeSpec>} \\ := \\ &\\hexi{01} \\ \\Rightarrowx \\text{u8} \\\\ | \\ &\\hexi{02} \\ \\Rightarrowx \\text{u16} \\\\ | \\ &\\hexi{03} \\ \\Rightarrowx \\text{u32} \\\\ | \\ &\\hexi{04} \\ \\Rightarrowx \\text{u64} \\\\ | \\ &\\hexi{05} \\ \\Rightarrowx \\text{u128} \\\\ | \\ &\\hexi{06} \\ \\Rightarrowx \\text{i8} \\\\ | \\ &\\hexi{07} \\ \\Rightarrowx \\text{i16} \\\\ | \\ &\\hexi{08} \\ \\Rightarrowx \\text{i32} \\\\ | \\ &\\hexi{09} \\ \\Rightarrowx \\text{i64} \\\\ | \\ &\\hexi{0a} \\ \\Rightarrowx \\text{i128} \\\\ | \\ &\\hexi{0b} \\ \\Rightarrowx \\text{String} \\\\ | \\ &\\hexi{0c} \\ \\Rightarrowx \\text{bool} \\\\ | \\ &\\hexi{0d} \\ \\Rightarrowx \\text{Address} \\\\ \\\\ \\text{<CompositeTypeSpec>} \\ := \\ &\\hexi{0e} \\text{ T:}\\text{TypeSpec} \\Rightarrowx \\text{Vec<}\\text{T>} \\\\ | \\ &\\hexi{0f} \\text{ K:}\\text{TypeSpec}\\text{ V:}\\text{TypeSpec} \\Rightarrowx \\text{Map <}\\text{K}, \\text{V>} \\\\ | \\ &\\hexi{10} \\text{ T:}\\text{TypeSpec} \\Rightarrowx \\text{Set<}\\text{T>} \\\\ | \\ &\\hexi{11} \\text{ L:}\\nnhexi{nn} \\Rightarrowx \\text{[u8; }\\text{L}\\text{]} & (\\hexi{00} \\leq L \\leq \\hexi{7F}) \\\\ | \\ &\\hexi{12} \\text{ T:}\\text{TypeSpec} \\Rightarrowx \\text{Option<}\\text{T>} \\\\ \\\\ \\end{align*} } \\] NOTE: Map and Set cannot be used as RPC arguments since it's not possible for a caller to check equality and sort order of the elements without running the code. Only arrays of lengths between (including) 0 and 127 are supported. The high bit in length is reserved for later extensions.","title":"Type Specifier binary format"},{"location":"abiv3_1.html#abi-file-binary-format","text":"All Identifier names must be valid Rust identifiers ; other strings are reserved for future extensions. \\[ \\textcolor{mathcolor}{ \\begin{align*} \\text{<FileAbi>} \\ := \\ \\{ \\ &\\text{Header: } \\bytes{6}, \\text{The header is always \"PBCABI\" in ASCII}\\\\ &\\text{VersionBinder: } \\bytes{3} \\ \\\\ &\\text{VersionClient: } \\bytes{3} \\ \\\\ &\\text{Contract: ContractAbi} \\ \\} \\\\ \\\\ \\text{<ContractAbi>} \\ := \\ \\{ \\ &\\text{StructTypes: List<StructTypeAbi>}, \\\\ &\\text{Init: FnAbi}, \\\\ &\\text{Actions: List<FnAbi>}, \\\\ &\\text{StateType: TypeSpec} \\ \\} \\\\ \\text{<StructTypeAbi>} \\ := \\ \\{ \\ &\\text{Name: Identifier}, \\\\ &\\text{Fields: List<FieldAbi>} \\ \\} \\\\ \\\\ \\text{<FnAbi>} \\ := \\ \\{ \\ &\\text{Name: Identifier}, \\\\ &\\text{Shortname: LEB128}, \\\\ &\\text{Arguments: List<ArgumentAbi>} \\ \\} \\\\ \\\\ \\text{<FieldAbi>} \\ := \\ \\{ \\ &\\text{Name: Identifier}, \\\\ &\\text{Type: TypeSpec} \\ \\} \\\\ \\\\ \\text{<ArgumentAbi>} \\ := \\ \\{ \\ &\\text{Name: Identifier}, \\\\ &\\text{Type: TypeSpec} \\ \\} \\\\ \\\\ \\text{<Identifier>} \\ := \\ \\phantom{\\{} \\ &\\text{len:}\\bytes{4} \\ \\text{utf8:}\\bytes{len} \\text{ utf8 must be Rust identifier, len is big endian} \\\\ \\\\ \\text{<LEB128>} \\ := \\ \\phantom{\\{} \\ &\\text{A LEB128 encoded unsigned 32 bit integer (1-5 bytes).} \\\\ \\end{align*} } \\]","title":"ABI File binary format"},{"location":"abiv3_1.html#wasm-contract-result-format","text":"The format used by Wasm contracts to return results is a section-based format defined as following: \\[ \\textcolor{mathcolor}{ \\begin{align*} \\text{<Result>} \\ := \\ & \\text{section}_0\\text{: Section} \\ \\dots \\ \\text{section}_n\\text{: Section} \\\\ \\text{<Section >} \\ := \\ & \\text{id:}\\byte{} \\ \\text{len:}\\bytes{4} \\ \\text{data:}\\bytes{len} \\ \\text{(len is big endian)} \\\\ \\end{align*} } \\] Note that section must occur in order of increasing ids. Two ids are \"well-known\" and specially handled by the interpreter: 0x01 : Stores event information. 0x02 : Stores state. Section ids 0x00 to 0x0F are reserved for \"well-known\" usage. All others are passed through the interpreter without modification.","title":"Wasm contract result format"},{"location":"abiv_latest.html","text":"Partisia Blockchain Smart Contract Binary Formats A Partisia Smart Contract utilizes three distinct binary formats, which are described in detail below. RPC Format : When an action of the smart function is invoked, the payload is sent to the action as binary data. The payload identifies which action is invoked and the values for all parameters to the action. State Format : The state of a smart contract is stored as binary data in the blockchain state. The state holds the value of all smart contract state variables. ABI Format : Meta-information about the smart contract is also stored as binary data, The ABI holds the list of available actions and their parameters and information about the different state variables. ABI Version changes Version 3.1 to 4.0 : Added Kind: FnKind field to FnAbi . Removed Init field from ContractAbi . Added zero-knowledge related FnKind s, for use in Zk contracts. Version 2.0 to 3.1 : Shortnames are now encoded as LEB128; ShortnameLength field have been removed. Added explicit, easily extensible return result format. RPC Binary Format The RPC payload identifies which action is invoked and the values for all parameters of the action. To decode the payload binary format you have to know which argument types each action expects, since the format of the argument values depends on the argument type. The ABI Format holds exactly the meta-data needed for finding types of the arguments for each action. The RPC payload contains the short name identifying the action being called followed by each of the arguments for the action. \\[ \\definecolor{mathcolor}{RGB}{33,33,33} \\definecolor{mathgray}{RGB}{100,100,100} \\newcommand{\\Rightarrowx}{{\\color{mathgray} \\ \\Rightarrow \\ \\ }} \\newcommand{\\hexi}[1]{{\\color{mathcolor}\\mathtt{0x}}{\\color{mathgray}}{\\color{mathcolor}\\mathtt{#1}}} \\newcommand{\\nnhexi}[1]{{\\color{mathcolor}\\mathtt{0x}}{\\color{mathgray}}{\\color{mathcolor} #1}} \\newcommand{\\repeat}[2]{#1\\text{*}#2} \\newcommand{\\byte}{\\nnhexi{nn}} \\newcommand{\\bytes}[1]{\\repeat{\\byte{}}{\\text{#1}}} \\] \\[ \\textcolor{mathcolor}{ \\begin{align*} \\text{<PayloadRpc>} \\ := \\ & \\text{action:}\\text{ShortName}\\ \\text{arguments:}\\text{ArgumentRpc}\\text{*} \\Rightarrowx \\text{action(arguments)} \\\\ \\end{align*} } \\] The short name of an action is an u32 integer identifier that uniquely identifies the action within the smart contract. The short name is encoded as unsigned LEB128 format , which means that short names have variable lengths. It is easy to determine how many bytes a LEB128 encoded number contains by examining bit 7 of each byte. \\[ \\textcolor{mathcolor}{ \\begin{align*} \\text{<ShortName>} \\ := \\ & \\text{pre:}\\nnhexi{nn}\\text{*}\\ \\text{last:}\\nnhexi{nn}\\ \\Rightarrowx \\text{Action} &\\text{(where pre is 0-4 bytes that are \u22650x80 and last<0x80)} \\\\ \\end{align*} } \\] The argument binary format depends on the type of the argument. The argument types for each action is defined by the contract, and can be read from the ABI format. \\[ \\textcolor{mathcolor}{ \\begin{align*} \\text{<ArgumentRpc>} \\ := \\ & \\byte{} \\ \\Rightarrowx \\text{u8/i8} & \\text{(i8 is twos complement)} \\\\ | \\ & \\bytes{2} \\ \\Rightarrowx \\text{u16/i16} & \\text{(big endian, i16 is two's complement)} \\\\ | \\ & \\bytes{4} \\ \\Rightarrowx \\text{u32/i32} & \\text{(big endian, i32 is two's complement)} \\\\ | \\ & \\bytes{8} \\ \\Rightarrowx \\text{u64/i64} & \\text{(big endian, i64 is two's complement)} \\\\ | \\ & \\bytes{16} \\ \\Rightarrowx \\text{u128/i128} & \\text{(big endian, i128 is two's complement)} \\\\ | \\ & \\text{b:}\\byte{} \\ \\Rightarrowx \\text{bool} & \\text{(false if b==0, true otherwise)} \\\\ | \\ & \\bytes{21} \\ \\Rightarrowx \\text{Address} \\\\ | \\ & \\bytes{len} \\ \\Rightarrowx \\text{Array }\\text{[u8;len]} & \\text{(containing the len u8 values)} \\\\ | \\ & \\text{len:}\\text{LengthRpc} \\ \\text{utf8:}\\bytes{len} \\ \\Rightarrowx \\text{String} & \\text{(with len UTF-8 encoded bytes)} \\\\ | \\ & \\text{len:}\\text{LengthRpc} \\ \\text{elems:}\\repeat{\\text{ArgumentRpc}}{\\text{len}} \\ \\Rightarrowx \\text{Vec<>} & \\text{(containing the len elements)} \\\\ | \\ & \\text{b:}\\byte{} \\ \\text{arg:}\\text{ArgumentRpc} \\ \\Rightarrowx \\text{Option<>} & \\text{(None if b==0, Some(arg) otherwise)} \\\\ \\end{align*} } \\] Only arrays of lengths between (including) 0 and 127 are supported. The high bit in length is reserved for later extensions. For arguments with variable lengths, such as Vecs or Strings the number of elements is represented as a big endian 32-bit unsigned integer. \\[ \\textcolor{mathcolor}{ \\begin{align*} \\text{<LengthRpc>} \\ := \\ & \\bytes{4} \\ \\Rightarrowx \\text{u32} \\text{(big endian)} \\\\ \\end{align*} } \\] State Binary Format Integers are stored as little-endian. Signed integers are stored as two's complement. Note that lengths are also stored as little-endian. \\[ \\textcolor{mathcolor}{ \\begin{align*} \\text{<State>} \\ := \\ & \\nnhexi{nn} \\ \\Rightarrowx \\text{u8/i8} & \\text{(i8 is twos complement)} \\\\ | \\ & \\bytes{2} \\ \\Rightarrowx \\text{u16/i16} & \\text{(little endian, i16 is two's complement)} \\\\ | \\ & \\bytes{4} \\ \\Rightarrowx \\text{u32/i32} & \\text{(little endian, i32 is two's complement)} \\\\ | \\ & \\bytes{8} \\ \\Rightarrowx \\text{u64/i64} & \\text{(little endian, i64 is two's complement)} \\\\ | \\ & \\bytes{16} \\ \\Rightarrowx \\text{u128/i128} & \\text{(little endian, i128 is two's complement)} \\\\ | \\ & \\text{b:}\\byte{} \\ \\Rightarrowx \\text{bool} & \\text{(false if b==0, true otherwise)} \\\\ | \\ & \\bytes{21} \\ \\Rightarrowx \\text{Address} \\\\ | \\ & \\bytes{len} \\ \\Rightarrowx \\text{Array }\\text{[u8;len]} & \\text{(containing the len u8 values)} \\\\ | \\ & \\text{len:}\\text{LengthState} \\ \\text{utf8:}\\bytes{len} \\ \\Rightarrowx \\text{String} & \\text{(with len UTF-8 encoded bytes)} \\\\ | \\ & \\text{len:}\\text{LengthState} \\ \\text{elems:}\\repeat{\\text{State}}{\\text{len}} \\ \\Rightarrowx \\text{Vec<>} & \\text{(containing the len elements)} \\\\ | \\ & \\text{b:}\\byte{} \\ \\text{arg:}\\text{State} \\ \\Rightarrowx \\text{Option<>} & \\text{(None if b==0, Some(arg) otherwise)} \\\\ | \\ & f_1 \\text{:State} \\dots f_n \\text{:State} \\Rightarrowx \\text{Struct S}\\ \\{ f_1, f_2, \\dots, f_n \\} & \\\\ \\end{align*} } \\] Only arrays of lengths between (including) 0 and 127 are supported. The high bit in length is reserved for later extensions. For arguments with variable lengths, such as Vecs or Strings the number of elements is represented as a little endian 32-bit unsigned integer. \\[ \\textcolor{mathcolor}{ \\begin{align*} \\text{<LengthState>} \\ := \\ & \\bytes{4} \\ \\Rightarrowx \\text{u32} &\\text{(little endian)} \\\\ \\end{align*} } \\] CopySerializable A state type is said to be CopySerializable, if it's serialization is identical to it's in-memory representation, and thus require minimal serialization overhead. PBC have efficient handling for types that are CopySerializable. Internal pointers are the main reason that types are not CopySerializable. \\[ \\textcolor{mathcolor}{ \\begin{align*} \\text{<CopySerializable>} \\ := \\ & \\text{uXXX} \\Rightarrowx \\text{true}\\\\ | \\ & \\text{iXXX} \\Rightarrowx \\text{true}\\\\ | \\ & \\text{bool} \\Rightarrowx \\text{true}\\\\ | \\ & \\text{Address} \\Rightarrowx \\text{true}\\\\ | \\ & \\text{[u8;N]} \\Rightarrowx \\text{true}\\\\ | \\ & \\text{String} \\Rightarrowx \\text{false}\\\\ | \\ & \\text{Vec<T>} \\Rightarrowx \\text{false}\\\\ | \\ & \\text{Option<T>} \\Rightarrowx \\text{false}\\\\ | \\ & \\text{BTreeMap<K, V>} \\Rightarrowx \\text{false}\\\\ | \\ & \\text{BTreeSet<T>} \\Rightarrowx \\text{false}\\\\ | \\ & \\text{Struct S}\\ \\{ f_1: T_1, \\dots, f_n: T_n \\} \\Rightarrowx \\text{CopySerializable}(T_1) \\wedge \\dots \\wedge \\text{CopySerializable}(T_n) \\wedge \\text{WellAligned(S)} \\\\ \\end{align*} } \\] The WellAligned constraint on Struct CopySerializable is to guarentee that struct layouts are identical to serialization. \\(\\text{Struct S}\\ \\{ f_1: T_1, \\dots, f_n: T_n \\}\\) is WellAligned if following points hold: Annotated with #[repr(C)] . Read the Rust Specification for details on this representation. No padding: \\(\\text{size_of}(S) = \\text{size_of}(T_1) + ... + \\text{size_of}(T_n)\\) No wasted bytes when stored in array: \\(\\text{size_of}(S) \\mod \\text{align_of}(T_n) = 0\\) It may be desirable to manually add \"padding\" fields structs in order to achieve CopySerializable. While this will use extra unneeded bytes for the serialized state, it may significantly improve serialization speed and lower gas costs. A future version of the SDK may automatically add padding fields. Examples These structs are CopySerializable: Struct E1 { /* empty */ } Struct E2 { f1: u32 } Struct E3 { f1: u32, f2: u32 } These structs are not CopySerializable: Struct E4 { f1: u8, f2: u16 } due to padding between f1 and f2. Struct E5 { f1: u16, f2: u8 } due to alignment not dividing size. Struct E6 { f1: Vec<u8> } due to non-CopySerializable subfield. ABI Binary Format Type Specifier binary format \\[ \\textcolor{mathcolor}{ \\begin{align*} \\text{<TypeSpec>} \\ := \\ &\\text{SimpleTypeSpec} \\\\ | \\ &\\text{CompositeTypeSpec} \\\\ | \\ &\\text{StructTypeRef} \\\\ \\\\ \\text{<StructTypeRef>} \\ := \\ &\\hexi{00} \\ \\text{Index}:\\nnhexi{nn} \\Rightarrowx StructTypes(\\text{Index}) \\\\ \\\\ \\text{<SimpleTypeSpec>} \\ := \\ &\\hexi{01} \\ \\Rightarrowx \\text{u8} \\\\ | \\ &\\hexi{02} \\ \\Rightarrowx \\text{u16} \\\\ | \\ &\\hexi{03} \\ \\Rightarrowx \\text{u32} \\\\ | \\ &\\hexi{04} \\ \\Rightarrowx \\text{u64} \\\\ | \\ &\\hexi{05} \\ \\Rightarrowx \\text{u128} \\\\ | \\ &\\hexi{06} \\ \\Rightarrowx \\text{i8} \\\\ | \\ &\\hexi{07} \\ \\Rightarrowx \\text{i16} \\\\ | \\ &\\hexi{08} \\ \\Rightarrowx \\text{i32} \\\\ | \\ &\\hexi{09} \\ \\Rightarrowx \\text{i64} \\\\ | \\ &\\hexi{0a} \\ \\Rightarrowx \\text{i128} \\\\ | \\ &\\hexi{0b} \\ \\Rightarrowx \\text{String} \\\\ | \\ &\\hexi{0c} \\ \\Rightarrowx \\text{bool} \\\\ | \\ &\\hexi{0d} \\ \\Rightarrowx \\text{Address} \\\\ \\\\ \\text{<CompositeTypeSpec>} \\ := \\ &\\hexi{0e} \\text{ T:}\\text{TypeSpec} \\Rightarrowx \\text{Vec<}\\text{T>} \\\\ | \\ &\\hexi{0f} \\text{ K:}\\text{TypeSpec}\\text{ V:}\\text{TypeSpec} \\Rightarrowx \\text{Map <}\\text{K}, \\text{V>} \\\\ | \\ &\\hexi{10} \\text{ T:}\\text{TypeSpec} \\Rightarrowx \\text{Set<}\\text{T>} \\\\ | \\ &\\hexi{11} \\text{ L:}\\nnhexi{nn} \\Rightarrowx \\text{[u8; }\\text{L}\\text{]} (\\hexi{00} \\leq L \\leq \\hexi{7F}) \\\\ | \\ &\\hexi{12} \\text{ T:}\\text{TypeSpec} \\Rightarrowx \\text{Option<}\\text{T>} \\\\ \\\\ \\end{align*} } \\] NOTE: Map and Set cannot be used as RPC arguments since it's not possible for a caller to check equality and sort order of the elements without running the code. Only arrays of lengths between (including) 0 and 127 are supported. The high bit in length is reserved for later extensions. ABI File binary format All Identifier names must be valid Rust identifiers ; other strings are reserved for future extensions. \\[ \\textcolor{mathcolor}{ \\begin{align*} \\text{<FileAbi>} \\ := \\ \\{ \\ &\\text{Header: } \\bytes{6},\\text{The header is always \"PBCABI\" in ASCII}\\\\ &\\text{VersionBinder: } \\bytes{3} \\ \\\\ &\\text{VersionClient: } \\bytes{3} \\ \\\\ &\\text{Contract: ContractAbi} \\ \\} \\\\ \\\\ \\text{<ContractAbi>} \\ := \\ \\{ \\ &\\text{StructTypes: List<StructTypeSpec>}, \\\\ &\\text{Hooks: List<FnAbi>}, \\\\ &\\text{StateType: TypeSpec} \\ \\} \\\\ \\\\ \\text{<StructTypeSpec>} \\ := \\ \\{ \\ &\\text{Name: Identifier}, \\\\ &\\text{Fields: List<FieldAbi>} \\ \\} \\\\ \\\\ \\text{<FnAbi>} \\ := \\ \\{ \\ &\\text{Kind: FnKind}, \\\\ &\\text{Name: Identifier}, \\\\ &\\text{Shortname: LEB128}, \\\\ &\\text{Arguments: List<ArgumentAbi>} \\ \\} \\\\ \\\\ \\text{<FieldAbi>} \\ := \\ \\{ \\ &\\text{Name: Identifier}, \\\\ &\\text{Type: TypeSpec} \\ \\} \\\\ \\\\ \\text{<ArgumentAbi>} \\ := \\ \\{ \\ &\\text{Name: Identifier}, \\\\ &\\text{Type: TypeSpec} \\ \\} \\\\ \\\\ \\text{<Identifier>} \\ := \\ \\phantom{\\{} \\ &\\text{len:}\\bytes{4} \\ \\text{utf8:}\\bytes{len} \\text{ utf8 must be Rust identifier, len is big endian} \\\\ \\\\ \\text{<LEB128>} \\ := \\ \\phantom{\\{} \\ &\\text{A LEB128 encoded unsigned 32 bit integer (1-5 bytes).} \\\\ \\\\ \\text{<FnKind>} \\ := \\ \\ &\\hexi{01} \\ \\Rightarrowx \\text{Init} &\\text{(Num allowed: 1)} \\\\ |\\ &\\hexi{02} \\ \\Rightarrowx \\text{Action} &\\text{(0..}\\infty\\text{)}\\\\ |\\ &\\hexi{03} \\ \\Rightarrowx \\text{Callback} &\\text{(0..}\\infty\\text{)}\\\\ |\\ &\\hexi{10} \\ \\Rightarrowx \\text{ZkSecretInput} &\\text{(0..}\\infty\\text{)}\\\\ |\\ &\\hexi{11} \\ \\Rightarrowx \\text{ZkVarInputted} &\\text{(0..1)}\\\\ |\\ &\\hexi{12} \\ \\Rightarrowx \\text{ZkVarRejected} &\\text{(0..1)}\\\\ |\\ &\\hexi{13} \\ \\Rightarrowx \\text{ZkComputeComplete} &\\text{(0..1)}\\\\ |\\ &\\hexi{14} \\ \\Rightarrowx \\text{ZkVarOpened} &\\text{(0..1)}\\\\ |\\ &\\hexi{15} \\ \\Rightarrowx \\text{ZkUserVarOpened} &\\text{(0..1)} \\end{align*} } \\] Note that a ContractAbi is only valid if the Hooks list contains a specific number of hooks of each type, as specified in FnKind . Wasm contract result format The format used by Wasm contracts to return results is a section-based format defined as following: \\[ \\textcolor{mathcolor}{ \\begin{align*} \\text{<Result>} \\ := \\ & \\text{section}_0\\text{: Section} \\ \\dots \\ \\text{section}_n\\text{: Section} \\\\ \\text{<Section >} \\ := \\ & \\text{id:}\\byte{} \\ \\text{len:}\\bytes{4} \\ \\text{data:}\\bytes{len} \\ \\text{(len is big endian)} \\\\ \\end{align*} } \\] Note that section must occur in order of increasing ids. Two ids are \"well-known\" and specially handled by the interpreter: 0x01 : Stores event information. 0x02 : Stores state. Section ids 0x00 to 0x0F are reserved for \"well-known\" usage. All others are passed through the interpreter without modification.","title":"ABI 4.0 specification"},{"location":"abiv_latest.html#partisia-blockchain-smart-contract-binary-formats","text":"A Partisia Smart Contract utilizes three distinct binary formats, which are described in detail below. RPC Format : When an action of the smart function is invoked, the payload is sent to the action as binary data. The payload identifies which action is invoked and the values for all parameters to the action. State Format : The state of a smart contract is stored as binary data in the blockchain state. The state holds the value of all smart contract state variables. ABI Format : Meta-information about the smart contract is also stored as binary data, The ABI holds the list of available actions and their parameters and information about the different state variables.","title":"Partisia Blockchain Smart Contract Binary Formats"},{"location":"abiv_latest.html#abi-version-changes","text":"Version 3.1 to 4.0 : Added Kind: FnKind field to FnAbi . Removed Init field from ContractAbi . Added zero-knowledge related FnKind s, for use in Zk contracts. Version 2.0 to 3.1 : Shortnames are now encoded as LEB128; ShortnameLength field have been removed. Added explicit, easily extensible return result format.","title":"ABI Version changes"},{"location":"abiv_latest.html#rpc-binary-format","text":"The RPC payload identifies which action is invoked and the values for all parameters of the action. To decode the payload binary format you have to know which argument types each action expects, since the format of the argument values depends on the argument type. The ABI Format holds exactly the meta-data needed for finding types of the arguments for each action. The RPC payload contains the short name identifying the action being called followed by each of the arguments for the action. \\[ \\definecolor{mathcolor}{RGB}{33,33,33} \\definecolor{mathgray}{RGB}{100,100,100} \\newcommand{\\Rightarrowx}{{\\color{mathgray} \\ \\Rightarrow \\ \\ }} \\newcommand{\\hexi}[1]{{\\color{mathcolor}\\mathtt{0x}}{\\color{mathgray}}{\\color{mathcolor}\\mathtt{#1}}} \\newcommand{\\nnhexi}[1]{{\\color{mathcolor}\\mathtt{0x}}{\\color{mathgray}}{\\color{mathcolor} #1}} \\newcommand{\\repeat}[2]{#1\\text{*}#2} \\newcommand{\\byte}{\\nnhexi{nn}} \\newcommand{\\bytes}[1]{\\repeat{\\byte{}}{\\text{#1}}} \\] \\[ \\textcolor{mathcolor}{ \\begin{align*} \\text{<PayloadRpc>} \\ := \\ & \\text{action:}\\text{ShortName}\\ \\text{arguments:}\\text{ArgumentRpc}\\text{*} \\Rightarrowx \\text{action(arguments)} \\\\ \\end{align*} } \\] The short name of an action is an u32 integer identifier that uniquely identifies the action within the smart contract. The short name is encoded as unsigned LEB128 format , which means that short names have variable lengths. It is easy to determine how many bytes a LEB128 encoded number contains by examining bit 7 of each byte. \\[ \\textcolor{mathcolor}{ \\begin{align*} \\text{<ShortName>} \\ := \\ & \\text{pre:}\\nnhexi{nn}\\text{*}\\ \\text{last:}\\nnhexi{nn}\\ \\Rightarrowx \\text{Action} &\\text{(where pre is 0-4 bytes that are \u22650x80 and last<0x80)} \\\\ \\end{align*} } \\] The argument binary format depends on the type of the argument. The argument types for each action is defined by the contract, and can be read from the ABI format. \\[ \\textcolor{mathcolor}{ \\begin{align*} \\text{<ArgumentRpc>} \\ := \\ & \\byte{} \\ \\Rightarrowx \\text{u8/i8} & \\text{(i8 is twos complement)} \\\\ | \\ & \\bytes{2} \\ \\Rightarrowx \\text{u16/i16} & \\text{(big endian, i16 is two's complement)} \\\\ | \\ & \\bytes{4} \\ \\Rightarrowx \\text{u32/i32} & \\text{(big endian, i32 is two's complement)} \\\\ | \\ & \\bytes{8} \\ \\Rightarrowx \\text{u64/i64} & \\text{(big endian, i64 is two's complement)} \\\\ | \\ & \\bytes{16} \\ \\Rightarrowx \\text{u128/i128} & \\text{(big endian, i128 is two's complement)} \\\\ | \\ & \\text{b:}\\byte{} \\ \\Rightarrowx \\text{bool} & \\text{(false if b==0, true otherwise)} \\\\ | \\ & \\bytes{21} \\ \\Rightarrowx \\text{Address} \\\\ | \\ & \\bytes{len} \\ \\Rightarrowx \\text{Array }\\text{[u8;len]} & \\text{(containing the len u8 values)} \\\\ | \\ & \\text{len:}\\text{LengthRpc} \\ \\text{utf8:}\\bytes{len} \\ \\Rightarrowx \\text{String} & \\text{(with len UTF-8 encoded bytes)} \\\\ | \\ & \\text{len:}\\text{LengthRpc} \\ \\text{elems:}\\repeat{\\text{ArgumentRpc}}{\\text{len}} \\ \\Rightarrowx \\text{Vec<>} & \\text{(containing the len elements)} \\\\ | \\ & \\text{b:}\\byte{} \\ \\text{arg:}\\text{ArgumentRpc} \\ \\Rightarrowx \\text{Option<>} & \\text{(None if b==0, Some(arg) otherwise)} \\\\ \\end{align*} } \\] Only arrays of lengths between (including) 0 and 127 are supported. The high bit in length is reserved for later extensions. For arguments with variable lengths, such as Vecs or Strings the number of elements is represented as a big endian 32-bit unsigned integer. \\[ \\textcolor{mathcolor}{ \\begin{align*} \\text{<LengthRpc>} \\ := \\ & \\bytes{4} \\ \\Rightarrowx \\text{u32} \\text{(big endian)} \\\\ \\end{align*} } \\]","title":"RPC Binary Format"},{"location":"abiv_latest.html#state-binary-format","text":"Integers are stored as little-endian. Signed integers are stored as two's complement. Note that lengths are also stored as little-endian. \\[ \\textcolor{mathcolor}{ \\begin{align*} \\text{<State>} \\ := \\ & \\nnhexi{nn} \\ \\Rightarrowx \\text{u8/i8} & \\text{(i8 is twos complement)} \\\\ | \\ & \\bytes{2} \\ \\Rightarrowx \\text{u16/i16} & \\text{(little endian, i16 is two's complement)} \\\\ | \\ & \\bytes{4} \\ \\Rightarrowx \\text{u32/i32} & \\text{(little endian, i32 is two's complement)} \\\\ | \\ & \\bytes{8} \\ \\Rightarrowx \\text{u64/i64} & \\text{(little endian, i64 is two's complement)} \\\\ | \\ & \\bytes{16} \\ \\Rightarrowx \\text{u128/i128} & \\text{(little endian, i128 is two's complement)} \\\\ | \\ & \\text{b:}\\byte{} \\ \\Rightarrowx \\text{bool} & \\text{(false if b==0, true otherwise)} \\\\ | \\ & \\bytes{21} \\ \\Rightarrowx \\text{Address} \\\\ | \\ & \\bytes{len} \\ \\Rightarrowx \\text{Array }\\text{[u8;len]} & \\text{(containing the len u8 values)} \\\\ | \\ & \\text{len:}\\text{LengthState} \\ \\text{utf8:}\\bytes{len} \\ \\Rightarrowx \\text{String} & \\text{(with len UTF-8 encoded bytes)} \\\\ | \\ & \\text{len:}\\text{LengthState} \\ \\text{elems:}\\repeat{\\text{State}}{\\text{len}} \\ \\Rightarrowx \\text{Vec<>} & \\text{(containing the len elements)} \\\\ | \\ & \\text{b:}\\byte{} \\ \\text{arg:}\\text{State} \\ \\Rightarrowx \\text{Option<>} & \\text{(None if b==0, Some(arg) otherwise)} \\\\ | \\ & f_1 \\text{:State} \\dots f_n \\text{:State} \\Rightarrowx \\text{Struct S}\\ \\{ f_1, f_2, \\dots, f_n \\} & \\\\ \\end{align*} } \\] Only arrays of lengths between (including) 0 and 127 are supported. The high bit in length is reserved for later extensions. For arguments with variable lengths, such as Vecs or Strings the number of elements is represented as a little endian 32-bit unsigned integer. \\[ \\textcolor{mathcolor}{ \\begin{align*} \\text{<LengthState>} \\ := \\ & \\bytes{4} \\ \\Rightarrowx \\text{u32} &\\text{(little endian)} \\\\ \\end{align*} } \\]","title":"State Binary Format"},{"location":"abiv_latest.html#copyserializable","text":"A state type is said to be CopySerializable, if it's serialization is identical to it's in-memory representation, and thus require minimal serialization overhead. PBC have efficient handling for types that are CopySerializable. Internal pointers are the main reason that types are not CopySerializable. \\[ \\textcolor{mathcolor}{ \\begin{align*} \\text{<CopySerializable>} \\ := \\ & \\text{uXXX} \\Rightarrowx \\text{true}\\\\ | \\ & \\text{iXXX} \\Rightarrowx \\text{true}\\\\ | \\ & \\text{bool} \\Rightarrowx \\text{true}\\\\ | \\ & \\text{Address} \\Rightarrowx \\text{true}\\\\ | \\ & \\text{[u8;N]} \\Rightarrowx \\text{true}\\\\ | \\ & \\text{String} \\Rightarrowx \\text{false}\\\\ | \\ & \\text{Vec<T>} \\Rightarrowx \\text{false}\\\\ | \\ & \\text{Option<T>} \\Rightarrowx \\text{false}\\\\ | \\ & \\text{BTreeMap<K, V>} \\Rightarrowx \\text{false}\\\\ | \\ & \\text{BTreeSet<T>} \\Rightarrowx \\text{false}\\\\ | \\ & \\text{Struct S}\\ \\{ f_1: T_1, \\dots, f_n: T_n \\} \\Rightarrowx \\text{CopySerializable}(T_1) \\wedge \\dots \\wedge \\text{CopySerializable}(T_n) \\wedge \\text{WellAligned(S)} \\\\ \\end{align*} } \\] The WellAligned constraint on Struct CopySerializable is to guarentee that struct layouts are identical to serialization. \\(\\text{Struct S}\\ \\{ f_1: T_1, \\dots, f_n: T_n \\}\\) is WellAligned if following points hold: Annotated with #[repr(C)] . Read the Rust Specification for details on this representation. No padding: \\(\\text{size_of}(S) = \\text{size_of}(T_1) + ... + \\text{size_of}(T_n)\\) No wasted bytes when stored in array: \\(\\text{size_of}(S) \\mod \\text{align_of}(T_n) = 0\\) It may be desirable to manually add \"padding\" fields structs in order to achieve CopySerializable. While this will use extra unneeded bytes for the serialized state, it may significantly improve serialization speed and lower gas costs. A future version of the SDK may automatically add padding fields.","title":"CopySerializable"},{"location":"abiv_latest.html#examples","text":"These structs are CopySerializable: Struct E1 { /* empty */ } Struct E2 { f1: u32 } Struct E3 { f1: u32, f2: u32 } These structs are not CopySerializable: Struct E4 { f1: u8, f2: u16 } due to padding between f1 and f2. Struct E5 { f1: u16, f2: u8 } due to alignment not dividing size. Struct E6 { f1: Vec<u8> } due to non-CopySerializable subfield.","title":"Examples"},{"location":"abiv_latest.html#abi-binary-format","text":"","title":"ABI Binary Format"},{"location":"abiv_latest.html#type-specifier-binary-format","text":"\\[ \\textcolor{mathcolor}{ \\begin{align*} \\text{<TypeSpec>} \\ := \\ &\\text{SimpleTypeSpec} \\\\ | \\ &\\text{CompositeTypeSpec} \\\\ | \\ &\\text{StructTypeRef} \\\\ \\\\ \\text{<StructTypeRef>} \\ := \\ &\\hexi{00} \\ \\text{Index}:\\nnhexi{nn} \\Rightarrowx StructTypes(\\text{Index}) \\\\ \\\\ \\text{<SimpleTypeSpec>} \\ := \\ &\\hexi{01} \\ \\Rightarrowx \\text{u8} \\\\ | \\ &\\hexi{02} \\ \\Rightarrowx \\text{u16} \\\\ | \\ &\\hexi{03} \\ \\Rightarrowx \\text{u32} \\\\ | \\ &\\hexi{04} \\ \\Rightarrowx \\text{u64} \\\\ | \\ &\\hexi{05} \\ \\Rightarrowx \\text{u128} \\\\ | \\ &\\hexi{06} \\ \\Rightarrowx \\text{i8} \\\\ | \\ &\\hexi{07} \\ \\Rightarrowx \\text{i16} \\\\ | \\ &\\hexi{08} \\ \\Rightarrowx \\text{i32} \\\\ | \\ &\\hexi{09} \\ \\Rightarrowx \\text{i64} \\\\ | \\ &\\hexi{0a} \\ \\Rightarrowx \\text{i128} \\\\ | \\ &\\hexi{0b} \\ \\Rightarrowx \\text{String} \\\\ | \\ &\\hexi{0c} \\ \\Rightarrowx \\text{bool} \\\\ | \\ &\\hexi{0d} \\ \\Rightarrowx \\text{Address} \\\\ \\\\ \\text{<CompositeTypeSpec>} \\ := \\ &\\hexi{0e} \\text{ T:}\\text{TypeSpec} \\Rightarrowx \\text{Vec<}\\text{T>} \\\\ | \\ &\\hexi{0f} \\text{ K:}\\text{TypeSpec}\\text{ V:}\\text{TypeSpec} \\Rightarrowx \\text{Map <}\\text{K}, \\text{V>} \\\\ | \\ &\\hexi{10} \\text{ T:}\\text{TypeSpec} \\Rightarrowx \\text{Set<}\\text{T>} \\\\ | \\ &\\hexi{11} \\text{ L:}\\nnhexi{nn} \\Rightarrowx \\text{[u8; }\\text{L}\\text{]} (\\hexi{00} \\leq L \\leq \\hexi{7F}) \\\\ | \\ &\\hexi{12} \\text{ T:}\\text{TypeSpec} \\Rightarrowx \\text{Option<}\\text{T>} \\\\ \\\\ \\end{align*} } \\] NOTE: Map and Set cannot be used as RPC arguments since it's not possible for a caller to check equality and sort order of the elements without running the code. Only arrays of lengths between (including) 0 and 127 are supported. The high bit in length is reserved for later extensions.","title":"Type Specifier binary format"},{"location":"abiv_latest.html#abi-file-binary-format","text":"All Identifier names must be valid Rust identifiers ; other strings are reserved for future extensions. \\[ \\textcolor{mathcolor}{ \\begin{align*} \\text{<FileAbi>} \\ := \\ \\{ \\ &\\text{Header: } \\bytes{6},\\text{The header is always \"PBCABI\" in ASCII}\\\\ &\\text{VersionBinder: } \\bytes{3} \\ \\\\ &\\text{VersionClient: } \\bytes{3} \\ \\\\ &\\text{Contract: ContractAbi} \\ \\} \\\\ \\\\ \\text{<ContractAbi>} \\ := \\ \\{ \\ &\\text{StructTypes: List<StructTypeSpec>}, \\\\ &\\text{Hooks: List<FnAbi>}, \\\\ &\\text{StateType: TypeSpec} \\ \\} \\\\ \\\\ \\text{<StructTypeSpec>} \\ := \\ \\{ \\ &\\text{Name: Identifier}, \\\\ &\\text{Fields: List<FieldAbi>} \\ \\} \\\\ \\\\ \\text{<FnAbi>} \\ := \\ \\{ \\ &\\text{Kind: FnKind}, \\\\ &\\text{Name: Identifier}, \\\\ &\\text{Shortname: LEB128}, \\\\ &\\text{Arguments: List<ArgumentAbi>} \\ \\} \\\\ \\\\ \\text{<FieldAbi>} \\ := \\ \\{ \\ &\\text{Name: Identifier}, \\\\ &\\text{Type: TypeSpec} \\ \\} \\\\ \\\\ \\text{<ArgumentAbi>} \\ := \\ \\{ \\ &\\text{Name: Identifier}, \\\\ &\\text{Type: TypeSpec} \\ \\} \\\\ \\\\ \\text{<Identifier>} \\ := \\ \\phantom{\\{} \\ &\\text{len:}\\bytes{4} \\ \\text{utf8:}\\bytes{len} \\text{ utf8 must be Rust identifier, len is big endian} \\\\ \\\\ \\text{<LEB128>} \\ := \\ \\phantom{\\{} \\ &\\text{A LEB128 encoded unsigned 32 bit integer (1-5 bytes).} \\\\ \\\\ \\text{<FnKind>} \\ := \\ \\ &\\hexi{01} \\ \\Rightarrowx \\text{Init} &\\text{(Num allowed: 1)} \\\\ |\\ &\\hexi{02} \\ \\Rightarrowx \\text{Action} &\\text{(0..}\\infty\\text{)}\\\\ |\\ &\\hexi{03} \\ \\Rightarrowx \\text{Callback} &\\text{(0..}\\infty\\text{)}\\\\ |\\ &\\hexi{10} \\ \\Rightarrowx \\text{ZkSecretInput} &\\text{(0..}\\infty\\text{)}\\\\ |\\ &\\hexi{11} \\ \\Rightarrowx \\text{ZkVarInputted} &\\text{(0..1)}\\\\ |\\ &\\hexi{12} \\ \\Rightarrowx \\text{ZkVarRejected} &\\text{(0..1)}\\\\ |\\ &\\hexi{13} \\ \\Rightarrowx \\text{ZkComputeComplete} &\\text{(0..1)}\\\\ |\\ &\\hexi{14} \\ \\Rightarrowx \\text{ZkVarOpened} &\\text{(0..1)}\\\\ |\\ &\\hexi{15} \\ \\Rightarrowx \\text{ZkUserVarOpened} &\\text{(0..1)} \\end{align*} } \\] Note that a ContractAbi is only valid if the Hooks list contains a specific number of hooks of each type, as specified in FnKind .","title":"ABI File binary format"},{"location":"abiv_latest.html#wasm-contract-result-format","text":"The format used by Wasm contracts to return results is a section-based format defined as following: \\[ \\textcolor{mathcolor}{ \\begin{align*} \\text{<Result>} \\ := \\ & \\text{section}_0\\text{: Section} \\ \\dots \\ \\text{section}_n\\text{: Section} \\\\ \\text{<Section >} \\ := \\ & \\text{id:}\\byte{} \\ \\text{len:}\\bytes{4} \\ \\text{data:}\\bytes{len} \\ \\text{(len is big endian)} \\\\ \\end{align*} } \\] Note that section must occur in order of increasing ids. Two ids are \"well-known\" and specially handled by the interpreter: 0x01 : Stores event information. 0x02 : Stores state. Section ids 0x00 to 0x0F are reserved for \"well-known\" usage. All others are passed through the interpreter without modification.","title":"Wasm contract result format"},{"location":"accounts.html","text":"Accounts Create an account through the wallet extension or when you buy MPC tokens for staking on a node. Every account has an individual private key used for signing transactions, this key has a public counterpart called a public key. An PBC account holds the information necessary to enabling the user to perform transactions. This information includes: A unique identity called an address, it is derived from the public key The account balance of BYOC Balance of MPC Tokens An account nonce (number used only once), which is incremented when transactions are signed. The above attributes except the nonce resides in the account plugin. But the account state itself holds a single piece of information: The nonce. This is a number that is incremented each time a transaction signed by an account is executed. Accounts are used when sending transactions to any contract on the blockchain. Since the account nonce is part of the signature it can be used only once. This means that an account holder can only execute one transaction for each block.","title":"Accounts"},{"location":"accounts.html#accounts","text":"Create an account through the wallet extension or when you buy MPC tokens for staking on a node. Every account has an individual private key used for signing transactions, this key has a public counterpart called a public key. An PBC account holds the information necessary to enabling the user to perform transactions. This information includes: A unique identity called an address, it is derived from the public key The account balance of BYOC Balance of MPC Tokens An account nonce (number used only once), which is incremented when transactions are signed. The above attributes except the nonce resides in the account plugin. But the account state itself holds a single piece of information: The nonce. This is a number that is incremented each time a transaction signed by an account is executed. Accounts are used when sending transactions to any contract on the blockchain. Since the account nonce is part of the signature it can be used only once. This means that an account holder can only execute one transaction for each block.","title":"Accounts"},{"location":"block.html","text":"Block A block is the basic component of the blockchain ledger. Each block contains a batch of valid transactions and events that have been executed at a given block time . The block time is incremental. The chain is started with a genesis block that defines the initial state of the blockchain. Each block has a reference to its parent block thus forming a chain all the way back to the genesis block. A block is produced by a block producer. When a block is produced the transactions and events are executed and the resulting state is stored as the current state. The produced block is then validated by the committee according to the currently running consensus protocol .","title":"Blocks"},{"location":"block.html#block","text":"A block is the basic component of the blockchain ledger. Each block contains a batch of valid transactions and events that have been executed at a given block time . The block time is incremental. The chain is started with a genesis block that defines the initial state of the blockchain. Each block has a reference to its parent block thus forming a chain all the way back to the genesis block. A block is produced by a block producer. When a block is produced the transactions and events are executed and the resulting state is stored as the current state. The produced block is then validated by the committee according to the currently running consensus protocol .","title":"Block"},{"location":"byoc.html","text":"BYOC and Gas What is BYOC and gas BYOC means bring your own coin. The idea is that you can bring liquid cryptocurrencies onto PBC. A very small unit of BYOC is called gas. This is a term also used on other blockchains. Gas in the blockchain ecosystem is analogous with the fuel you need to get the machines moving. So to move something to the blockchain and change the state of things fuel is needed. To pay the gas costs of transactions you need to have some amount of BYOC in your account. The costs cover the payment of the node operators which are providing the services enabling the transactions to take place. How does it work To be able to spend and transfer your coins, twins are minted which can interact with the payment scheme of PBC. So, in essence you can deposit, withdraw and transfer Etherum or other cryptocurrencies with your PBC wallet. The first cryptocurrency you are able to use in the BYOC system at PBC is Ethereum. Soon you will also be able to use USDC. The cost for using the blockchain The initial conversion rate for gas and gas price for different services on the blockchain has been chosen to roughly match the following prices in USD. Network fee: 5 USD cents/kb. CPU fee: 5 USD cents per 1000 instructions. Storage fee: 1 USD cent/kb per year. NB. Future prices may be subject to market mechanisms. How to get started The easiest way to make a deposit of ETH s to use the PBC Token Bridge. Install the Partisa Wallet Extension . Make a Partisia Account with the wallet (or use the one you have already). You can use the Partisia Wallet to make additional accounts. Install Metamask app or extension . Make an Ethereum account, you can use Metamask to do it. Set the network in Metamask to Ethereum Mainnet in upper right corner. You can use Metamask to buy ETH. You can add funds with card or Apple Pay. Use the PBC Token bridge to transfer ETH from the Ethereum account into the PBC account. You get a confirmation as seen below if the deposit is successful. Your gas balance in the wallet should now be positive. This means that you can deploy or interact with smart contracts on the blockchain. Read more about smart contracts here .","title":"BYOC and gas"},{"location":"byoc.html#byoc-and-gas","text":"","title":"BYOC and Gas"},{"location":"byoc.html#what-is-byoc-and-gas","text":"BYOC means bring your own coin. The idea is that you can bring liquid cryptocurrencies onto PBC. A very small unit of BYOC is called gas. This is a term also used on other blockchains. Gas in the blockchain ecosystem is analogous with the fuel you need to get the machines moving. So to move something to the blockchain and change the state of things fuel is needed. To pay the gas costs of transactions you need to have some amount of BYOC in your account. The costs cover the payment of the node operators which are providing the services enabling the transactions to take place. How does it work To be able to spend and transfer your coins, twins are minted which can interact with the payment scheme of PBC. So, in essence you can deposit, withdraw and transfer Etherum or other cryptocurrencies with your PBC wallet. The first cryptocurrency you are able to use in the BYOC system at PBC is Ethereum. Soon you will also be able to use USDC.","title":"What is BYOC and gas"},{"location":"byoc.html#the-cost-for-using-the-blockchain","text":"The initial conversion rate for gas and gas price for different services on the blockchain has been chosen to roughly match the following prices in USD. Network fee: 5 USD cents/kb. CPU fee: 5 USD cents per 1000 instructions. Storage fee: 1 USD cent/kb per year. NB. Future prices may be subject to market mechanisms.","title":"The cost for using the blockchain"},{"location":"byoc.html#how-to-get-started","text":"The easiest way to make a deposit of ETH s to use the PBC Token Bridge. Install the Partisa Wallet Extension . Make a Partisia Account with the wallet (or use the one you have already). You can use the Partisia Wallet to make additional accounts. Install Metamask app or extension . Make an Ethereum account, you can use Metamask to do it. Set the network in Metamask to Ethereum Mainnet in upper right corner. You can use Metamask to buy ETH. You can add funds with card or Apple Pay. Use the PBC Token bridge to transfer ETH from the Ethereum account into the PBC account. You get a confirmation as seen below if the deposit is successful. Your gas balance in the wallet should now be positive. This means that you can deploy or interact with smart contracts on the blockchain. Read more about smart contracts here .","title":"How to get started"},{"location":"compile-sdk.html","text":"Contract compilation and deployment 1) Compile a contract example The token contract can be found in SDK archive: examples/rust-example-token-contract . The following will compile it and generate an ABI for it: cd examples/rust-example-token-contract cargo partisia-contract build --release Now you will find a .wasm-file in called token_contract.wasm in: /tmp/pbc-rust-wasm/examples/rust-example-token-contract/target/wasm32-unknown-unknown/release . If you look at lib.rs file in your IDE, you will see the contract utilizes several functions denoted with the initial fn . Three of these functions are actions that allow you to perform the basic operations needed for a transfer. The functions are initialize , mint , and transfer . After deployment, you can call the functions from the dashboard. When you perform an action it changes the contract state. If you inspect the contract you can see the serialized data showing the contract state. Contract state can be revealed as a .json . 2) Upload the contract to the blockchain To deploy a smart contract you need an account with gas to cover transaction costs. Open the wallet in the Dashboard or use Partisia Blockchain Explorer Select the token_contract.wasm and the token_contract.abi . In the total_supply field you put the number of tokens you want minted for total supply of the contract from the moment of deployment. The decimals field indicates placement of decimal point in total supply. E.g. total supply: 1050 decimals: 3 will mint supply of 1.050 token. After you send the contract to the chain a box appears below. You are provided with the following information fields Execution status , Hash , Invocation and Deployed at . Successful deployment will look like this: You are now ready to interact with the contract. Copy the address of deployment and paste it into the menu Interact Wasm Contract in the dashboard. Now you can mint and transfer your tokens. Congratulations! You have now created an active smart-contract on the Partisia Blockchain.","title":"Compile and deploy contracts"},{"location":"compile-sdk.html#contract-compilation-and-deployment","text":"","title":"Contract compilation and deployment"},{"location":"compile-sdk.html#1-compile-a-contract-example","text":"The token contract can be found in SDK archive: examples/rust-example-token-contract . The following will compile it and generate an ABI for it: cd examples/rust-example-token-contract cargo partisia-contract build --release Now you will find a .wasm-file in called token_contract.wasm in: /tmp/pbc-rust-wasm/examples/rust-example-token-contract/target/wasm32-unknown-unknown/release . If you look at lib.rs file in your IDE, you will see the contract utilizes several functions denoted with the initial fn . Three of these functions are actions that allow you to perform the basic operations needed for a transfer. The functions are initialize , mint , and transfer . After deployment, you can call the functions from the dashboard. When you perform an action it changes the contract state. If you inspect the contract you can see the serialized data showing the contract state. Contract state can be revealed as a .json .","title":"1) Compile a contract example"},{"location":"compile-sdk.html#2-upload-the-contract-to-the-blockchain","text":"To deploy a smart contract you need an account with gas to cover transaction costs. Open the wallet in the Dashboard or use Partisia Blockchain Explorer Select the token_contract.wasm and the token_contract.abi . In the total_supply field you put the number of tokens you want minted for total supply of the contract from the moment of deployment. The decimals field indicates placement of decimal point in total supply. E.g. total supply: 1050 decimals: 3 will mint supply of 1.050 token. After you send the contract to the chain a box appears below. You are provided with the following information fields Execution status , Hash , Invocation and Deployed at . Successful deployment will look like this: You are now ready to interact with the contract. Copy the address of deployment and paste it into the menu Interact Wasm Contract in the dashboard. Now you can mint and transfer your tokens. Congratulations! You have now created an active smart-contract on the Partisia Blockchain.","title":"2) Upload the contract to the blockchain"},{"location":"consensus.html","text":"The FastTrack consensus The FastTrack consensus protocol is an optimistic protocol with built-in failure recovery. When running optimistically a single block producer (proposer) continuously produces new blocks whilst the rest of the committee verify the validity of said blocks. After a fixed number of blocks have been proposed by a single producer a new proposer is chosen by the rules of the protocol. As long as the proposer is honest and produces what are by the committee deemed as valid blocks, transactions can be executed eagerly allowing for a high transaction throughput. If the proposer fails to produce valid blocks, either by losing network connectivity or malicious intent, the protocol enters what is called the Shutdown state . In this state the entire committee votes on which block is the newest. Once the committee has agreed on a block the next block proposer is chosen. To distinquish connectivity loss and a slow day on the chain, an empty heartbeat block is produced every 30 seconds if no transactions are received. Consensus is achieved using Proof-of-Justification (PoJ) and Proof-of-Finalization (PoF). PoJ is a list of 2/3 or more signatures confirming the validity of a block. This PoJ then becomes PoF for the previous block. Since the validity of the current block depends on the state of the previous, the previous block is considered final. This proof is indirect and therefore is not flooded. It can be derived by any node that has access to the chain state. Only Baker nodes run the ledger with a FastTrack plugin enabled and they communicate with the other Baker nodes for their specific shard. Since a separate consensus protocol runs for each available shard, cross-shard communication requires the propagation of the PoF from one shard to another. This effectively means that an event spawned on shard \\(A\\) at block time \\(t_A = i\\) is only valid when \\(i\\) is finalized, which is at \\(t_A = i + 1\\)","title":"Consensus Model"},{"location":"consensus.html#the-fasttrack-consensus","text":"The FastTrack consensus protocol is an optimistic protocol with built-in failure recovery. When running optimistically a single block producer (proposer) continuously produces new blocks whilst the rest of the committee verify the validity of said blocks. After a fixed number of blocks have been proposed by a single producer a new proposer is chosen by the rules of the protocol. As long as the proposer is honest and produces what are by the committee deemed as valid blocks, transactions can be executed eagerly allowing for a high transaction throughput. If the proposer fails to produce valid blocks, either by losing network connectivity or malicious intent, the protocol enters what is called the Shutdown state . In this state the entire committee votes on which block is the newest. Once the committee has agreed on a block the next block proposer is chosen. To distinquish connectivity loss and a slow day on the chain, an empty heartbeat block is produced every 30 seconds if no transactions are received. Consensus is achieved using Proof-of-Justification (PoJ) and Proof-of-Finalization (PoF). PoJ is a list of 2/3 or more signatures confirming the validity of a block. This PoJ then becomes PoF for the previous block. Since the validity of the current block depends on the state of the previous, the previous block is considered final. This proof is indirect and therefore is not flooded. It can be derived by any node that has access to the chain state. Only Baker nodes run the ledger with a FastTrack plugin enabled and they communicate with the other Baker nodes for their specific shard. Since a separate consensus protocol runs for each available shard, cross-shard communication requires the propagation of the PoF from one shard to another. This effectively means that an event spawned on shard \\(A\\) at block time \\(t_A = i\\) is only valid when \\(i\\) is finalized, which is at \\(t_A = i + 1\\)","title":"The FastTrack consensus"},{"location":"contract-development.html","text":"What is a smart contract? Creating a smart contract is one of the basic ways you can utilize the Partisia Blockchain. A smart contract is a program you run on the blockchain. The conditions of the contract are present across the blockchain. This ensures that actions of the smart contract will happen only once, are trackable and irreversible. In this way a smart contract works independently, without any need for outside authority to facilitate the change in state. So, you do not need a bank or a lawyer to set up a binding agreement anymore, since you have ultimate control over the conditions necessary to make the change happen. Smart contracts are the tool for you if you need to buy, sell, facilitate auctions or administrate portfolios of diverse assets. Why should you use the Partisia Blockchain for your smart contracts? What makes the smart contract on Partisia Blockchain different from contracts on other blockchains is that we allow you to add a privacy layer parallel with the immutable ledger. This means that you through your contract will allocate nodes in the blockchain to handle Zero Knowledge computation. If you for example want to make an auction, you can keep the identity of the current bidder and account information secret and off the record, while the identity of the winner and seller will be added to the immutable record. This will secure a record of change in ownership while at the same time preserving the privacy of all interested parties that don\u2019t give the winning bid. This principle of a combination of a privacy layer and a public record means that the Patisia Blockchain effectively can replace the trustee in binding transactions. The different contract types and their life on the blockchain There are three types of smart contracts on PBC: System smart contracts: The permanent contracts maintaining the PBC Ecosystem, they are involved in the deployment and eventual destruction of the public and private smart contracts as well as a larger number of other essential duties, such as block producer orchestration, preprocessing of data for zero knowledge contracts and changes to procedures on the chain. Public smart contracts: Public smart contracts are written in the PBC contract language which is based on Rust. A contract has a state which include the variables subject to change. When a user deploys a contract it is sent as a WASM file to a system contract which check the content for type and format validity. Then the public contract is initialized. It is now deployed on the chain and the state of the contract can be changed by the available actions made stipulated in the contract. Actions cannot only change the state of their own contract, but also affect the actions and state of other public smart contracts. An action of a contract affecting an action in another contract is called an interaction (also referred to as event transaction). The transactions constituting the deployment and actions of a contract has a gas cost . A public smart contract will be destroyed by a system contract when it hits the expiration date set by the contract creator or if it runs out of gas. You can see the life stages below. Private smart contracts: Are just like public smart contracts except that the contract stipulates some actions of the contract taking place on the special private layer of the PBC. These actions are zero knowledge computations. Famously PBC supports secure multiparty computation called MPC giving name to the blockcain's native token.","title":"What is a smart contract"},{"location":"contract-development.html#what-is-a-smart-contract","text":"Creating a smart contract is one of the basic ways you can utilize the Partisia Blockchain. A smart contract is a program you run on the blockchain. The conditions of the contract are present across the blockchain. This ensures that actions of the smart contract will happen only once, are trackable and irreversible. In this way a smart contract works independently, without any need for outside authority to facilitate the change in state. So, you do not need a bank or a lawyer to set up a binding agreement anymore, since you have ultimate control over the conditions necessary to make the change happen. Smart contracts are the tool for you if you need to buy, sell, facilitate auctions or administrate portfolios of diverse assets.","title":"What is a smart contract?"},{"location":"contract-development.html#why-should-you-use-the-partisia-blockchain-for-your-smart-contracts","text":"What makes the smart contract on Partisia Blockchain different from contracts on other blockchains is that we allow you to add a privacy layer parallel with the immutable ledger. This means that you through your contract will allocate nodes in the blockchain to handle Zero Knowledge computation. If you for example want to make an auction, you can keep the identity of the current bidder and account information secret and off the record, while the identity of the winner and seller will be added to the immutable record. This will secure a record of change in ownership while at the same time preserving the privacy of all interested parties that don\u2019t give the winning bid. This principle of a combination of a privacy layer and a public record means that the Patisia Blockchain effectively can replace the trustee in binding transactions.","title":"Why should you use the Partisia Blockchain for your smart contracts?"},{"location":"contract-development.html#the-different-contract-types-and-their-life-on-the-blockchain","text":"There are three types of smart contracts on PBC: System smart contracts: The permanent contracts maintaining the PBC Ecosystem, they are involved in the deployment and eventual destruction of the public and private smart contracts as well as a larger number of other essential duties, such as block producer orchestration, preprocessing of data for zero knowledge contracts and changes to procedures on the chain. Public smart contracts: Public smart contracts are written in the PBC contract language which is based on Rust. A contract has a state which include the variables subject to change. When a user deploys a contract it is sent as a WASM file to a system contract which check the content for type and format validity. Then the public contract is initialized. It is now deployed on the chain and the state of the contract can be changed by the available actions made stipulated in the contract. Actions cannot only change the state of their own contract, but also affect the actions and state of other public smart contracts. An action of a contract affecting an action in another contract is called an interaction (also referred to as event transaction). The transactions constituting the deployment and actions of a contract has a gas cost . A public smart contract will be destroyed by a system contract when it hits the expiration date set by the contract creator or if it runs out of gas. You can see the life stages below. Private smart contracts: Are just like public smart contracts except that the contract stipulates some actions of the contract taking place on the special private layer of the PBC. These actions are zero knowledge computations. Famously PBC supports secure multiparty computation called MPC giving name to the blockcain's native token.","title":"The different contract types and their life on the blockchain"},{"location":"download-sdk.html","text":"Download the software development kit 1) Install Rust To develop and compile contracts for the Partisia Blockchain, you need to install Rust along with the wasm32 target. To install Rust for you platform follow the instructions on https://rustup.rs/ . Now add the wasm32 target: rustup update rustup target add wasm32-unknown-unknown If Working from a Windows machine you must either: Get Visual Studio with C++ build tools - In Visual Studio Installer choose Desktop development with C++ . Install Linux Subsystem for Windows 2) Download Partisia Contract SDK The archive contains the Rust project files and the SDK. The archive contains the partisia-contract tool, the SDK and some example contracts. If you are working with a WSL shell on Windows you can locate files within WSL in the folder named \\\\wsl$\\Ubuntu\\ . From now on we assume you have extracted the archive to /tmp/pbc-rust-wasm . Open a terminal and go to the /tmp/pbc-rust-wasm folder: cd /tmp/pbc-rust-wasm . 3) Install the cargo partisia-contract command cd cargo-partisia-contract cargo install --path . Test that it worked by executing: cargo partisia-contract --version . This should print the version of the command.","title":"Download SDK for contract development"},{"location":"download-sdk.html#download-the-software-development-kit","text":"","title":"Download the software development kit"},{"location":"download-sdk.html#1-install-rust","text":"To develop and compile contracts for the Partisia Blockchain, you need to install Rust along with the wasm32 target. To install Rust for you platform follow the instructions on https://rustup.rs/ . Now add the wasm32 target: rustup update rustup target add wasm32-unknown-unknown If Working from a Windows machine you must either: Get Visual Studio with C++ build tools - In Visual Studio Installer choose Desktop development with C++ . Install Linux Subsystem for Windows","title":"1) Install Rust"},{"location":"download-sdk.html#2-download-partisia-contract-sdk","text":"The archive contains the Rust project files and the SDK. The archive contains the partisia-contract tool, the SDK and some example contracts. If you are working with a WSL shell on Windows you can locate files within WSL in the folder named \\\\wsl$\\Ubuntu\\ . From now on we assume you have extracted the archive to /tmp/pbc-rust-wasm . Open a terminal and go to the /tmp/pbc-rust-wasm folder: cd /tmp/pbc-rust-wasm .","title":"2) Download Partisia Contract SDK"},{"location":"download-sdk.html#3-install-the-cargo-partisia-contract-command","text":"cd cargo-partisia-contract cargo install --path . Test that it worked by executing: cargo partisia-contract --version . This should print the version of the command.","title":"3) Install the cargo partisia-contract command"},{"location":"events.html","text":"Event transactions An event transaction is a special type of transaction that is spawned during the execution of another transaction. Events are used to communicate across different contracts and/or shards. Events have the same basic properties as ordinary transactions. Events are sent through the flooding network and have the same validity rules as ordinary transactions. When a transaction is executed the network and CPU fees are collected, the rest of the cost is distributed evenly between any events said transaction spawns. Events are executed the same way as ordinary transactions meaning they can also spawn events. This means one can implement asynchronous, indefinite recursion which will eventually terminate since the events will run out of gas to pay the fees. Event transactions are instrumental in enabling cross-shard transactions since they can be routed by the blockchain to their respective destination shard. A routed event transaction is enriched with a finalization proof and routed based on the routing table in the chain state. For more details see Shards .","title":"Event transactions"},{"location":"events.html#event-transactions","text":"An event transaction is a special type of transaction that is spawned during the execution of another transaction. Events are used to communicate across different contracts and/or shards. Events have the same basic properties as ordinary transactions. Events are sent through the flooding network and have the same validity rules as ordinary transactions. When a transaction is executed the network and CPU fees are collected, the rest of the cost is distributed evenly between any events said transaction spawns. Events are executed the same way as ordinary transactions meaning they can also spawn events. This means one can implement asynchronous, indefinite recursion which will eventually terminate since the events will run out of gas to pay the fees. Event transactions are instrumental in enabling cross-shard transactions since they can be routed by the blockchain to their respective destination shard. A routed event transaction is enriched with a finalization proof and routed based on the routing table in the chain state. For more details see Shards .","title":"Event transactions"},{"location":"introduction.html","text":"Introduction to the Partisia Blockchain Ecosystem Below is a small introduction to the some of the core concepts of blockchains and an explanation of what make PBC different from other blockchains. What is a blockchain Blockchains are a means to make an immutable record of transactions on a decentralized database. This makes blockchains a useful place to record important information e.g. of a financial, medical or legal nature. A blockchain is a public database where any update is added sequentially. Since all information is time stamped. You can add information in the present, but you cannot edit past information. In this way a blockchain creates an immutable ledger. The name blockchain means that information added to the ledger comes in discrete bundles called blocks. A block points to the block before it. That way a chain is created that connects the changes on the ledger from the beginning to the present. The blocks are connected cryptographically. The hash of each block is produced as a function of the hash of the transactions and the hash of the previous block. A blockchain exists on a distributed network of computers called nodes . Changes to the database happens to all the computers on the network through a secure consensus mechanism . In a traditional centralized database you just need to hack or compromise one computer and the integrety of all content on that database would be in jeopardy. Conversely, a blockchain is a decentralized database. Therefore, data on the blockchain remains secure even if a computer in the network is hacked, short circuits or loose connection to the internet. What happens when I use a blockchain In the following paragraph we will examine user interactions with the blockchain using a purchase of an NFT as our case example. We will explore how a user action like purchase of NFTs affect the blockchain on different levels. On the surface level your phone or computer is connected to the internet. Apps and webpages can get you in contact with the blockchain through the internet just like using any other online service like e-mail. The Partisia blockchain lives on a network of computers connected to each other through the internet. The blockchain comes with a software architecture which allows for binding trackable transactions to happen very fast. A puchase of an NFT is a transaction on the blockchain. Specifically it is an action of an active smart contract . Smart contracts hold some information which can be changed, that information is called the state. The state of our NFT contract holds an inventory of NFTs and their owners. The contract action Transfer can change the ownership of an NFT by changing an owner address in the inventory. Actions of contracts are themselves transactions on the blockchain. When they have been added to a block and executed, the resulting state change of the contract becomes part of the blockchain state. We now have a permanent timestamped record of the purchase. What is special about Partisia Blockchain? - A privacy preserving blockchain The advantages of a public blockchain comes with a trade-off. The fact that everything that happens on the public blockchain is added to a permanent record limits the scope of their use. You can only use a public ledger for things you want everyone to know. Imagine you want to make use of the public blockchain to prevent voter fraud in a general election. The public blockchain can give you a transparent election without fraud, but the price will be compromising the privacy of the voters. Partisia Blockchain comes with an extra privacy layer. This allows for zero knowledge computations to happen in parallel with the activities on the public blockchain. For our example that would mean that PBC could provide an election without the possibility of voter fraud and at the same time keep all votes secret. This way PBC expands the scope of use for a blockchain into much broader domains. For zero knowledge computation to happen simultaneous with the public activities on the blockchain it is necessary to allocate part of the nodes of the network to focus on these tasks. To increase security of these services even further nodes that partake in them are selected through an economic staking model. This means that the owners of the computers handling the sensitive data has a common interest with the users of Partisia Blockchain to protect the data and preserve their privacy. Find out more What is a node operator? How does the economy of PBC work? What is a smart contract? How can I add zero knowledge computation to a smart contract?","title":"Introduction to the Partisia Blockchain Ecosystem"},{"location":"introduction.html#introduction-to-the-partisia-blockchain-ecosystem","text":"Below is a small introduction to the some of the core concepts of blockchains and an explanation of what make PBC different from other blockchains.","title":"Introduction to the Partisia Blockchain Ecosystem"},{"location":"introduction.html#what-is-a-blockchain","text":"Blockchains are a means to make an immutable record of transactions on a decentralized database. This makes blockchains a useful place to record important information e.g. of a financial, medical or legal nature. A blockchain is a public database where any update is added sequentially. Since all information is time stamped. You can add information in the present, but you cannot edit past information. In this way a blockchain creates an immutable ledger. The name blockchain means that information added to the ledger comes in discrete bundles called blocks. A block points to the block before it. That way a chain is created that connects the changes on the ledger from the beginning to the present. The blocks are connected cryptographically. The hash of each block is produced as a function of the hash of the transactions and the hash of the previous block. A blockchain exists on a distributed network of computers called nodes . Changes to the database happens to all the computers on the network through a secure consensus mechanism . In a traditional centralized database you just need to hack or compromise one computer and the integrety of all content on that database would be in jeopardy. Conversely, a blockchain is a decentralized database. Therefore, data on the blockchain remains secure even if a computer in the network is hacked, short circuits or loose connection to the internet.","title":"What is a blockchain"},{"location":"introduction.html#what-happens-when-i-use-a-blockchain","text":"In the following paragraph we will examine user interactions with the blockchain using a purchase of an NFT as our case example. We will explore how a user action like purchase of NFTs affect the blockchain on different levels. On the surface level your phone or computer is connected to the internet. Apps and webpages can get you in contact with the blockchain through the internet just like using any other online service like e-mail. The Partisia blockchain lives on a network of computers connected to each other through the internet. The blockchain comes with a software architecture which allows for binding trackable transactions to happen very fast. A puchase of an NFT is a transaction on the blockchain. Specifically it is an action of an active smart contract . Smart contracts hold some information which can be changed, that information is called the state. The state of our NFT contract holds an inventory of NFTs and their owners. The contract action Transfer can change the ownership of an NFT by changing an owner address in the inventory. Actions of contracts are themselves transactions on the blockchain. When they have been added to a block and executed, the resulting state change of the contract becomes part of the blockchain state. We now have a permanent timestamped record of the purchase.","title":"What happens when I use a blockchain"},{"location":"introduction.html#what-is-special-about-partisia-blockchain-a-privacy-preserving-blockchain","text":"The advantages of a public blockchain comes with a trade-off. The fact that everything that happens on the public blockchain is added to a permanent record limits the scope of their use. You can only use a public ledger for things you want everyone to know. Imagine you want to make use of the public blockchain to prevent voter fraud in a general election. The public blockchain can give you a transparent election without fraud, but the price will be compromising the privacy of the voters. Partisia Blockchain comes with an extra privacy layer. This allows for zero knowledge computations to happen in parallel with the activities on the public blockchain. For our example that would mean that PBC could provide an election without the possibility of voter fraud and at the same time keep all votes secret. This way PBC expands the scope of use for a blockchain into much broader domains. For zero knowledge computation to happen simultaneous with the public activities on the blockchain it is necessary to allocate part of the nodes of the network to focus on these tasks. To increase security of these services even further nodes that partake in them are selected through an economic staking model. This means that the owners of the computers handling the sensitive data has a common interest with the users of Partisia Blockchain to protect the data and preserve their privacy.","title":"What is special about Partisia Blockchain? - A privacy preserving blockchain"},{"location":"introduction.html#find-out-more","text":"What is a node operator? How does the economy of PBC work? What is a smart contract? How can I add zero knowledge computation to a smart contract?","title":"Find out more"},{"location":"keys.html","text":"Public-key cryptography Public-key cryptography is a form of cryptography that uses pairs of keys: A public key that may be shared with anyone and a private key that must be kept secret. The public and private keys are generated in mathematically connected pairs. The public key can be used to encrypt a message that can be decrypted by the private key, meaning that anyone can send an encrypted message to any recipient assuming they know their public key. PBC uses elliptic curve cryptography, specifically the curve secp256k1 .","title":"Public key cryptography"},{"location":"keys.html#public-key-cryptography","text":"Public-key cryptography is a form of cryptography that uses pairs of keys: A public key that may be shared with anyone and a private key that must be kept secret. The public and private keys are generated in mathematically connected pairs. The public key can be used to encrypt a message that can be decrypted by the private key, meaning that anyone can send an encrypted message to any recipient assuming they know their public key. PBC uses elliptic curve cryptography, specifically the curve secp256k1 .","title":"Public-key cryptography"},{"location":"mpc-tokens.html","text":"What are MPC tokens MPC is the name used for the PBC native token. MPC tokens are used for staking on a Node. Functions of MPC tokens: A stake of MPC tokens works as the entry ticket to becoming a node operator and allows them to take fees for services. The staking requirements for different tasks can be read here . The staked MPC tokens provide an additional guaranty. Since the stake can be used to pay compensation for misconduct committed by a node operator. The staked MPC tokens create an incentive structure that align the user's security interest with the financial interests of the node operators who facilitate the transactions on the network. MPC as secure multiparty computation On the PBC platform MPC may refer to two different things. MPC is an acronym for secure multiparty computation. Secure multiparty computation (MPC) is the technological speciality of Partisia Blockchain. One could argue that the main technology which seperates Partisia Blockchain from other blockchains is contracts with zero knowledge computations not least MPC. So, instead of naming the tokens after the platform they are named after the most significant technology on the platform.","title":"MPC tokens"},{"location":"mpc-tokens.html#what-are-mpc-tokens","text":"MPC is the name used for the PBC native token. MPC tokens are used for staking on a Node. Functions of MPC tokens: A stake of MPC tokens works as the entry ticket to becoming a node operator and allows them to take fees for services. The staking requirements for different tasks can be read here . The staked MPC tokens provide an additional guaranty. Since the stake can be used to pay compensation for misconduct committed by a node operator. The staked MPC tokens create an incentive structure that align the user's security interest with the financial interests of the node operators who facilitate the transactions on the network.","title":"What are MPC tokens"},{"location":"mpc-tokens.html#mpc-as-secure-multiparty-computation","text":"On the PBC platform MPC may refer to two different things. MPC is an acronym for secure multiparty computation. Secure multiparty computation (MPC) is the technological speciality of Partisia Blockchain. One could argue that the main technology which seperates Partisia Blockchain from other blockchains is contracts with zero knowledge computations not least MPC. So, instead of naming the tokens after the platform they are named after the most significant technology on the platform.","title":"MPC as secure multiparty computation"},{"location":"mpc1155actions.html","text":"Actions \u200b set_uri Set uri for the tokens. \u200b Params: Se t UriMsg { \"new_uri\" : \"<uri>\" , } \u200b mint Mint a new token. Can only be executed by minter account. \u200b Params: Mi nt Msg { \"to\" : \"<address>\" , \"token_info\" : { \"token_id\" : 1 , \"amount\" : 1 , \"token_uri\" : \"<token-uri>\" , } } \u200b batch_mint Batch mint a new token. Can only be executed by minter account. \u200b Params: Ba t chMi nt Msg { \"to\" : \"<address>\" , \"token_infos\" : [ { \"token_id\" : 1 , \"amount\" : 1 , \"token_uri\" : \"<token-uri>\" , } ] } \u200b transfer_from Only with approval extension. Transfer token from owner to spender. \u200b Params: Tra nsfer FromMsg { \"from\" : \"<address>\" , \"to\" : \"<address>\" , \"token_info\" : { \"token_id\" : 1 , \"amount\" : 1 , }, } \u200b batch_transfer_from Only with approval extension. Batch transfer token from owner to spender. \u200b Params: Ba t chTra nsfer FromMsg { \"from\" : \"<address>\" , \"to\" : \"<address>\" , \"token_infos\" : [ { \"token_id\" : 1 , \"amount\" : 1 , } ], } \u200b burn Destroy your token forever. \u200b Params: Bur n Msg { \"from\" : \"<address>\" , \"token_info\" : { \"token_id\" : 1 , \"amount\" : 1 , }, } \u200b batch_burn Batch destroy your token forever. \u200b Params: Ba t chBur n Msg { \"from\" : \"<address>\" , \"token_infos\" : [ { \"token_id\" : 1 , \"amount\" : 1 , } ], } \u200b approve_for_all Allows operator to transfer any owner tokens from his account. \u200b Params: ApproveForAllMsg { \"operator\" : \"<address>\" , } \u200b revoke_for_all Remove operator. \u200b Params: RevokeForAllMsg { \"operator\" : \"<address>\" , }","title":"Actions"},{"location":"mpc1155actions.html#actions","text":"\u200b","title":"Actions"},{"location":"mpc1155actions.html#set_uri","text":"Set uri for the tokens. \u200b Params: Se t UriMsg { \"new_uri\" : \"<uri>\" , } \u200b","title":"set_uri"},{"location":"mpc1155actions.html#mint","text":"Mint a new token. Can only be executed by minter account. \u200b Params: Mi nt Msg { \"to\" : \"<address>\" , \"token_info\" : { \"token_id\" : 1 , \"amount\" : 1 , \"token_uri\" : \"<token-uri>\" , } } \u200b","title":"mint"},{"location":"mpc1155actions.html#batch_mint","text":"Batch mint a new token. Can only be executed by minter account. \u200b Params: Ba t chMi nt Msg { \"to\" : \"<address>\" , \"token_infos\" : [ { \"token_id\" : 1 , \"amount\" : 1 , \"token_uri\" : \"<token-uri>\" , } ] } \u200b","title":"batch_mint"},{"location":"mpc1155actions.html#transfer_from","text":"Only with approval extension. Transfer token from owner to spender. \u200b Params: Tra nsfer FromMsg { \"from\" : \"<address>\" , \"to\" : \"<address>\" , \"token_info\" : { \"token_id\" : 1 , \"amount\" : 1 , }, } \u200b","title":"transfer_from"},{"location":"mpc1155actions.html#batch_transfer_from","text":"Only with approval extension. Batch transfer token from owner to spender. \u200b Params: Ba t chTra nsfer FromMsg { \"from\" : \"<address>\" , \"to\" : \"<address>\" , \"token_infos\" : [ { \"token_id\" : 1 , \"amount\" : 1 , } ], } \u200b","title":"batch_transfer_from"},{"location":"mpc1155actions.html#burn","text":"Destroy your token forever. \u200b Params: Bur n Msg { \"from\" : \"<address>\" , \"token_info\" : { \"token_id\" : 1 , \"amount\" : 1 , }, } \u200b","title":"burn"},{"location":"mpc1155actions.html#batch_burn","text":"Batch destroy your token forever. \u200b Params: Ba t chBur n Msg { \"from\" : \"<address>\" , \"token_infos\" : [ { \"token_id\" : 1 , \"amount\" : 1 , } ], } \u200b","title":"batch_burn"},{"location":"mpc1155actions.html#approve_for_all","text":"Allows operator to transfer any owner tokens from his account. \u200b Params: ApproveForAllMsg { \"operator\" : \"<address>\" , } \u200b","title":"approve_for_all"},{"location":"mpc1155actions.html#revoke_for_all","text":"Remove operator. \u200b Params: RevokeForAllMsg { \"operator\" : \"<address>\" , }","title":"revoke_for_all"},{"location":"mpc20stakingactions.html","text":"\u200b# Actions \u200b stake Stake specified amount of tokens to earn rewards. \u200b Pararms: S ta keMsg { amou nt : 10 , } \u200b unstake Withdraw staked tokens. \u200b Pararms: U nsta keMsg { amou nt : 11 , } \u200b claim Claim earned rewards. \u200b Pararms: ClaimMsg { amou nt : 10 | null } \u200b compound Compound earned rewards(e.g. stake them). Only works when deposit token is reward token. \u200b Pararms: Compou n dMsg { amou nt : 10 | null } \u200b MPC20 Base actions","title":"Actions"},{"location":"mpc20stakingactions.html#stake","text":"Stake specified amount of tokens to earn rewards. \u200b Pararms: S ta keMsg { amou nt : 10 , } \u200b","title":"stake"},{"location":"mpc20stakingactions.html#unstake","text":"Withdraw staked tokens. \u200b Pararms: U nsta keMsg { amou nt : 11 , } \u200b","title":"unstake"},{"location":"mpc20stakingactions.html#claim","text":"Claim earned rewards. \u200b Pararms: ClaimMsg { amou nt : 10 | null } \u200b","title":"claim"},{"location":"mpc20stakingactions.html#compound","text":"Compound earned rewards(e.g. stake them). Only works when deposit token is reward token. \u200b Pararms: Compou n dMsg { amou nt : 10 | null } \u200b","title":"compound"},{"location":"mpc20stakingactions.html#mpc20-base-actions","text":"","title":"MPC20 Base actions"},{"location":"mpc721actions.html","text":"Actions \u200b\u200b set_base_uri Set base uri for the tokens. \u200b Params: Se t BaseUriMsg { \"new_base_uri\" : \"<uri>\" , } \u200b mint Mint a new token. Can only be executed by minter account. \u200b Params: Mi nt Msg { \"token_id\" : 1 , \"to\" : \"<address>\" , \"token_uri\" : \"<optional uri>\" , } \u200b transfer Transfer token to another account. \u200b Params: Tra nsfer Msg { \"to\" : \"<address>\" , \"token_id\" : 1 , } \u200b transfer_from Only with approval extension. Transfer token from owner to spender. \u200b Params: Tra nsfer FromMsg { \"from\" : \"<address>\" , \"to\" : \"<address>\" , \"token_id\" : 1 , } \u200b approve Allows spender to transfer token from the owner account. \u200b Params: ApproveMsg { \"spedner\" : \"<address>\" , \"token_id\" : 1 , } \u200b approve_for_all Allows operator to transfer any owner tokens from his account. \u200b Params: ApproveForAllMsg { \"operator\" : \"<address>\" , } \u200b revoke Remove approval. \u200b Params: RevokeMsg { \"spedner\" : \"<address>\" , \"token_id\" : 1 , } \u200b revoke_for_all Remove operator. \u200b Params: RevokeForAllMsg { \"operator\" : \"<address>\" , } \u200b burn Destroy your token forever. \u200b Params: Bur n Msg { \"token_id\" : 1 , }","title":"Actions"},{"location":"mpc721actions.html#actions","text":"\u200b\u200b","title":"Actions"},{"location":"mpc721actions.html#set_base_uri","text":"Set base uri for the tokens. \u200b Params: Se t BaseUriMsg { \"new_base_uri\" : \"<uri>\" , } \u200b","title":"set_base_uri"},{"location":"mpc721actions.html#mint","text":"Mint a new token. Can only be executed by minter account. \u200b Params: Mi nt Msg { \"token_id\" : 1 , \"to\" : \"<address>\" , \"token_uri\" : \"<optional uri>\" , } \u200b","title":"mint"},{"location":"mpc721actions.html#transfer","text":"Transfer token to another account. \u200b Params: Tra nsfer Msg { \"to\" : \"<address>\" , \"token_id\" : 1 , } \u200b","title":"transfer"},{"location":"mpc721actions.html#transfer_from","text":"Only with approval extension. Transfer token from owner to spender. \u200b Params: Tra nsfer FromMsg { \"from\" : \"<address>\" , \"to\" : \"<address>\" , \"token_id\" : 1 , } \u200b","title":"transfer_from"},{"location":"mpc721actions.html#approve","text":"Allows spender to transfer token from the owner account. \u200b Params: ApproveMsg { \"spedner\" : \"<address>\" , \"token_id\" : 1 , } \u200b","title":"approve"},{"location":"mpc721actions.html#approve_for_all","text":"Allows operator to transfer any owner tokens from his account. \u200b Params: ApproveForAllMsg { \"operator\" : \"<address>\" , } \u200b","title":"approve_for_all"},{"location":"mpc721actions.html#revoke","text":"Remove approval. \u200b Params: RevokeMsg { \"spedner\" : \"<address>\" , \"token_id\" : 1 , } \u200b","title":"revoke"},{"location":"mpc721actions.html#revoke_for_all","text":"Remove operator. \u200b Params: RevokeForAllMsg { \"operator\" : \"<address>\" , } \u200b","title":"revoke_for_all"},{"location":"mpc721actions.html#burn","text":"Destroy your token forever. \u200b Params: Bur n Msg { \"token_id\" : 1 , }","title":"burn"},{"location":"mpcactions.html","text":"Actions \u200b mint Mint specified amount of tokens to provided address. Only works when minter option is enabled \u200b Pararms: Mi nt Msg { \"recipient\" : \"<address>\" , \"amount\" : 123 } \u200b transfer Moves amount tokens from the msg sender account to specified to account. \u200b Params: Tra nsfer Msg { \"to\" : \"<address>\" , \"amount\" : 123 } \u200b transfer_from Only with approval extension. Transfers amount tokens from owner -> recipient if sender has sufficient pre-approval. \u200b Params: Tra nsfer FromMsg { \"owner\" : \"<address>\" , \"to\" : \"<address>\" , \"amount\" : 123 } \u200b burn Burn is a method to destroy your tokens forever. \u200b Params: Bur n Msg { \"amount\" : 123 } \u200b burn_from Only with approval extension. Destroys your tokens forever. \u200b Params: Bur n FromMsg { \"owner\" : \"<address>\" , \"amount\" : 123 } \u200b approve Sets amount as the allowance of spender over the caller's tokens. \u200b Params: ApproveMsg { \"spender\" : \"<address>\" , \"amount\" : 123 } \u200b increase_allowance Allows spender to access an additional amount tokens from the owner's account. \u200b Params: I n creaseAllowa n ceMsg { \"spender\" : \"<address>\" , \"amount\" : 123 } \u200b decrease_allowance Lowers the spender's access of tokens from the owner's account by amount. \u200b Params: DecreaseAllowa n ceMsg { \"spender\" : \"<address>\" , \"amount\" : 123 }","title":"Actions"},{"location":"mpcactions.html#actions","text":"\u200b","title":"Actions"},{"location":"mpcactions.html#mint","text":"Mint specified amount of tokens to provided address. Only works when minter option is enabled \u200b Pararms: Mi nt Msg { \"recipient\" : \"<address>\" , \"amount\" : 123 } \u200b","title":"mint"},{"location":"mpcactions.html#transfer","text":"Moves amount tokens from the msg sender account to specified to account. \u200b Params: Tra nsfer Msg { \"to\" : \"<address>\" , \"amount\" : 123 } \u200b","title":"transfer"},{"location":"mpcactions.html#transfer_from","text":"Only with approval extension. Transfers amount tokens from owner -> recipient if sender has sufficient pre-approval. \u200b Params: Tra nsfer FromMsg { \"owner\" : \"<address>\" , \"to\" : \"<address>\" , \"amount\" : 123 } \u200b","title":"transfer_from"},{"location":"mpcactions.html#burn","text":"Burn is a method to destroy your tokens forever. \u200b Params: Bur n Msg { \"amount\" : 123 } \u200b","title":"burn"},{"location":"mpcactions.html#burn_from","text":"Only with approval extension. Destroys your tokens forever. \u200b Params: Bur n FromMsg { \"owner\" : \"<address>\" , \"amount\" : 123 } \u200b","title":"burn_from"},{"location":"mpcactions.html#approve","text":"Sets amount as the allowance of spender over the caller's tokens. \u200b Params: ApproveMsg { \"spender\" : \"<address>\" , \"amount\" : 123 } \u200b","title":"approve"},{"location":"mpcactions.html#increase_allowance","text":"Allows spender to access an additional amount tokens from the owner's account. \u200b Params: I n creaseAllowa n ceMsg { \"spender\" : \"<address>\" , \"amount\" : 123 } \u200b","title":"increase_allowance"},{"location":"mpcactions.html#decrease_allowance","text":"Lowers the spender's access of tokens from the owner's account by amount. \u200b Params: DecreaseAllowa n ceMsg { \"spender\" : \"<address>\" , \"amount\" : 123 }","title":"decrease_allowance"},{"location":"operator-0-introduction.html","text":"Run a node on Partisia Blockchain This guide has 9 parts. If you do the steps of the guide in order, you should know how to set up your node correctly, before you commit your stake. In other words, you can find out if you have the skills and patience for running a block producing node, before you tie your stake to the performance of the node. Hardware and software for running the node Run a reader node locally Get a VPS Secure your VPS Run a reader node on a VPS Create keys for config and registration Run a block producing node on the VPS Register your node Node health and maintenance","title":"Run a node - Introduction and index"},{"location":"operator-0-introduction.html#run-a-node-on-partisia-blockchain","text":"This guide has 9 parts. If you do the steps of the guide in order, you should know how to set up your node correctly, before you commit your stake. In other words, you can find out if you have the skills and patience for running a block producing node, before you tie your stake to the performance of the node. Hardware and software for running the node Run a reader node locally Get a VPS Secure your VPS Run a reader node on a VPS Create keys for config and registration Run a block producing node on the VPS Register your node Node health and maintenance","title":"Run a node on Partisia Blockchain"},{"location":"operator-1-specs.html","text":"Run a node Part 1 - Recommended hardware, software and access to Git repository Recommended machine specs 8 vCPU or 8 cores 10 GB RAM (8 GB allocated JVM, 4 GB is absolute minimum) 40 GB SSD Publicly accessible IP with ports 9888 to 9897 open Recommended software Docker Docker Compose Linux (In this tutorial Ubuntu 20.04.3 was used) A text editor (In this tutorial nano 4.3 was used) Access to Gitlab Repository Send your e-mail address to @Kristian Hu#7382 in a direct message on the Partisia Blockchain Discord Server for access to Partisia's Gitlab Repository (Will soon be open source). If you are not already a member on the Partisia Discord Server click here .","title":"Run a node 1 - Specs"},{"location":"operator-1-specs.html#run-a-node-part-1-recommended-hardware-software-and-access-to-git-repository","text":"","title":"Run a node Part 1 - Recommended hardware, software and access to Git repository"},{"location":"operator-1-specs.html#recommended-machine-specs","text":"8 vCPU or 8 cores 10 GB RAM (8 GB allocated JVM, 4 GB is absolute minimum) 40 GB SSD Publicly accessible IP with ports 9888 to 9897 open","title":"Recommended machine specs"},{"location":"operator-1-specs.html#recommended-software","text":"Docker Docker Compose Linux (In this tutorial Ubuntu 20.04.3 was used) A text editor (In this tutorial nano 4.3 was used)","title":"Recommended software"},{"location":"operator-1-specs.html#access-to-gitlab-repository","text":"Send your e-mail address to @Kristian Hu#7382 in a direct message on the Partisia Blockchain Discord Server for access to Partisia's Gitlab Repository (Will soon be open source). If you are not already a member on the Partisia Discord Server click here .","title":"Access to Gitlab Repository"},{"location":"operator-2-reader.html","text":"Run a reader node on your local machine Step 1 - Creating the folders First we need to create the conf and storage folders for the application: sudo mkdir -p /opt/pbc-betanet/conf sudo mkdir -p /opt/pbc-betanet/storage Step 2 - Creating the node config.json Start by opening the file in nano : sudo nano /opt/pbc-betanet/conf/config.json You paste this into config.json : { \"restPort\" : 8080 , \"floodingPort\" : 9888 , \"knownPeers\" : [ \"188.180.83.49:9090\" , \"188.180.83.49:9190\" , \"188.180.83.49:9290\" , \"188.180.83.49:9390\" , \"174.138.2.217:9888\" , \"172.93.110.125:9888\" , \"107.189.1.171:9888\" , \"176.78.42.5:9888\" ] } To save the file press CTRL+O and then ENTER and then CTRL+X . You can verify the contents of the files are what you expect by opening them with cat : sudo cat /opt/pbc-betanet/conf/config.json # The config file should be printed here Step 3 - Setting file permissions Now we need to make sure the user with uid 1500 has the needed access to the files: sudo chown -R \"1500:1500\" /opt/pbc-betanet sudo chmod 500 /opt/pbc-betanet/conf sudo chmod 700 /opt/pbc-betanet/storage sudo chmod 400 /opt/pbc-betanet/conf/config.json The above commands set conservative permissions on the folders the node is using. chmod 500 makes the config folder readable by the PBC node and root. chmod 700 makes the storage folder readable and writable for the PBC node and root. Step 4 - Pull docker image You can run the node using the docker-compose . Start by creating a directory pbc and add a file named docker-compose.yml . cd ~ mkdir -p pbc We put the folder containing docker-compose.yml in home directory to prevent users who access docker from gaining easy access to information in the config.json . Therefor you can execute the following docker commands without superuser privileges. cd pbc nano docker-compose.yml The contents of the file should be the following: version : \"2.0\" services : pbc-betanet-reader : image : registry.gitlab.com/privacyblockchain/demo/betanet-public:latest container_name : pbc-betanet-reader user : \"1500:1500\" restart : always expose : - \"8080\" ports : - \"9888-9897:9888-9897\" command : [ \"/conf/config.json\" , \"/storage/\" ] volumes : - /opt/pbc-betanet/conf:/conf - /opt/pbc-betanet/storage:/storage environment : - JAVA_TOOL_OPTIONS=\"-Xmx8G\" Save the file by pressing CTRL+O and then ENTER and then CTRL+X . Keep an eye on the indentation since YAML is whitespace sensitive, and it won't work if the indentation is off. You don't yet have access to the Partisia container repository, so you first need to log in. docker login -u <GitLab e-mail address> registry.gitlab.com Note: If you have two-factor login enabled in GitLab you need to create a personal access token . You can now start the node: docker-compose up -d This should pull the latest image and start the reader node in the background. If the command was executed successfully it won't print anything. To verify that the node is running, run: docker logs -f pbc-betanet-reader This should print a bunch of log statements. All the timestamps are in UTC and can therefore be offset several hours from your local time.","title":"Run a node 2 - Local reader"},{"location":"operator-2-reader.html#run-a-reader-node-on-your-local-machine","text":"","title":"Run a reader node on your local machine"},{"location":"operator-2-reader.html#step-1-creating-the-folders","text":"First we need to create the conf and storage folders for the application: sudo mkdir -p /opt/pbc-betanet/conf sudo mkdir -p /opt/pbc-betanet/storage","title":"Step 1 - Creating the folders"},{"location":"operator-2-reader.html#step-2-creating-the-node-configjson","text":"Start by opening the file in nano : sudo nano /opt/pbc-betanet/conf/config.json You paste this into config.json : { \"restPort\" : 8080 , \"floodingPort\" : 9888 , \"knownPeers\" : [ \"188.180.83.49:9090\" , \"188.180.83.49:9190\" , \"188.180.83.49:9290\" , \"188.180.83.49:9390\" , \"174.138.2.217:9888\" , \"172.93.110.125:9888\" , \"107.189.1.171:9888\" , \"176.78.42.5:9888\" ] } To save the file press CTRL+O and then ENTER and then CTRL+X . You can verify the contents of the files are what you expect by opening them with cat : sudo cat /opt/pbc-betanet/conf/config.json # The config file should be printed here","title":"Step 2 - Creating the node config.json"},{"location":"operator-2-reader.html#step-3-setting-file-permissions","text":"Now we need to make sure the user with uid 1500 has the needed access to the files: sudo chown -R \"1500:1500\" /opt/pbc-betanet sudo chmod 500 /opt/pbc-betanet/conf sudo chmod 700 /opt/pbc-betanet/storage sudo chmod 400 /opt/pbc-betanet/conf/config.json The above commands set conservative permissions on the folders the node is using. chmod 500 makes the config folder readable by the PBC node and root. chmod 700 makes the storage folder readable and writable for the PBC node and root.","title":"Step 3 - Setting file permissions"},{"location":"operator-2-reader.html#step-4-pull-docker-image","text":"You can run the node using the docker-compose . Start by creating a directory pbc and add a file named docker-compose.yml . cd ~ mkdir -p pbc We put the folder containing docker-compose.yml in home directory to prevent users who access docker from gaining easy access to information in the config.json . Therefor you can execute the following docker commands without superuser privileges. cd pbc nano docker-compose.yml The contents of the file should be the following: version : \"2.0\" services : pbc-betanet-reader : image : registry.gitlab.com/privacyblockchain/demo/betanet-public:latest container_name : pbc-betanet-reader user : \"1500:1500\" restart : always expose : - \"8080\" ports : - \"9888-9897:9888-9897\" command : [ \"/conf/config.json\" , \"/storage/\" ] volumes : - /opt/pbc-betanet/conf:/conf - /opt/pbc-betanet/storage:/storage environment : - JAVA_TOOL_OPTIONS=\"-Xmx8G\" Save the file by pressing CTRL+O and then ENTER and then CTRL+X . Keep an eye on the indentation since YAML is whitespace sensitive, and it won't work if the indentation is off. You don't yet have access to the Partisia container repository, so you first need to log in. docker login -u <GitLab e-mail address> registry.gitlab.com Note: If you have two-factor login enabled in GitLab you need to create a personal access token . You can now start the node: docker-compose up -d This should pull the latest image and start the reader node in the background. If the command was executed successfully it won't print anything. To verify that the node is running, run: docker logs -f pbc-betanet-reader This should print a bunch of log statements. All the timestamps are in UTC and can therefore be offset several hours from your local time.","title":"Step 4 - Pull docker image"},{"location":"operator-3-vps.html","text":"Get a VPS where you can run your block producing node What is VPS A VPS is a Virtual Private server. Just like you can have a virtual machines on your PC, it is possible to rent server space for virtual machine from an internet hosting service (IHS). That is called a VPS. You choose a VPS just like you would choose a PC. You decide on an operating system (OS), for running nodes on Partisia Blockchain you choose Linux based OS (In this guide we used Ubuntu). Your VPS is physically capable of running the node if you align it with the recommended machine specs . Where you get a VPS There are numerous choices in service providers when it comes to VPS. In the illustration below you can see the geography of a committee of block producing nodes. There are many factors to weigh in when making your choice. but most important is to choose a provider you trust. There are at least 4 aspects to the location of your server, that you might want to consider: Location with adequate infrastructure? (Stable power grid and internet) Tax liabilities and property rights. Well-connected to remainder of the network. If the network was a spiderweb it would be advantageous to be at the center. Enhance the decentralization. As a rule of thumb for any investment, a broad portfolio has a greater probability of long term success. You can help to consolidate the chain against vulnerabilities by avoiding putting your node in the same location as everyone else. Why you should use a VPS Many users ask, \"Is it OK if I keep the server at home?\". You can make it work, but we advise against it. Servers at home suffers from the following problems: Home server Pets, children and spouses unplug your internet connection. You boil water when the toaster is on, and you lose power. You need to clean the basement or garage, you must move the server. You get a new job and have to move. VPS Stable internet and power connection. Cloud hosting allows for backup of your server. Renting a VPS is fairly cheap, and switching to a new one with different specs is much faster than getting a new physical server.","title":"Run a node 3 - VPS"},{"location":"operator-3-vps.html#get-a-vps-where-you-can-run-your-block-producing-node","text":"","title":"Get a VPS where you can run your block producing node"},{"location":"operator-3-vps.html#what-is-vps","text":"A VPS is a Virtual Private server. Just like you can have a virtual machines on your PC, it is possible to rent server space for virtual machine from an internet hosting service (IHS). That is called a VPS. You choose a VPS just like you would choose a PC. You decide on an operating system (OS), for running nodes on Partisia Blockchain you choose Linux based OS (In this guide we used Ubuntu). Your VPS is physically capable of running the node if you align it with the recommended machine specs .","title":"What is VPS"},{"location":"operator-3-vps.html#where-you-get-a-vps","text":"There are numerous choices in service providers when it comes to VPS. In the illustration below you can see the geography of a committee of block producing nodes. There are many factors to weigh in when making your choice. but most important is to choose a provider you trust. There are at least 4 aspects to the location of your server, that you might want to consider: Location with adequate infrastructure? (Stable power grid and internet) Tax liabilities and property rights. Well-connected to remainder of the network. If the network was a spiderweb it would be advantageous to be at the center. Enhance the decentralization. As a rule of thumb for any investment, a broad portfolio has a greater probability of long term success. You can help to consolidate the chain against vulnerabilities by avoiding putting your node in the same location as everyone else.","title":"Where you get a VPS"},{"location":"operator-3-vps.html#why-you-should-use-a-vps","text":"Many users ask, \"Is it OK if I keep the server at home?\". You can make it work, but we advise against it. Servers at home suffers from the following problems: Home server Pets, children and spouses unplug your internet connection. You boil water when the toaster is on, and you lose power. You need to clean the basement or garage, you must move the server. You get a new job and have to move. VPS Stable internet and power connection. Cloud hosting allows for backup of your server. Renting a VPS is fairly cheap, and switching to a new one with different specs is much faster than getting a new physical server.","title":"Why you should use a VPS"},{"location":"operator-4-security.html","text":"Secure your VPS Change root password When you get a VPS with Lixux OS you will be provided with a root password by the VPS provider. Change the root password: sudo passwd root Add a non-root user For best security practice root should not be default user. Add a non-root user: sudo adduser userNameHere Install Network Time Protocol To avoid time drift use Network Time Protocol (NTP). First install: sudo apt-get update sudo apt-get install ntp ntpdate Stop NTP service and point to NTP server: sudo service ntp stop sudo ntpdate pool.ntp.org Start NTP service and check status: sudo service ntp start sudo systemctl status ntp Install Htop It is useful to be able to monitor CPU and memory use on your server. For this purpose install Htop: sudo apt install htop Secure shell (SSH) It is sensible to use SSH when connection to your server. Most VPS hosting sites have a SSH guide specific to their hosting platform, so you should follow the specifics of your hosting provider's SSH guide. Configure your firewall Disable firewall off, set default to block incoming traffic and allow outgoing: sudo ufw disable sudo ufw default deny incoming sudo ufw default allow outgoing Allow specific ports for Secure Shell (SSH) and Partisia: sudo ufw allow your-SSH-port-number sudo ufw allow 9888 :9897/tcp Enable rate limiting on your SSH connection sudo ufw limit your-SSH-port-number Enable logging, start the firewall and check status: sudo ufw logging on sudo ufw enable sudo ufw status","title":"Run a node 4 - VPS security"},{"location":"operator-4-security.html#secure-your-vps","text":"","title":"Secure your VPS"},{"location":"operator-4-security.html#change-root-password","text":"When you get a VPS with Lixux OS you will be provided with a root password by the VPS provider. Change the root password: sudo passwd root","title":"Change root password"},{"location":"operator-4-security.html#add-a-non-root-user","text":"For best security practice root should not be default user. Add a non-root user: sudo adduser userNameHere","title":"Add a non-root user"},{"location":"operator-4-security.html#install-network-time-protocol","text":"To avoid time drift use Network Time Protocol (NTP). First install: sudo apt-get update sudo apt-get install ntp ntpdate Stop NTP service and point to NTP server: sudo service ntp stop sudo ntpdate pool.ntp.org Start NTP service and check status: sudo service ntp start sudo systemctl status ntp","title":"Install Network Time Protocol"},{"location":"operator-4-security.html#install-htop","text":"It is useful to be able to monitor CPU and memory use on your server. For this purpose install Htop: sudo apt install htop","title":"Install Htop"},{"location":"operator-4-security.html#secure-shell-ssh","text":"It is sensible to use SSH when connection to your server. Most VPS hosting sites have a SSH guide specific to their hosting platform, so you should follow the specifics of your hosting provider's SSH guide.","title":"Secure shell (SSH)"},{"location":"operator-4-security.html#configure-your-firewall","text":"Disable firewall off, set default to block incoming traffic and allow outgoing: sudo ufw disable sudo ufw default deny incoming sudo ufw default allow outgoing Allow specific ports for Secure Shell (SSH) and Partisia: sudo ufw allow your-SSH-port-number sudo ufw allow 9888 :9897/tcp Enable rate limiting on your SSH connection sudo ufw limit your-SSH-port-number Enable logging, start the firewall and check status: sudo ufw logging on sudo ufw enable sudo ufw status","title":"Configure your firewall"},{"location":"operator-5-reader-vps.html","text":"Run a reader node on VPS The following steps are the same as you went through setting up a reader node on your local machine. You should use the non-root user you created in the previous step . You need to install the recommended software before you start. Step 1 - Creating the folders In this guide we will be running the nodes from the folder /opt/pbc-betanet with user:group 1500:1500 . First we need to create the conf and storage folders for the application: sudo mkdir -p /opt/pbc-betanet/conf sudo mkdir -p /opt/pbc-betanet/storage Step 2 - Creating the node config.json Start by opening the file in nano : sudo nano /opt/pbc-betanet/conf/config.json You paste this into config.json : { \"restPort\" : 8080 , \"floodingPort\" : 9888 , \"knownPeers\" : [ \"188.180.83.49:9090\" , \"188.180.83.49:9190\" , \"188.180.83.49:9290\" , \"188.180.83.49:9390\" , \"174.138.2.217:9888\" , \"172.93.110.125:9888\" , \"107.189.1.171:9888\" , \"176.78.42.5:9888\" ] } To save the file press CTRL+O and then ENTER and then CTRL+X . You can verify the contents of the files are what you expect by opening them with cat : sudo cat /opt/pbc-betanet/conf/config.json # The config file should be printed here Step 3 - Setting file permissions Now we need to make sure the user with uid 1500 has the needed access to the files: sudo chown -R \"1500:1500\" /opt/pbc-betanet sudo chmod 500 /opt/pbc-betanet/conf sudo chmod 700 /opt/pbc-betanet/storage sudo chmod 400 /opt/pbc-betanet/conf/config.json The above commands set conservative permissions on the folders the node is using. chmod 500 makes the config folder readable by the PBC node and root. chmod 700 makes the storage folder readable and writable for the PBC node and root. Step 4 - Pull docker image You can run the node using the docker-compose . Start by creating a directory pbc and add a file named docker-compose.yml . mkdir -p pbc cd pbc nano docker-compose.yml The contents of the file should be the following: version : \"2.0\" services : pbc-betanet-reader : image : registry.gitlab.com/privacyblockchain/demo/betanet-public:latest container_name : pbc-betanet-reader user : \"1500:1500\" restart : always expose : - \"8080\" ports : - \"9888-9897:9888-9897\" command : [ \"/conf/config.json\" , \"/storage/\" ] volumes : - /opt/pbc-betanet/conf:/conf - /opt/pbc-betanet/storage:/storage environment : - JAVA_TOOL_OPTIONS=\"-Xmx8G\" Save the file by pressing CTRL+O and then ENTER and then CTRL+X . Keep an eye on the indentation since YAML is whitespace sensitive, and it won't work if the indentation is off. You don't yet have access to the Partisia container repository, so you first need to log in. docker login -u <GitLab e-mail address> registry.gitlab.com Note: If you have two-factor login enabled in GitLab you need to create a personal access token . You can now start the node: docker-compose up -d This should pull the latest image and start the reader node in the background. If the command was executed successfully it won't print anything. To verify that the node is running, run: docker logs -f pbc-betanet-reader This should print a bunch of log statements. All the timestamps are in UTC and can therefore be offset several hours from your local time. Logs and storage The logs of the node are written to the standard output of the container and are therefore managed using the tools provided by Docker. You can read about configuring Docker logs here . The storage of the node is based on RocksDB. It is write-heavy and will increase in size for the foreseeable future. The number and size of reads and writes is entirely dependent on the traffic on the network. Updating Updating the PBC node is a simple 3-step process: cd ~/pbc docker-compose pull docker-compose up -d First you change the directory to where you put your docker-compose.yml file. You then stop the currently running container, pull the newest image and start it again. You should now be running the newest version of the software.","title":"Run a node 5 - Reader node on VPS"},{"location":"operator-5-reader-vps.html#run-a-reader-node-on-vps","text":"The following steps are the same as you went through setting up a reader node on your local machine. You should use the non-root user you created in the previous step . You need to install the recommended software before you start.","title":"Run a reader node on VPS"},{"location":"operator-5-reader-vps.html#step-1-creating-the-folders","text":"In this guide we will be running the nodes from the folder /opt/pbc-betanet with user:group 1500:1500 . First we need to create the conf and storage folders for the application: sudo mkdir -p /opt/pbc-betanet/conf sudo mkdir -p /opt/pbc-betanet/storage","title":"Step 1 - Creating the folders"},{"location":"operator-5-reader-vps.html#step-2-creating-the-node-configjson","text":"Start by opening the file in nano : sudo nano /opt/pbc-betanet/conf/config.json You paste this into config.json : { \"restPort\" : 8080 , \"floodingPort\" : 9888 , \"knownPeers\" : [ \"188.180.83.49:9090\" , \"188.180.83.49:9190\" , \"188.180.83.49:9290\" , \"188.180.83.49:9390\" , \"174.138.2.217:9888\" , \"172.93.110.125:9888\" , \"107.189.1.171:9888\" , \"176.78.42.5:9888\" ] } To save the file press CTRL+O and then ENTER and then CTRL+X . You can verify the contents of the files are what you expect by opening them with cat : sudo cat /opt/pbc-betanet/conf/config.json # The config file should be printed here","title":"Step 2 - Creating the node config.json"},{"location":"operator-5-reader-vps.html#step-3-setting-file-permissions","text":"Now we need to make sure the user with uid 1500 has the needed access to the files: sudo chown -R \"1500:1500\" /opt/pbc-betanet sudo chmod 500 /opt/pbc-betanet/conf sudo chmod 700 /opt/pbc-betanet/storage sudo chmod 400 /opt/pbc-betanet/conf/config.json The above commands set conservative permissions on the folders the node is using. chmod 500 makes the config folder readable by the PBC node and root. chmod 700 makes the storage folder readable and writable for the PBC node and root.","title":"Step 3 - Setting file permissions"},{"location":"operator-5-reader-vps.html#step-4-pull-docker-image","text":"You can run the node using the docker-compose . Start by creating a directory pbc and add a file named docker-compose.yml . mkdir -p pbc cd pbc nano docker-compose.yml The contents of the file should be the following: version : \"2.0\" services : pbc-betanet-reader : image : registry.gitlab.com/privacyblockchain/demo/betanet-public:latest container_name : pbc-betanet-reader user : \"1500:1500\" restart : always expose : - \"8080\" ports : - \"9888-9897:9888-9897\" command : [ \"/conf/config.json\" , \"/storage/\" ] volumes : - /opt/pbc-betanet/conf:/conf - /opt/pbc-betanet/storage:/storage environment : - JAVA_TOOL_OPTIONS=\"-Xmx8G\" Save the file by pressing CTRL+O and then ENTER and then CTRL+X . Keep an eye on the indentation since YAML is whitespace sensitive, and it won't work if the indentation is off. You don't yet have access to the Partisia container repository, so you first need to log in. docker login -u <GitLab e-mail address> registry.gitlab.com Note: If you have two-factor login enabled in GitLab you need to create a personal access token . You can now start the node: docker-compose up -d This should pull the latest image and start the reader node in the background. If the command was executed successfully it won't print anything. To verify that the node is running, run: docker logs -f pbc-betanet-reader This should print a bunch of log statements. All the timestamps are in UTC and can therefore be offset several hours from your local time.","title":"Step 4 - Pull docker image"},{"location":"operator-5-reader-vps.html#logs-and-storage","text":"The logs of the node are written to the standard output of the container and are therefore managed using the tools provided by Docker. You can read about configuring Docker logs here . The storage of the node is based on RocksDB. It is write-heavy and will increase in size for the foreseeable future. The number and size of reads and writes is entirely dependent on the traffic on the network.","title":"Logs and storage"},{"location":"operator-5-reader-vps.html#updating","text":"Updating the PBC node is a simple 3-step process: cd ~/pbc docker-compose pull docker-compose up -d First you change the directory to where you put your docker-compose.yml file. You then stop the currently running container, pull the newest image and start it again. You should now be running the newest version of the software.","title":"Updating"},{"location":"operator-6-keys.html","text":"Node operators will need 3 sets of keys In the next two pages you will see how to fill out a config.json for a block producing node and how to register your node for block production on Partisia Blockchain. Before you can do that you need 3 private keys. Steps: 1) Find your PBC account private key and PBC address. 2) Generate The Network key pair. 3) Generate the Finalization key pair. The network and finalization keypair are randomly generated at KeyGen . Description of the functions of the keys and where to use them: You only need the private keys for the node configuration and registration. It is essential to keep private keys safe, since they cannot be recovered. Do not safe them on your server, store them on something physical where you always have access Public keys and addresses are generated as a function of the private key and can be recovered if forgotten. Nonetheless, you should the public keys as well for practical purposes. You PBC address works as your public identity on the blockchain, you use it to find your node performance in metrics. Active block producers on PBC are listed and identified with by address. So you will be using it a lot. The 1st set are Account keys of your PBC account, that you get through KYC the process: Account Private key - This is the private key for your PBC account that holds the MPC Tokens that you are staking. When you use the wallet to send the Register Transaction, the transaction is signed with this key. Goes in config.json as \"accountKey\" unless you are operating a genesis node, then you put the private key referring to the account you have chosen to hold your stake as \"accountKey\". PBC address - This is the address associated with your PBC account. When you send the Register Transaction it is automatically registered as your \"Identity\" when you sign the transaction. The 2nd set are Network Keys for network identification: Network PrivateKey - The private key is registered in config.json as \"networkKey\" Network PublicKey - Store for practical purposes The 3rd set needs to be generated with a key generation algorithm for BLS keypair and is in the box below the other set: Finalization PrivateKey - Goes in the config.json as \"finalizationKey\" Finalization PublicKey - Store for practical purposes","title":"Run a node 6 - Keys for BP config and registration"},{"location":"operator-6-keys.html#node-operators-will-need-3-sets-of-keys","text":"In the next two pages you will see how to fill out a config.json for a block producing node and how to register your node for block production on Partisia Blockchain. Before you can do that you need 3 private keys.","title":"Node operators will need 3 sets of keys"},{"location":"operator-6-keys.html#steps","text":"1) Find your PBC account private key and PBC address. 2) Generate The Network key pair. 3) Generate the Finalization key pair. The network and finalization keypair are randomly generated at KeyGen .","title":"Steps:"},{"location":"operator-6-keys.html#description-of-the-functions-of-the-keys-and-where-to-use-them","text":"You only need the private keys for the node configuration and registration. It is essential to keep private keys safe, since they cannot be recovered. Do not safe them on your server, store them on something physical where you always have access Public keys and addresses are generated as a function of the private key and can be recovered if forgotten. Nonetheless, you should the public keys as well for practical purposes. You PBC address works as your public identity on the blockchain, you use it to find your node performance in metrics. Active block producers on PBC are listed and identified with by address. So you will be using it a lot. The 1st set are Account keys of your PBC account, that you get through KYC the process: Account Private key - This is the private key for your PBC account that holds the MPC Tokens that you are staking. When you use the wallet to send the Register Transaction, the transaction is signed with this key. Goes in config.json as \"accountKey\" unless you are operating a genesis node, then you put the private key referring to the account you have chosen to hold your stake as \"accountKey\". PBC address - This is the address associated with your PBC account. When you send the Register Transaction it is automatically registered as your \"Identity\" when you sign the transaction. The 2nd set are Network Keys for network identification: Network PrivateKey - The private key is registered in config.json as \"networkKey\" Network PublicKey - Store for practical purposes The 3rd set needs to be generated with a key generation algorithm for BLS keypair and is in the box below the other set: Finalization PrivateKey - Goes in the config.json as \"finalizationKey\" Finalization PublicKey - Store for practical purposes","title":"Description of the functions of the keys and where to use them:"},{"location":"operator-7-bp.html","text":"Run a block producing node on Partisia Blockchain You must finish the previous two sections( Reader node on VPS and Keys for BP ) is a prerequisite. Step 1 - Stop your reader node Find the reader node container name: docker ps Stop the reader node: docker stop yourContainerNamer Step 2 - Change config.json to support block production To fill out the config.json for a block producing node you need to add the following information: Network privateKey Account privateKey Finalization privateKey IP address of the server hosting your node (You get this from your VPS service provider) Ethereum API endpoint. This is a URL address pointing to an Ethereum reader node on the Ethereum Mainnet (You should use a source you find trustworthy). This user made guide has a provider list and further information about endpoints. Start by opening the config.json in nano : sudo nano /opt/pbc-betanet/conf/config.json Config for the block producing nodes - baker nodes, ZK nodes and oracle nodes Put your private keys and IP inside the quotation marks replacing descriptions in capital letters. The IP address must be a public IPv4.: { \"restPort\" : 8080 , \"floodingPort\" : 9888 , \"networkKey\" : \"NETWORK_PRIVATE_KEY\" , \"producerConfig\" : { \"host\" : \"PUBLIC_IPV4_OF_SERVER_HOSTING_THIS_NODE\" , \"accountKey\" : \"PRIVATE_KEY_FROM_ACCOUNT_HOLDING STAKE\" , \"finalizationKey\" : \"FINALIZATION_PRIVATE_KEY_BLS\" , \"ethereumUrl\" : \"ETHEREUM_MAINNET_HTTP_ENDPOINT\" }, \"knownPeers\" : [ \"188.180.83.49:9090\" , \"188.180.83.49:9190\" , \"188.180.83.49:9290\" , \"188.180.83.49:9390\" , \"174.138.2.217:9888\" , \"172.93.110.125:9888\" , \"107.189.1.171:9888\" , \"176.78.42.5:9888\" ] } To save the file press CTRL+O and then ENTER and then CTRL+X . You can verify the contents of the files are what you expect by opening them with cat : sudo cat /opt/pbc-betanet/conf/config.json # The config file should be printed here Start your block producing node docker-compose up -d This should pull the latest image and start the reader node in the background. If the command was executed successfully it won't print anything. To verify that the node is running, run: docker logs -f pbc-betanet-reader This should print a bunch of log statements. All the timestamps are in UTC and can therefore be offset several hours from your local time.","title":"Run a node 7 - Change node config from reader to block producer"},{"location":"operator-7-bp.html#run-a-block-producing-node-on-partisia-blockchain","text":"You must finish the previous two sections( Reader node on VPS and Keys for BP ) is a prerequisite.","title":"Run a block producing node on Partisia Blockchain"},{"location":"operator-7-bp.html#step-1-stop-your-reader-node","text":"Find the reader node container name: docker ps Stop the reader node: docker stop yourContainerNamer","title":"Step 1 - Stop your reader node"},{"location":"operator-7-bp.html#step-2-change-configjson-to-support-block-production","text":"To fill out the config.json for a block producing node you need to add the following information: Network privateKey Account privateKey Finalization privateKey IP address of the server hosting your node (You get this from your VPS service provider) Ethereum API endpoint. This is a URL address pointing to an Ethereum reader node on the Ethereum Mainnet (You should use a source you find trustworthy). This user made guide has a provider list and further information about endpoints. Start by opening the config.json in nano : sudo nano /opt/pbc-betanet/conf/config.json Config for the block producing nodes - baker nodes, ZK nodes and oracle nodes Put your private keys and IP inside the quotation marks replacing descriptions in capital letters. The IP address must be a public IPv4.: { \"restPort\" : 8080 , \"floodingPort\" : 9888 , \"networkKey\" : \"NETWORK_PRIVATE_KEY\" , \"producerConfig\" : { \"host\" : \"PUBLIC_IPV4_OF_SERVER_HOSTING_THIS_NODE\" , \"accountKey\" : \"PRIVATE_KEY_FROM_ACCOUNT_HOLDING STAKE\" , \"finalizationKey\" : \"FINALIZATION_PRIVATE_KEY_BLS\" , \"ethereumUrl\" : \"ETHEREUM_MAINNET_HTTP_ENDPOINT\" }, \"knownPeers\" : [ \"188.180.83.49:9090\" , \"188.180.83.49:9190\" , \"188.180.83.49:9290\" , \"188.180.83.49:9390\" , \"174.138.2.217:9888\" , \"172.93.110.125:9888\" , \"107.189.1.171:9888\" , \"176.78.42.5:9888\" ] } To save the file press CTRL+O and then ENTER and then CTRL+X . You can verify the contents of the files are what you expect by opening them with cat : sudo cat /opt/pbc-betanet/conf/config.json # The config file should be printed here","title":"Step 2 - Change config.json to support block production"},{"location":"operator-7-bp.html#start-your-block-producing-node","text":"docker-compose up -d This should pull the latest image and start the reader node in the background. If the command was executed successfully it won't print anything. To verify that the node is running, run: docker logs -f pbc-betanet-reader This should print a bunch of log statements. All the timestamps are in UTC and can therefore be offset several hours from your local time.","title":"Start your block producing node"},{"location":"operator-8-registration.html","text":"Register your node The final step in becoming a block producer in the Partisia Blockchain is the registration. This is done by committing a stake of MPC Tokens and sending a registration form. Both are done with transaction you can perform in the Partisia Blochain Explorer . 1) You need the MPC Wallet extension for your browser. 2) You need to be able to cover gas costs of transaction, click here for help to get gas in your account. 3) Go to the Partisia Blochain Explorer . Log in. 4) Stake MPC Tokens: Put your PBC address in the search bar, then you get your account information. There is a staking button next to your balance of MPC Tokens. 5) Click Register Node Connect your MPC Wallet by clicking Connect Wallet . 6) Send Register Transaction. 7) Send the public IP of the server hosting the node and your PBC account address to @Kristian Hu#7382 in a direct message on the Node Operator Discord Channel. Content of Staking Transaction Amount (The amount of MPC Tokens you are staking) How to fill out the form for the Register Transaction You need the same 3 private keys you have put in the config.json . You use the private key of your account to log into your wallet and the Explorer. The form generates the public versions of the network and finalization key when you put in the private version. The registration ensures that your account and tokens are associated with your node. Also, it creates a profile with public information about your node. For this reason it is important to put trustworthy information in this form. IP is cross-checked with server jurisdiction and address with entity jurisdiction. Mismatched information will not be approved. Important rule for public information: You cannot use Partisia in the domain name. And you cannot call it a Partisia node, because that could imply the node to be operated by the company Partisia. Refering to a node as on Partisia Blockchain is fine. But I will emphazise the importance of the preposition. It is in the interest of all that the blockchain does not mistakenly appear to be less decentralized than it is. It should be clear for trust, which entity is running the node. And it should never appear to be controlled by Partisia or a subsidiary. Name (Name of company or person operating the node) Website (Company or personal webpage - do not use Partisia in domain name) Address (Company or personal address) Put in network private key Put in finalization private key (The BLS key) EntityJurisdiction (Node owner's (company or person) country of residence - ISO 3166-1 : 3-digit code referring to a country) ServerJurisdiction (Location of the server where you operate the node - ISO 3166-1: 3-digit code referring to a country) NB. You can change your public information from the Register Transaction by doing an Update Transaction Conditions for inclusion Formal conditions for inclusion in the network is stipulated in the soon-to-be published Yellow Paper (YP_0.95 Ch. 2.3.1 pp. 11-12): The public information regarding the node given by the operator must be validated. Sufficient stakes committed. Test run is successful. The transaction fees of Register and Staking Transaction have been paid.","title":"Run a node 8 - Register your node in the MPC Explorer"},{"location":"operator-8-registration.html#register-your-node","text":"The final step in becoming a block producer in the Partisia Blockchain is the registration. This is done by committing a stake of MPC Tokens and sending a registration form. Both are done with transaction you can perform in the Partisia Blochain Explorer . 1) You need the MPC Wallet extension for your browser. 2) You need to be able to cover gas costs of transaction, click here for help to get gas in your account. 3) Go to the Partisia Blochain Explorer . Log in. 4) Stake MPC Tokens: Put your PBC address in the search bar, then you get your account information. There is a staking button next to your balance of MPC Tokens. 5) Click Register Node Connect your MPC Wallet by clicking Connect Wallet . 6) Send Register Transaction. 7) Send the public IP of the server hosting the node and your PBC account address to @Kristian Hu#7382 in a direct message on the Node Operator Discord Channel.","title":"Register your node"},{"location":"operator-8-registration.html#content-of-staking-transaction","text":"Amount (The amount of MPC Tokens you are staking)","title":"Content of Staking Transaction"},{"location":"operator-8-registration.html#how-to-fill-out-the-form-for-the-register-transaction","text":"You need the same 3 private keys you have put in the config.json . You use the private key of your account to log into your wallet and the Explorer. The form generates the public versions of the network and finalization key when you put in the private version. The registration ensures that your account and tokens are associated with your node. Also, it creates a profile with public information about your node. For this reason it is important to put trustworthy information in this form. IP is cross-checked with server jurisdiction and address with entity jurisdiction. Mismatched information will not be approved. Important rule for public information: You cannot use Partisia in the domain name. And you cannot call it a Partisia node, because that could imply the node to be operated by the company Partisia. Refering to a node as on Partisia Blockchain is fine. But I will emphazise the importance of the preposition. It is in the interest of all that the blockchain does not mistakenly appear to be less decentralized than it is. It should be clear for trust, which entity is running the node. And it should never appear to be controlled by Partisia or a subsidiary. Name (Name of company or person operating the node) Website (Company or personal webpage - do not use Partisia in domain name) Address (Company or personal address) Put in network private key Put in finalization private key (The BLS key) EntityJurisdiction (Node owner's (company or person) country of residence - ISO 3166-1 : 3-digit code referring to a country) ServerJurisdiction (Location of the server where you operate the node - ISO 3166-1: 3-digit code referring to a country) NB. You can change your public information from the Register Transaction by doing an Update Transaction","title":"How to fill out the form for the Register Transaction"},{"location":"operator-8-registration.html#conditions-for-inclusion","text":"Formal conditions for inclusion in the network is stipulated in the soon-to-be published Yellow Paper (YP_0.95 Ch. 2.3.1 pp. 11-12): The public information regarding the node given by the operator must be validated. Sufficient stakes committed. Test run is successful. The transaction fees of Register and Staking Transaction have been paid.","title":"Conditions for inclusion"},{"location":"operator-9-node-health.html","text":"Node health and maintenance If your node is unattended for to long it can run into problems. Problems that may affect your node's earning potential and the safety of your stake. Your node has to be up-to-date to participate in the committee. If your node is not updated regularly, it is bound to fall out of committee. Only nodes up-to-date can participate in forming a new committee, so every time a new committee is formed from registered nodes, only nodes with newest version of Partisia Software can be included. Your node can only perform services and by extension earn rewards when in the committee. After you are included you want to make sure your node is able to continue to participate. To optimize your nodes earning potential you should implement automatic updates and check up on the node's performance regularly. Your node is working when: Your node is producing blocks when chosen as producer. At the moment nodes take turns based on their index from the list of committee members . This can be affirmed in the metrics explained below. Your node is signing blocks. Can be checked in the logs as explained below. Your node is running the newest version of Partisia Software. The easiest way to assure this is by implementing automatic updates. The following section covers how to: Update your node manually. Implement automatic updates. Check your IP accessibility and version of Partisia Software. Metrics of node performance - See if your node is producing blocks and have a reasonable finalization time. Interpret log messages and debugging problems - See if your node is signing blocks. How to migrate your node to a different VPS Updating In the following it is assumed we assume you are using ~/pbc as directory for your docker-compose.yml . Updating the PBC node is a simple 3-step process: cd ~/pbc docker-compose pull docker-compose up -d First you change the directory to where you put your docker-compose.yml . You then pull the newest image and start it again. You should now be running the newest version of the software. Get automatic updates To set up automatic updates you will need Cron, which is a time based job scheduler. See if you have the Cron package installed: dpkg -l cron If not: apt-get install cron Now you are ready to start. 1. Create the auto update script: Go to the directory where docker-compose.yml is located. cd ~/pbc Open the file in nano: nano update_docker.sh Paste the following content into the file: #!/bin/bash DATETIME=$(date -u) echo \"$DATETIME\" cd ~/pbc /usr/local/bin/docker-compose pull /usr/local/bin/docker-compose up -d Save the file by pressing CTRL+O and then ENTER and then CTRL+X . 2. Make the file executable: chmod +x update_docker.sh Type ls -l and confirm update_docker.sh has an x in its first group of attributes, that means it is now executable. 3. Set update frequency to 30 minutes: crontab -e This command allows you to add a rule for a scheduled event. You will be asked to choose your preferred text editor to edit the cron rule. If you have not already chosen a preference. Paste and add the rule to the scheduler. NB . No \"#\" in front of the rule: */30 * * * * /home/pbc/update_docker.sh >> /home/pbc/update.log 2 > & 1 Press CTRL+X and then Y and then ENTER . This rule will make the script run and thereby check for available updates every 30 minutes. To see if the script is working you can read the update log with the cat command : cat update.log You might want to change the timing the first time, so you do not have to wait 30 minutes to confirm that it works. If your version is up-to-date, you should see: YOUR_CONTAINER_NAME is up-to-date If you are currently updating you should see: Pulling YOUR_CONTAINER_NAME ... pulling from privacyblockchain/de... NB. Never include a shutdown command in your update script, otherwise your node will go offline every time checks for updates. Check software version and uptime with your personal endpoint Your node can only get registered as a block producer and participate in the committee if your host IP is reachable, and you are running the newest version of the Partisia software. Replace the letters in the URL below with the IP of the server hosting your node. This should navigate you to a page showing a JSON, with the following information: http://PUBLIC_IP_OF_SERVER_HOSTING_THIS_NODE:9888/status { versio n Ide nt i f ier : \"VERSION_NUMBER\" , up t ime : nu mber , - k n ow n PeersNe t workKeys : [ lis t O f Producers ], net workKey : \"NETWORK_PUBLIC_KEY\" , blockchai n Address : \"BLOCKCHAIN_ADDRESS\" You can see which version of Partisia software you are running. Uptime is measured in milliseconds, and show how long your server has been running uninterrupted. If you cannot open your status endpoint there is probably a problem with the opening of ports of the VPS. See which ports are allowed through the firewall: sudo ufw status Make sure you have opened for ports 9888-9897. If not consult instructions here . How to find and use metrics to measure performance You should visit the metrics, where you can get important indicators of your node's performance. It is possible to see metrics for one shard, or for the whole chain, you can also see specifics of your node. Make the metrics give you the information you are looking for: In this example I will look at the latest 400 minutes on Shard2 . Notice, that you add the time you wish to look back in the end of the URL, in this case 400 minutes. You can change shard number in the URL to see Shard0 and Shard1 . It takes about a day (1500 minutes) for all producers to have had their turn. If there are a lot of votes due to reset blocks, it can take longer. https://betareader.partisiablockchain.com/shards/Shard2/metrics/blocks/400 In case of problems it makes sense to look at each shard, because failures can be shard specific. And different tasks happen on different shards. It is highly recommendable to use a json extension for your browser, or paste the text into an IDE, otherwise it might be quite difficult to read the json file. Explanation of the terms in the output follows below. Your output should look like the ordered list you see here: { earlies t BlockProduc t io n Time : 1651026257696 , la test BlockProduc t io n Time : 1651050197085 , transa c t io n Cou nt : 1298 , eve nt Tra nsa c t io n Cou nt : 15 , blockCou nt : 967 , rese t BlockCou nt : 1 , commi ttees : { 2 : { producers : { 63 : { blocksProduced : 42 , media n Fi nal iza t io n Time : 2704 }, 65 : { blocksProduced : 99 , media n Fi nal iza t io n Time : 2726 }, 66 : { blocksProduced : 100 , media n Fi nal iza t io n Time : 3056 }, 67 : { blocksProduced : 100 , media n Fi nal iza t io n Time : 2799.5 }, 68 : { blocksProduced : 100 , media n Fi nal iza t io n Time : 3035 }, 69 : { blocksProduced : 100 , media n Fi nal iza t io n Time : 3159 }, 70 : { blocksProduced : 100 , media n Fi nal iza t io n Time : 3061 }, 71 : { blocksProduced : 100 , media n Fi nal iza t io n Time : 2853 }, 72 : { blocksProduced : 100 , media n Fi nal iza t io n Time : 3259 }, 73 : { blocksProduced : 100 , media n Fi nal iza t io n Time : 3045 }, 74 : { blocksProduced : 25 , media n Fi nal iza t io n Time : 3572 }, -1 : { blocksProduced : 1 , media n Fi nal iza t io n Time : -1 } } } } } The index of your node on this list corresponds to the index of listed committee members here . NB. You index can change every time a new committee is formed. The number of blocks your node produced should be 100, unless a producer at the previous index was offline or did not finish producing their 100 blocks. If there is a quota of leftover blocks from the previous producer, they will be produced by your node minus one reset block to change current producer. So if the node before yours produced 20 blocks and then stopped, your node would optimally produce 79 blocks. resetBlockCount: The first number to notice is resetBlockCount , this number is in our case different from zero, which means some nodes in the network have performed suboptimally. A node produces 100 blocks each time it is chosen as producer, unless it has to produce leftover blocks from a previous producer, or if one or more reset blocks have been used to skip offline producers. We can see in the resetBlockCount that 1 reset blocks were produced. The reset block was caused by the producer with index 64 offline or misconfigured. The nodes with index 65 only produced 99 blocks because one reset block is expended when skipping the unavailable producer. The first and last producer on the list might look like they did not perform, but that is due to the time when we pull the list. medianFinalizationTime: Each node has a medianFinalizationTime , the median time used by the node to produce a block. If this number is significantly higher for your node than the rest on the list. Then your node might have to weak hardware or something is causing the node to under perform. You can see blocks produced on the entire chain by modifying the URL: https://betareader.partisiablockchain.com/metrics/blocks/400 Logs and storage You use the docker logs to see activity on the chain and if your node is signing blocks. The logs of the node are written to the standard output of the container and are therefore managed using the tools provided by Docker. You can read about configuring Docker logs here . The storage of the node is based on RocksDB. It is write-heavy and will increase in size for the foreseeable future. The number and size of reads and writes is entirely dependent on the traffic on the network. Common log messages Signing BlockState - All is well. Not signing as shutdown is active - You may assume all is well. Shutdown happens when chosen producer fails to produce a block, a reset block is made, and then a new node is chosen for the role of producer. Not signing - This is not a good sign, you are not signing blocks. First, check if you are on the list of current committee members , if you are not, and you have already sent the Register Transaction, then you should search for your PBC account address in the state the Block Producer Orchestration Contract (BPOC). There is a field for each producer called \"status\": - after this you will see either \"CONFIRMED\" or \"PENDING\". Confirmed means you are registered as a block producer and are formally eligible to participate in the committee. Pending means your public information is still awaiting manual approval from the team cross-checking the information you have given. If you cannot find your address in the BPOC at all you need to resend your registration. Alternatively, if you are on the list of committee members and still get persistent \u201cNot signing\u201d then you almost certainly have some problem in your config.json Probably you have a wrong or no key in one of the fields: networkKey, accountKey or finalizationKey, or you forgot to add the host IP address. Got a message with wrong protocol identifier - This message comes every time a shutdown has occurred (in other words whenever a producer has not produced the block he is supposed to). So, on its own that message does not indicate a problem. But, if the log just repeats and don't change to a new message saying Executing Block\u2026 it could suggest you are running an outdated version of our software, a version that does not pull the newest docker image automatically. WebApplicationException. Status=404 - You may assume all is well. You may encounter different types of not found errors in the logs. Most of them are not indicative of a problem at your end. They occur when a node in the network has not received what it expected you can in most cases see the address or producer index of the nodes related to the error. Sorting the logs Latest logs: docker logs -f nameOfDockerContainer This will show the latest logs after they have caught up to present. Sorting by time: docker logs --since 1h nameOfDockerContainer This will give you the latest hour of logs Sorting by number of lines: docker logs --tail 1000 nameOfDockerContainer This will give you the latest 1000 lines of logs. docker logs --tail 1000 -f nameOfDockerContainer You can add the -f after a command to continue the logs afterwards. Sort for specific messages: You can use the grep command to get logs containing a specific string. docker logs --since 1h pbc-betanet-reader | grep \"Signing BlockState\" This will give you the blocks you have signed the last hour. You might also want to look for blocks you created when you were chosen as producer | grep \"Created Block\" . How to migrate your node to a different VPS When changing VPS there are a few important precautions you take ensuring a problem free migration. You may never run two nodes performing baker services at the same time Running two nodes with same config can be interpreted as malicious behavior.You can start a reader node on the new VPS. Then, when you are ready to change the config.json to the BP version, you stop the node from running on the old server: docker stop nameOfDockerContainer If you change host IP, you need to correct your config.json In config.json correct the IPv4: \"host\" : \"PUBLIC_IP_OF_SERVER_HOSTING_THIS_NODE\" , You must migrate certain files for your node to participate in voting on a new committee (Large Oracle) From the root directory of your old node host you move the 3 files below to the root directory of the new server: large-oracle-backup-database.db , large-oracle-database.db and peers.json","title":"Run a node 9 - Node health and maintenance"},{"location":"operator-9-node-health.html#node-health-and-maintenance","text":"If your node is unattended for to long it can run into problems. Problems that may affect your node's earning potential and the safety of your stake. Your node has to be up-to-date to participate in the committee. If your node is not updated regularly, it is bound to fall out of committee. Only nodes up-to-date can participate in forming a new committee, so every time a new committee is formed from registered nodes, only nodes with newest version of Partisia Software can be included. Your node can only perform services and by extension earn rewards when in the committee. After you are included you want to make sure your node is able to continue to participate. To optimize your nodes earning potential you should implement automatic updates and check up on the node's performance regularly. Your node is working when: Your node is producing blocks when chosen as producer. At the moment nodes take turns based on their index from the list of committee members . This can be affirmed in the metrics explained below. Your node is signing blocks. Can be checked in the logs as explained below. Your node is running the newest version of Partisia Software. The easiest way to assure this is by implementing automatic updates.","title":"Node health and maintenance"},{"location":"operator-9-node-health.html#the-following-section-covers-how-to","text":"Update your node manually. Implement automatic updates. Check your IP accessibility and version of Partisia Software. Metrics of node performance - See if your node is producing blocks and have a reasonable finalization time. Interpret log messages and debugging problems - See if your node is signing blocks. How to migrate your node to a different VPS","title":"The following section covers how to:"},{"location":"operator-9-node-health.html#updating","text":"In the following it is assumed we assume you are using ~/pbc as directory for your docker-compose.yml . Updating the PBC node is a simple 3-step process: cd ~/pbc docker-compose pull docker-compose up -d First you change the directory to where you put your docker-compose.yml . You then pull the newest image and start it again. You should now be running the newest version of the software.","title":"Updating"},{"location":"operator-9-node-health.html#get-automatic-updates","text":"To set up automatic updates you will need Cron, which is a time based job scheduler. See if you have the Cron package installed: dpkg -l cron If not: apt-get install cron Now you are ready to start. 1. Create the auto update script: Go to the directory where docker-compose.yml is located. cd ~/pbc Open the file in nano: nano update_docker.sh Paste the following content into the file: #!/bin/bash DATETIME=$(date -u) echo \"$DATETIME\" cd ~/pbc /usr/local/bin/docker-compose pull /usr/local/bin/docker-compose up -d Save the file by pressing CTRL+O and then ENTER and then CTRL+X . 2. Make the file executable: chmod +x update_docker.sh Type ls -l and confirm update_docker.sh has an x in its first group of attributes, that means it is now executable. 3. Set update frequency to 30 minutes: crontab -e This command allows you to add a rule for a scheduled event. You will be asked to choose your preferred text editor to edit the cron rule. If you have not already chosen a preference. Paste and add the rule to the scheduler. NB . No \"#\" in front of the rule: */30 * * * * /home/pbc/update_docker.sh >> /home/pbc/update.log 2 > & 1 Press CTRL+X and then Y and then ENTER . This rule will make the script run and thereby check for available updates every 30 minutes. To see if the script is working you can read the update log with the cat command : cat update.log You might want to change the timing the first time, so you do not have to wait 30 minutes to confirm that it works. If your version is up-to-date, you should see: YOUR_CONTAINER_NAME is up-to-date If you are currently updating you should see: Pulling YOUR_CONTAINER_NAME ... pulling from privacyblockchain/de... NB. Never include a shutdown command in your update script, otherwise your node will go offline every time checks for updates.","title":"Get automatic updates"},{"location":"operator-9-node-health.html#check-software-version-and-uptime-with-your-personal-endpoint","text":"Your node can only get registered as a block producer and participate in the committee if your host IP is reachable, and you are running the newest version of the Partisia software. Replace the letters in the URL below with the IP of the server hosting your node. This should navigate you to a page showing a JSON, with the following information: http://PUBLIC_IP_OF_SERVER_HOSTING_THIS_NODE:9888/status { versio n Ide nt i f ier : \"VERSION_NUMBER\" , up t ime : nu mber , - k n ow n PeersNe t workKeys : [ lis t O f Producers ], net workKey : \"NETWORK_PUBLIC_KEY\" , blockchai n Address : \"BLOCKCHAIN_ADDRESS\" You can see which version of Partisia software you are running. Uptime is measured in milliseconds, and show how long your server has been running uninterrupted. If you cannot open your status endpoint there is probably a problem with the opening of ports of the VPS. See which ports are allowed through the firewall: sudo ufw status Make sure you have opened for ports 9888-9897. If not consult instructions here .","title":"Check software version and uptime with your personal endpoint"},{"location":"operator-9-node-health.html#how-to-find-and-use-metrics-to-measure-performance","text":"You should visit the metrics, where you can get important indicators of your node's performance. It is possible to see metrics for one shard, or for the whole chain, you can also see specifics of your node. Make the metrics give you the information you are looking for: In this example I will look at the latest 400 minutes on Shard2 . Notice, that you add the time you wish to look back in the end of the URL, in this case 400 minutes. You can change shard number in the URL to see Shard0 and Shard1 . It takes about a day (1500 minutes) for all producers to have had their turn. If there are a lot of votes due to reset blocks, it can take longer. https://betareader.partisiablockchain.com/shards/Shard2/metrics/blocks/400 In case of problems it makes sense to look at each shard, because failures can be shard specific. And different tasks happen on different shards. It is highly recommendable to use a json extension for your browser, or paste the text into an IDE, otherwise it might be quite difficult to read the json file. Explanation of the terms in the output follows below. Your output should look like the ordered list you see here: { earlies t BlockProduc t io n Time : 1651026257696 , la test BlockProduc t io n Time : 1651050197085 , transa c t io n Cou nt : 1298 , eve nt Tra nsa c t io n Cou nt : 15 , blockCou nt : 967 , rese t BlockCou nt : 1 , commi ttees : { 2 : { producers : { 63 : { blocksProduced : 42 , media n Fi nal iza t io n Time : 2704 }, 65 : { blocksProduced : 99 , media n Fi nal iza t io n Time : 2726 }, 66 : { blocksProduced : 100 , media n Fi nal iza t io n Time : 3056 }, 67 : { blocksProduced : 100 , media n Fi nal iza t io n Time : 2799.5 }, 68 : { blocksProduced : 100 , media n Fi nal iza t io n Time : 3035 }, 69 : { blocksProduced : 100 , media n Fi nal iza t io n Time : 3159 }, 70 : { blocksProduced : 100 , media n Fi nal iza t io n Time : 3061 }, 71 : { blocksProduced : 100 , media n Fi nal iza t io n Time : 2853 }, 72 : { blocksProduced : 100 , media n Fi nal iza t io n Time : 3259 }, 73 : { blocksProduced : 100 , media n Fi nal iza t io n Time : 3045 }, 74 : { blocksProduced : 25 , media n Fi nal iza t io n Time : 3572 }, -1 : { blocksProduced : 1 , media n Fi nal iza t io n Time : -1 } } } } } The index of your node on this list corresponds to the index of listed committee members here . NB. You index can change every time a new committee is formed. The number of blocks your node produced should be 100, unless a producer at the previous index was offline or did not finish producing their 100 blocks. If there is a quota of leftover blocks from the previous producer, they will be produced by your node minus one reset block to change current producer. So if the node before yours produced 20 blocks and then stopped, your node would optimally produce 79 blocks. resetBlockCount: The first number to notice is resetBlockCount , this number is in our case different from zero, which means some nodes in the network have performed suboptimally. A node produces 100 blocks each time it is chosen as producer, unless it has to produce leftover blocks from a previous producer, or if one or more reset blocks have been used to skip offline producers. We can see in the resetBlockCount that 1 reset blocks were produced. The reset block was caused by the producer with index 64 offline or misconfigured. The nodes with index 65 only produced 99 blocks because one reset block is expended when skipping the unavailable producer. The first and last producer on the list might look like they did not perform, but that is due to the time when we pull the list. medianFinalizationTime: Each node has a medianFinalizationTime , the median time used by the node to produce a block. If this number is significantly higher for your node than the rest on the list. Then your node might have to weak hardware or something is causing the node to under perform. You can see blocks produced on the entire chain by modifying the URL: https://betareader.partisiablockchain.com/metrics/blocks/400","title":"How to find and use metrics to measure performance"},{"location":"operator-9-node-health.html#logs-and-storage","text":"You use the docker logs to see activity on the chain and if your node is signing blocks. The logs of the node are written to the standard output of the container and are therefore managed using the tools provided by Docker. You can read about configuring Docker logs here . The storage of the node is based on RocksDB. It is write-heavy and will increase in size for the foreseeable future. The number and size of reads and writes is entirely dependent on the traffic on the network.","title":"Logs and storage"},{"location":"operator-9-node-health.html#common-log-messages","text":"Signing BlockState - All is well. Not signing as shutdown is active - You may assume all is well. Shutdown happens when chosen producer fails to produce a block, a reset block is made, and then a new node is chosen for the role of producer. Not signing - This is not a good sign, you are not signing blocks. First, check if you are on the list of current committee members , if you are not, and you have already sent the Register Transaction, then you should search for your PBC account address in the state the Block Producer Orchestration Contract (BPOC). There is a field for each producer called \"status\": - after this you will see either \"CONFIRMED\" or \"PENDING\". Confirmed means you are registered as a block producer and are formally eligible to participate in the committee. Pending means your public information is still awaiting manual approval from the team cross-checking the information you have given. If you cannot find your address in the BPOC at all you need to resend your registration. Alternatively, if you are on the list of committee members and still get persistent \u201cNot signing\u201d then you almost certainly have some problem in your config.json Probably you have a wrong or no key in one of the fields: networkKey, accountKey or finalizationKey, or you forgot to add the host IP address. Got a message with wrong protocol identifier - This message comes every time a shutdown has occurred (in other words whenever a producer has not produced the block he is supposed to). So, on its own that message does not indicate a problem. But, if the log just repeats and don't change to a new message saying Executing Block\u2026 it could suggest you are running an outdated version of our software, a version that does not pull the newest docker image automatically. WebApplicationException. Status=404 - You may assume all is well. You may encounter different types of not found errors in the logs. Most of them are not indicative of a problem at your end. They occur when a node in the network has not received what it expected you can in most cases see the address or producer index of the nodes related to the error.","title":"Common log messages"},{"location":"operator-9-node-health.html#sorting-the-logs","text":"Latest logs: docker logs -f nameOfDockerContainer This will show the latest logs after they have caught up to present. Sorting by time: docker logs --since 1h nameOfDockerContainer This will give you the latest hour of logs Sorting by number of lines: docker logs --tail 1000 nameOfDockerContainer This will give you the latest 1000 lines of logs. docker logs --tail 1000 -f nameOfDockerContainer You can add the -f after a command to continue the logs afterwards. Sort for specific messages: You can use the grep command to get logs containing a specific string. docker logs --since 1h pbc-betanet-reader | grep \"Signing BlockState\" This will give you the blocks you have signed the last hour. You might also want to look for blocks you created when you were chosen as producer | grep \"Created Block\" .","title":"Sorting the logs"},{"location":"operator-9-node-health.html#how-to-migrate-your-node-to-a-different-vps","text":"When changing VPS there are a few important precautions you take ensuring a problem free migration. You may never run two nodes performing baker services at the same time Running two nodes with same config can be interpreted as malicious behavior.You can start a reader node on the new VPS. Then, when you are ready to change the config.json to the BP version, you stop the node from running on the old server: docker stop nameOfDockerContainer If you change host IP, you need to correct your config.json In config.json correct the IPv4: \"host\" : \"PUBLIC_IP_OF_SERVER_HOSTING_THIS_NODE\" , You must migrate certain files for your node to participate in voting on a new committee (Large Oracle) From the root directory of your old node host you move the 3 files below to the root directory of the new server: large-oracle-backup-database.db , large-oracle-database.db and peers.json","title":"How to migrate your node to a different VPS"},{"location":"programmers_guide.html","text":"Partisia Blockchain SDK (Software Development Kit) Programmer's Guide This page is a quick overview of the software development kit for Partisia Blockchain. Smart Contract Overview A smart contract on Partisia Blockchain consists of, on a surface level, some state, and some actions defined to either operate on the state and/or to interact other contracts. Consider for example a basic public voting contract: State: What are we voting on? (if applicable) Who are allowed to vote? Deadline (if applicable) Who have voted? Are we done yet? What is the result if we are done? Actions: Voters should be able to vote. Anybody should be able to retrieve how many votes have been cast, and whether the vote is complete yet. Anybody should be able to retrieve the result of the vote. Initializer: Vote subject, Voters and Deadline are all permanent attributes of the vote, and so should be set in the initializer. Contracts' state and actions must be declared in an Contract ABI file ; a concise description of the contract's interface and internal state representation, that must be uploaded together with the contract code when initializing the contract. Without an ABI file, it might be impossible for the dashboard and other contracts to interact with your contract. The PBC SDK is capable of automatically producing an ABI for your contract, along with state and RPC serialization code for your actions. Macros Smart contract elements can be declared using these macros: #[state] declares how the contract represents its state. #[action] declares an endpoint that the contract can be interacted with by. #[init] declares the code run when the contract is initialized. #[state] Declares that the annotated struct is the top level of the contract state. This macro must occur exactly once in any given contract. Example: #[state] pub struct VotingContractState { proposal_id : u64 , mp_addresses : Vec < Address > , votes : BTreeMap < Address , u8 > , closed : u8 , } This macro implicitly derives the ReadWriteState trait for the struct. The ReadWriteState derive may fail if any of the state struct's fields aren't impl ReadWriteState . Further reading: state macro documentation #[action] Declares that the annotated function is an contract action that can be called from other contracts and dashboard. Must have a signature of the following format: #[action] pub fn action_internal_name ( context : ContractContext , state : ContractState , .. . // RPC arguments. ) -> ( ContractState , Vec < EventGroup > ) The action receives the previous state, along with a context, and the declared arguments, and must return the new state, along with a vector of EventGroup ; a list of interactions with other contracts. Example: #[action] pub fn vote ( context : ContractContext , state : VotingContractState , vote : u8 , ) -> ( VotingContractState , Vec < EventGroup > ) { // Code... } Further reading: action macro documentation A note on functional contracts Contracts are functional : Each interaction point, whether init or action take some input, and return some output. Interactions cannot produce side effects, visible or not. The state will thus not be changed should a transaction fail while running the contract code, whether due to panics or insufficient gas. Of further interest here, is that the entire contract is essentially \"reset\" after every interaction. Any static mut items will possess their initial value, once again. The only state your contract can possess is the state returned from interactions. #[init] Similar to #[action] macro, but declares how the contract can be initialized. #[init] pub fn initialize ( context : ContractContext , .. . // Initialization arguments ) -> ( VotingContractState , Vec < EventGroup > ) { // Code... } Note that there are no previous context when initializing, in contrast to the action macro. All arguments will be required during initialization. This macro must occur exactly once in any given contract. If the initializer fails the contract will not be created. Example: #[init] pub fn initialize ( context : ContractContext , proposal_id : u64 , mp_addresses : Vec < Address > , ) -> ( VotingContractState , Vec < EventGroup > ) { // Code... } Further reading: init macro documentation Traits The SDK exposes traits that provides serialization methods. These traits are important for the operation of PBC contracts, but should rarely be implemented manually; prefer using the built-in derive methods. ReadWriteState: Serialization for State serialization format . ReadWriteRPC: Serialization for RPC argument serialization format . CreateTypeSpec: Serialization for ABI serialization format . Further reading: pbc_traits crate documentation Data Structures Address Address represents an address on the blockchain; it has a subfield indicating the type of the address (account, system contract, public contract or zk contract.) Further reading: Address struct documentation ContractContext ContractContext is available from every action, and contains some useful context information for the current transaction: Address of the contract itself and the caller; the person or contract that caused the interaction. The current block number, and time since some epoche. Hashes of both the current transaction and the previous transaction. Further reading: ContractContext struct documentation Events Partisia Blockchain's contract interaction model sandboxes each contract, and allows RPC calls as the primary form of interaction. As each transaction is entirely isolated, RPCs can only occur \"between\" action calls. For example: Zeno calls Alice in transaction 1: Alice determines she needs some information from Bob, and exits while telling the blockchain: \"Call Bob for me, I want a reply, and let me pay for the reply\" Alice calls Bob in transaction 2: Bob performs it's computation, and exists with \"Here's the reply to Alice, she said she'd pay for this reply\". Bob calls Alice in transaction 3: Alice finally got the necessary information to perform her own computation... To accommodate this model, the SDK requires each action annotated function to return a (possibly empty) Vec of EventGroup s, which represents the \"Call X for me\" information. Each EventGroup consists of one or more interactions (representing \"Call X for me\",) with the possibility of callbacks (representing \"I want a reply\".) All interactions in an EventGroup shares gas costs uniformly. Further reading: events module documentation State serialization gas considerations Contracts with a lot of state should prefer Vec<T> to BTreeSet<T> or BTreeMap<T> , as Vec<T> (specifically for CopySerializable T ) are more efficiently (de)serialized, both in terms of gas and computation time. Remember that (de)serialization gas costs must be paid for every action, even ones that never handle state. If quick lookups are required, and the data structure rarely changes, it might be feasible to maintain a sorted Vec in state, and use [T]::binary_search_by_key for lookups, essentially creating your own map structure. Ensure you depend upon and link against the pbc_lib crate . This should automatically lower gas costs. Cheap memcpy (or why you should definitely link pbc_lib ) The SDK exposes cheaper (in terms of gas) versions of the memcpy and memmove functions. These functions are commonly used for copying bytes around directly, but are (thankfully) rarely manually used in Rust, though they may still occur in compiled programs due to lower-level libraries and compiler optimizations. Your compiled contracts will be using memcpy for (de)serialization, hence why the SDK defines these alternatives. The pbc_lib crate overwrites these functions with versions that directly interact with the PBC WASM Interpreter to trigger the interpreter's built-in support for quickly copying data around. Further reading: pbc_lib crate documentation","title":"Programmer's Guide to PBC SDK"},{"location":"programmers_guide.html#partisia-blockchain-sdk-software-development-kit-programmers-guide","text":"This page is a quick overview of the software development kit for Partisia Blockchain.","title":"Partisia Blockchain SDK (Software Development Kit) Programmer's Guide"},{"location":"programmers_guide.html#smart-contract-overview","text":"A smart contract on Partisia Blockchain consists of, on a surface level, some state, and some actions defined to either operate on the state and/or to interact other contracts. Consider for example a basic public voting contract: State: What are we voting on? (if applicable) Who are allowed to vote? Deadline (if applicable) Who have voted? Are we done yet? What is the result if we are done? Actions: Voters should be able to vote. Anybody should be able to retrieve how many votes have been cast, and whether the vote is complete yet. Anybody should be able to retrieve the result of the vote. Initializer: Vote subject, Voters and Deadline are all permanent attributes of the vote, and so should be set in the initializer. Contracts' state and actions must be declared in an Contract ABI file ; a concise description of the contract's interface and internal state representation, that must be uploaded together with the contract code when initializing the contract. Without an ABI file, it might be impossible for the dashboard and other contracts to interact with your contract. The PBC SDK is capable of automatically producing an ABI for your contract, along with state and RPC serialization code for your actions.","title":"Smart Contract Overview"},{"location":"programmers_guide.html#macros","text":"Smart contract elements can be declared using these macros: #[state] declares how the contract represents its state. #[action] declares an endpoint that the contract can be interacted with by. #[init] declares the code run when the contract is initialized.","title":"Macros"},{"location":"programmers_guide.html#state","text":"Declares that the annotated struct is the top level of the contract state. This macro must occur exactly once in any given contract. Example: #[state] pub struct VotingContractState { proposal_id : u64 , mp_addresses : Vec < Address > , votes : BTreeMap < Address , u8 > , closed : u8 , } This macro implicitly derives the ReadWriteState trait for the struct. The ReadWriteState derive may fail if any of the state struct's fields aren't impl ReadWriteState . Further reading: state macro documentation","title":"#[state]"},{"location":"programmers_guide.html#action","text":"Declares that the annotated function is an contract action that can be called from other contracts and dashboard. Must have a signature of the following format: #[action] pub fn action_internal_name ( context : ContractContext , state : ContractState , .. . // RPC arguments. ) -> ( ContractState , Vec < EventGroup > ) The action receives the previous state, along with a context, and the declared arguments, and must return the new state, along with a vector of EventGroup ; a list of interactions with other contracts. Example: #[action] pub fn vote ( context : ContractContext , state : VotingContractState , vote : u8 , ) -> ( VotingContractState , Vec < EventGroup > ) { // Code... } Further reading: action macro documentation","title":"#[action]"},{"location":"programmers_guide.html#a-note-on-functional-contracts","text":"Contracts are functional : Each interaction point, whether init or action take some input, and return some output. Interactions cannot produce side effects, visible or not. The state will thus not be changed should a transaction fail while running the contract code, whether due to panics or insufficient gas. Of further interest here, is that the entire contract is essentially \"reset\" after every interaction. Any static mut items will possess their initial value, once again. The only state your contract can possess is the state returned from interactions.","title":"A note on functional contracts"},{"location":"programmers_guide.html#init","text":"Similar to #[action] macro, but declares how the contract can be initialized. #[init] pub fn initialize ( context : ContractContext , .. . // Initialization arguments ) -> ( VotingContractState , Vec < EventGroup > ) { // Code... } Note that there are no previous context when initializing, in contrast to the action macro. All arguments will be required during initialization. This macro must occur exactly once in any given contract. If the initializer fails the contract will not be created. Example: #[init] pub fn initialize ( context : ContractContext , proposal_id : u64 , mp_addresses : Vec < Address > , ) -> ( VotingContractState , Vec < EventGroup > ) { // Code... } Further reading: init macro documentation","title":"#[init]"},{"location":"programmers_guide.html#traits","text":"The SDK exposes traits that provides serialization methods. These traits are important for the operation of PBC contracts, but should rarely be implemented manually; prefer using the built-in derive methods. ReadWriteState: Serialization for State serialization format . ReadWriteRPC: Serialization for RPC argument serialization format . CreateTypeSpec: Serialization for ABI serialization format . Further reading: pbc_traits crate documentation","title":"Traits"},{"location":"programmers_guide.html#data-structures","text":"","title":"Data Structures"},{"location":"programmers_guide.html#address","text":"Address represents an address on the blockchain; it has a subfield indicating the type of the address (account, system contract, public contract or zk contract.) Further reading: Address struct documentation","title":"Address"},{"location":"programmers_guide.html#contractcontext","text":"ContractContext is available from every action, and contains some useful context information for the current transaction: Address of the contract itself and the caller; the person or contract that caused the interaction. The current block number, and time since some epoche. Hashes of both the current transaction and the previous transaction. Further reading: ContractContext struct documentation","title":"ContractContext"},{"location":"programmers_guide.html#events","text":"Partisia Blockchain's contract interaction model sandboxes each contract, and allows RPC calls as the primary form of interaction. As each transaction is entirely isolated, RPCs can only occur \"between\" action calls. For example: Zeno calls Alice in transaction 1: Alice determines she needs some information from Bob, and exits while telling the blockchain: \"Call Bob for me, I want a reply, and let me pay for the reply\" Alice calls Bob in transaction 2: Bob performs it's computation, and exists with \"Here's the reply to Alice, she said she'd pay for this reply\". Bob calls Alice in transaction 3: Alice finally got the necessary information to perform her own computation... To accommodate this model, the SDK requires each action annotated function to return a (possibly empty) Vec of EventGroup s, which represents the \"Call X for me\" information. Each EventGroup consists of one or more interactions (representing \"Call X for me\",) with the possibility of callbacks (representing \"I want a reply\".) All interactions in an EventGroup shares gas costs uniformly. Further reading: events module documentation","title":"Events"},{"location":"programmers_guide.html#state-serialization-gas-considerations","text":"Contracts with a lot of state should prefer Vec<T> to BTreeSet<T> or BTreeMap<T> , as Vec<T> (specifically for CopySerializable T ) are more efficiently (de)serialized, both in terms of gas and computation time. Remember that (de)serialization gas costs must be paid for every action, even ones that never handle state. If quick lookups are required, and the data structure rarely changes, it might be feasible to maintain a sorted Vec in state, and use [T]::binary_search_by_key for lookups, essentially creating your own map structure. Ensure you depend upon and link against the pbc_lib crate . This should automatically lower gas costs.","title":"State serialization gas considerations"},{"location":"programmers_guide.html#cheap-memcpy-or-why-you-should-definitely-link-pbc_lib","text":"The SDK exposes cheaper (in terms of gas) versions of the memcpy and memmove functions. These functions are commonly used for copying bytes around directly, but are (thankfully) rarely manually used in Rust, though they may still occur in compiled programs due to lower-level libraries and compiler optimizations. Your compiled contracts will be using memcpy for (de)serialization, hence why the SDK defines these alternatives. The pbc_lib crate overwrites these functions with versions that directly interact with the PBC WASM Interpreter to trigger the interpreter's built-in support for quickly copying data around. Further reading: pbc_lib crate documentation","title":"Cheap memcpy (or why you should definitely link pbc_lib)"},{"location":"shards.html","text":"Sharding Sharding has a big effect on your experience of interacting with Partisia Blockchain. Sharding ensures scalability of blockchain services. The chain can support an arbitrarily large number of shards. Transactions can be settled parallel and each shard can process around a 1000 transactions per second. Therefore the only practical limitation to the number of transactions that PBC can perform is the network capacity between the nodes. But, there are more good news. When you interact with the blockchain via smart contracts you do not have to take any measures to utilize the sharding in execution of transactions. The contracts you develop can be coded with no regard for the sharding. You harvest all the benefits in terms of speed and scalability, but none of the downside in form of complication of the contract development you see on other blockchains using sharding. How it works PBC is a blockchain that has the state, contracts and accounts distributed across multiple groups of nodes. These groups are called shards . Each shard has its own independent block time and it's own block producer which enables parallel execution of transactions that do not depend on the same state. Every account and every contract live on a specific shard. Shards have their own consensus and the current proposer/block time can drift freely between the shards. Shards operate independently of each other and can thus process transactions in parallel. If the chain has n shards then the chain can process n blocks simultaneously. When an account holder sends a transaction he/she does so to the shard his/her account lives on. The transaction spawns an event transaction that is then routed to the relevant shard and executed. If the destination contract lives on the same shard, the event is executed inline, otherwise it is flooded through the network to a node on the relevant shard. To ensure the validity of the propagated transaction the source shard adds a finalization proof to the sent event. This is needed because the destination shard cannot verify the validity of the transaction without the PoF since the destination shard does not have direct access to the state of the source shard. For more details on the proofs see FastTrack consensus .","title":"Shards"},{"location":"shards.html#sharding","text":"Sharding has a big effect on your experience of interacting with Partisia Blockchain. Sharding ensures scalability of blockchain services. The chain can support an arbitrarily large number of shards. Transactions can be settled parallel and each shard can process around a 1000 transactions per second. Therefore the only practical limitation to the number of transactions that PBC can perform is the network capacity between the nodes. But, there are more good news. When you interact with the blockchain via smart contracts you do not have to take any measures to utilize the sharding in execution of transactions. The contracts you develop can be coded with no regard for the sharding. You harvest all the benefits in terms of speed and scalability, but none of the downside in form of complication of the contract development you see on other blockchains using sharding.","title":"Sharding"},{"location":"shards.html#how-it-works","text":"PBC is a blockchain that has the state, contracts and accounts distributed across multiple groups of nodes. These groups are called shards . Each shard has its own independent block time and it's own block producer which enables parallel execution of transactions that do not depend on the same state. Every account and every contract live on a specific shard. Shards have their own consensus and the current proposer/block time can drift freely between the shards. Shards operate independently of each other and can thus process transactions in parallel. If the chain has n shards then the chain can process n blocks simultaneously. When an account holder sends a transaction he/she does so to the shard his/her account lives on. The transaction spawns an event transaction that is then routed to the relevant shard and executed. If the destination contract lives on the same shard, the event is executed inline, otherwise it is flooded through the network to a node on the relevant shard. To ensure the validity of the propagated transaction the source shard adds a finalization proof to the sent event. This is needed because the destination shard cannot verify the validity of the transaction without the PoF since the destination shard does not have direct access to the state of the source shard. For more details on the proofs see FastTrack consensus .","title":"How it works"},{"location":"transactions.html","text":"Transactions A transaction represents an authorized atomic interaction with the blockchain. Each transaction defines how long into the future it is valid and what the cost is. A hash of the transaction and the signer\u2019s nonce is then signed by the account holder using his/her private key. This signature is used to authenticate the signer on the blockchain. If the signing key does not have a corresponding account, the transaction is rejected. A transaction is valid when: It has as a valid signature The nonce in the transaction matches the account nonce in the blockchain state The transaction has not expired The account can cover the cost of the transaction (see Transaction fees below) There are three types of transactions: create contract, interact with contract and remove contract. All transactions include an RPC byte stream, the interpretation of which is up to the specific contract. The three transaction types correspond to the onCreate , onInvoke and onDestroy methods comprise the contract lifecycle.","title":"Transactions"},{"location":"transactions.html#transactions","text":"A transaction represents an authorized atomic interaction with the blockchain. Each transaction defines how long into the future it is valid and what the cost is. A hash of the transaction and the signer\u2019s nonce is then signed by the account holder using his/her private key. This signature is used to authenticate the signer on the blockchain. If the signing key does not have a corresponding account, the transaction is rejected. A transaction is valid when: It has as a valid signature The nonce in the transaction matches the account nonce in the blockchain state The transaction has not expired The account can cover the cost of the transaction (see Transaction fees below) There are three types of transactions: create contract, interact with contract and remove contract. All transactions include an RPC byte stream, the interpretation of which is up to the specific contract. The three transaction types correspond to the onCreate , onInvoke and onDestroy methods comprise the contract lifecycle.","title":"Transactions"},{"location":"update-transaction.html","text":"The Update Transaction This page is only for updating information in a successful node registration. You can update the public node information from the Register Transaction. This is necessary if you change the country of your residence or the country of the server hosting your node. This is a practical way of changing and correcting the information without having to leave the network and redo the Register Transaction. NB. You can only use this transaction if you are a registered block producer. If your node is still pending KYC approval this transaction has no effect on your public information. Content of the Update Transaction Name (Legal name) Website (Company or personal webpage) Address (Company or personal address) EntityJurisdiction (Your country of residence - ISO 3166-1: 3-digit code referring to a country) ServerJurisdiction (Location of the server where you operate the node - ISO 3166-1: 3-digit code referring to a country) You send the Update Transaction from Register Node in the Partisia Blockchain Explorer, there is a tab labeled UPDATE .","title":"Update your node's public information"},{"location":"update-transaction.html#the-update-transaction","text":"This page is only for updating information in a successful node registration. You can update the public node information from the Register Transaction. This is necessary if you change the country of your residence or the country of the server hosting your node. This is a practical way of changing and correcting the information without having to leave the network and redo the Register Transaction. NB. You can only use this transaction if you are a registered block producer. If your node is still pending KYC approval this transaction has no effect on your public information.","title":"The Update Transaction"},{"location":"update-transaction.html#content-of-the-update-transaction","text":"Name (Legal name) Website (Company or personal webpage) Address (Company or personal address) EntityJurisdiction (Your country of residence - ISO 3166-1: 3-digit code referring to a country) ServerJurisdiction (Location of the server where you operate the node - ISO 3166-1: 3-digit code referring to a country) You send the Update Transaction from Register Node in the Partisia Blockchain Explorer, there is a tab labeled UPDATE .","title":"Content of the Update Transaction"},{"location":"vickrey.html","text":"Example of a zero knowledge smart contract on PBC - Vickrey Auction One of the smart contracts you will be able to implement on PBC is a Vickrey Auction, which is a sealed bid auction where the second highest bid wins. When some valuable item changes hands through an auction it is desirable to have the change in ownership registered on an immutable record. It is however highly undesirable that individual maximum bids are public, since the seller can use a third party to drive up the price to the highest possible price. One of the great advantages of PBC over other blockchains is that zero knowledge computations can be performed on the network parallel to the public transactions on the blockchain. The second price auction takes as input a list of prices for each account, ordered in arrival by a number. When the computation is initiated by the contract owner, the zero knowledge computation nodes reads the collected input and then create a bit vector consisting of prices and the ordering number. The list of bit vectors is now sorted in MPC. The winner is the first entry (the bidder with the highest price-bid), the price is determined by the size of the second highest bid. The contract follows these phases: - Input Each participant in the computation delivers their input to the computation. Either via the blockchain with the shares in encrypted form (making the nodes stateless) or directly to the nodes (making the data information-theoretic secure). In both cases the inputter provides commitments stored on the blockchain of each share so the nodes can ensure internal consistency among the nodes. - Computation The computation takes the input and runs the designated computation, the separation into phases makes the computation rerunnable without any data leaks. This means that the computation can be restarted in case of a server failure or any other unexpected problem. - Commitment of output Each node sends a commit to the chain of each of their shares. When the smart contract has received the shares from every node, the smart contract initiates the next phase. - Output. Every node now sends their shares to the smart contract, when a majority has released their shares, the contract has complete information and can open the result up. Below you can see the Java implementation of the zero knowledge smart contract for the Vickrey Auction: /** Contract for a second price auction. */ public f i nal class Seco n dPriceAuc t io n Co ntra c t ex ten ds RealCo ntra c t <Wi nner , S tate Void> { /** Create a new second price auction contract. */ public Seco n dPriceAuc t io n Co ntra c t () { super( ne w RealCompu tat io n <>() { @Override public < NumberT ex ten ds SharedNumber<NumberT> , Bi t T ex ten ds SharedBi t <Bi t T> , E ex ten ds Fi n i te FieldEleme nt <E>> void compu te ( ZkCompu tat io n S tate <Wi nner , S tate Void , RealClosed<S tate Void>> s tate , RealPro t ocol<NumberT , Bi t T , E> pro t ocol) { ShareS t orage<NumberT , Bi t T> s t orage = pro t ocol.s t orage(); Lis t <Secre t Bid<NumberT>> bids = s tate .ge t Variables().s trea m() .map(ZkClosed :: ge t Id) .sor te d() .map(id - > ne w Secre t Bid<>(id , s t orage.load(id).ge t ( 0 ).ge t Number())) .collec t (Collec t ors. t oLis t ()); Compu te Wi nner <Bi t T , NumberT , E> compu te Wi nner = ne w Compu te Wi nner <>(bids); Fi n i te FieldEleme nt Fac t ory<E> fa c t ory = pro t ocol.eleme nt Fac t ory(); compu te Wi nner .execu te (pro t ocol , Ma t h.max( fa c t ory.eleme nt Bi t Size() , 32 )); } } ); } @Override public Wi nner o n Crea te ( ZkCo ntra c t Co nte x t co nte x t , ZkS tate <S tate Void , RealClosed<S tate Void>> zkS tate , Sa fe Da ta I n pu t S trea m i n voca t io n ) { re turn ne w Wi nner (); } /** An open input from the contract owner is treated as the signal to execute the auction. */ @Override public Wi nner o n Ope n I n pu t ( ZkCo ntra c t Co nte x t co nte x t , ZkS tate <S tate Void , RealClosed<S tate Void>> zkS tate , Wi nner s tate , Sa fe Da ta I n pu t S trea m i n voca t io n ) { i f (!co nte x t .ge t Co ntra c t Ow ner ().equals(co nte x t .ge t From())) { t hrow ne w IllegalArgume nt Excep t io n ( \"Only owner can start computation\" ); } i f (zkS tate .ge t Variables().size() < 2 ) { t hrow ne w IllegalArgume nt Excep t io n ( \"Need at least two bids to compute\" ); } // computation has two outputs: the bid and the winner id. zkS tate .s tart Compu tat io n (Collec t io ns . n Copies( 2 , null )); re turn s tate ; } /** Treat secret inputs as bids. */ @Override public Wi nner o n Secre t I n pu t ( ZkCo ntra c t Co nte x t co nte x t , ZkS tate <S tate Void , RealClosed<S tate Void>> zkS tate , Wi nner s tate , Secre t I n pu t Builder<S tate Void> i n pu t , Sa fe Da ta I n pu t S trea m i n voca t io n ) { i f (zkS tate .ge t Calcula t io n S tatus () != Calcula t io n S tatus .WAITING) { t hrow ne w IllegalS tate Excep t io n ( \"Cannot submit inputs after computation has started\" ); } i n pu t .expec t Bi t Le n g t h( 32 ); zkS tate .ge t Variables(co nte x t .ge t From()).s trea m() .map(ZkClosed :: ge t Id) . f orEach(zkS tate :: dele te Variable); zkS tate .ge t Pe n di n gI n pu ts (co nte x t .ge t From()).s trea m() .map(ZkClosed :: ge t Id) . f orEach(zkS tate :: dele te Pe n di n gI n pu t ); re turn s tate ; } @Override public Wi nner o n Compu te Comple te ( ZkCo ntra c t Co nte x t co nte x t , ZkS tate <S tate Void , RealClosed<S tate Void>> zkS tate , Wi nner s tate , Lis t <I nte ger> crea te dVariables) { zkS tate .ope n Variables(crea te dVariables); re turn s tate ; } @Override public Wi nner o n VariablesOpe ne d( ZkCo ntra c t Co nte x t co nte x t , ZkS tate <S tate Void , RealClosed<S tate Void>> zkS tate , Wi nner s tate , Lis t <I nte ger> ope ne dVariables) { RealClosed<S tate Void> wi nner Variable = zkS tate .ge t Variable(ope ne dVariables.ge t ( 0 )); RealClosed<S tate Void> priceVariable = zkS tate .ge t Variable(ope ne dVariables.ge t ( 1 )); by te [] ope n Wi nner Value = packBi t ArrayI nt oBy te Array(wi nner Variable.ge t Ope n Value()); ShareReader wi nner Reader = ShareReader.crea te (ope n Wi nner Value , wi nner Variable.ge t ShareBi t Le n g t hs().ge t ( 0 )); i nt wi nner Id = (i nt ) wi nner Reader.readLo n g( 32 ); Blockchai n Address wi nner Address = zkS tate .ge t Variable(wi nner Id).ge t Ow ner (); by te [] ope n PriceValue = packBi t ArrayI nt oBy te Array(priceVariable.ge t Ope n Value()); ShareReader priceReader = ShareReader.crea te (ope n PriceValue , priceVariable.ge t ShareBi t Le n g t hs().ge t ( 0 )); i nt wi nner Price = (i nt ) priceReader.readLo n g( 32 ); zkS tate .co ntra c t Do ne (); re turn ne w Wi nner (wi nner Address , wi nner Price); } // Pack a little endian bit array into a little endian byte array priva te by te [] packBi t ArrayI nt oBy te Array(by te [] bi ts ) { i nt by te Le n g t h = ZkClosed.ge t By te Le n g t h(bi ts .le n g t h); by te [] resul t = ne w by te [ by te Le n g t h ] ; i nt by te I n dex = 0 ; i nt bi t I n dex = 0 ; f or (by te bi t : bi ts ) { resul t [ by te I n dex ] = (by te ) (resul t [ by te I n dex ] | ((bi t & 1 ) << bi t I n dex)); bi t I n dex++; i f (bi t I n dex == By te .SIZE) { bi t I n dex = 0 ; by te I n dex++; } } re turn resul t ; } @Immu ta ble s tat ic f i nal class Wi nner impleme nts S tate Serializable { f i nal Blockchai n Address bidder; f i nal i nt price; public Wi nner () { bidder = null ; price = 0 ; } Wi nner (Blockchai n Address bidder , i nt price) { t his.bidder = bidder; t his.price = price; } boolea n hasWi nner () { re turn t his.bidder != null ; } } } This Java version of the zero knowledge contract has already been run and tested on the TestNet. But, for security reasons the deployable version on MainNet will have to be developed in a Rust like environment.","title":"Zero Knowledge Contracts"},{"location":"vickrey.html#example-of-a-zero-knowledge-smart-contract-on-pbc-vickrey-auction","text":"One of the smart contracts you will be able to implement on PBC is a Vickrey Auction, which is a sealed bid auction where the second highest bid wins. When some valuable item changes hands through an auction it is desirable to have the change in ownership registered on an immutable record. It is however highly undesirable that individual maximum bids are public, since the seller can use a third party to drive up the price to the highest possible price. One of the great advantages of PBC over other blockchains is that zero knowledge computations can be performed on the network parallel to the public transactions on the blockchain. The second price auction takes as input a list of prices for each account, ordered in arrival by a number. When the computation is initiated by the contract owner, the zero knowledge computation nodes reads the collected input and then create a bit vector consisting of prices and the ordering number. The list of bit vectors is now sorted in MPC. The winner is the first entry (the bidder with the highest price-bid), the price is determined by the size of the second highest bid. The contract follows these phases: - Input Each participant in the computation delivers their input to the computation. Either via the blockchain with the shares in encrypted form (making the nodes stateless) or directly to the nodes (making the data information-theoretic secure). In both cases the inputter provides commitments stored on the blockchain of each share so the nodes can ensure internal consistency among the nodes. - Computation The computation takes the input and runs the designated computation, the separation into phases makes the computation rerunnable without any data leaks. This means that the computation can be restarted in case of a server failure or any other unexpected problem. - Commitment of output Each node sends a commit to the chain of each of their shares. When the smart contract has received the shares from every node, the smart contract initiates the next phase. - Output. Every node now sends their shares to the smart contract, when a majority has released their shares, the contract has complete information and can open the result up. Below you can see the Java implementation of the zero knowledge smart contract for the Vickrey Auction: /** Contract for a second price auction. */ public f i nal class Seco n dPriceAuc t io n Co ntra c t ex ten ds RealCo ntra c t <Wi nner , S tate Void> { /** Create a new second price auction contract. */ public Seco n dPriceAuc t io n Co ntra c t () { super( ne w RealCompu tat io n <>() { @Override public < NumberT ex ten ds SharedNumber<NumberT> , Bi t T ex ten ds SharedBi t <Bi t T> , E ex ten ds Fi n i te FieldEleme nt <E>> void compu te ( ZkCompu tat io n S tate <Wi nner , S tate Void , RealClosed<S tate Void>> s tate , RealPro t ocol<NumberT , Bi t T , E> pro t ocol) { ShareS t orage<NumberT , Bi t T> s t orage = pro t ocol.s t orage(); Lis t <Secre t Bid<NumberT>> bids = s tate .ge t Variables().s trea m() .map(ZkClosed :: ge t Id) .sor te d() .map(id - > ne w Secre t Bid<>(id , s t orage.load(id).ge t ( 0 ).ge t Number())) .collec t (Collec t ors. t oLis t ()); Compu te Wi nner <Bi t T , NumberT , E> compu te Wi nner = ne w Compu te Wi nner <>(bids); Fi n i te FieldEleme nt Fac t ory<E> fa c t ory = pro t ocol.eleme nt Fac t ory(); compu te Wi nner .execu te (pro t ocol , Ma t h.max( fa c t ory.eleme nt Bi t Size() , 32 )); } } ); } @Override public Wi nner o n Crea te ( ZkCo ntra c t Co nte x t co nte x t , ZkS tate <S tate Void , RealClosed<S tate Void>> zkS tate , Sa fe Da ta I n pu t S trea m i n voca t io n ) { re turn ne w Wi nner (); } /** An open input from the contract owner is treated as the signal to execute the auction. */ @Override public Wi nner o n Ope n I n pu t ( ZkCo ntra c t Co nte x t co nte x t , ZkS tate <S tate Void , RealClosed<S tate Void>> zkS tate , Wi nner s tate , Sa fe Da ta I n pu t S trea m i n voca t io n ) { i f (!co nte x t .ge t Co ntra c t Ow ner ().equals(co nte x t .ge t From())) { t hrow ne w IllegalArgume nt Excep t io n ( \"Only owner can start computation\" ); } i f (zkS tate .ge t Variables().size() < 2 ) { t hrow ne w IllegalArgume nt Excep t io n ( \"Need at least two bids to compute\" ); } // computation has two outputs: the bid and the winner id. zkS tate .s tart Compu tat io n (Collec t io ns . n Copies( 2 , null )); re turn s tate ; } /** Treat secret inputs as bids. */ @Override public Wi nner o n Secre t I n pu t ( ZkCo ntra c t Co nte x t co nte x t , ZkS tate <S tate Void , RealClosed<S tate Void>> zkS tate , Wi nner s tate , Secre t I n pu t Builder<S tate Void> i n pu t , Sa fe Da ta I n pu t S trea m i n voca t io n ) { i f (zkS tate .ge t Calcula t io n S tatus () != Calcula t io n S tatus .WAITING) { t hrow ne w IllegalS tate Excep t io n ( \"Cannot submit inputs after computation has started\" ); } i n pu t .expec t Bi t Le n g t h( 32 ); zkS tate .ge t Variables(co nte x t .ge t From()).s trea m() .map(ZkClosed :: ge t Id) . f orEach(zkS tate :: dele te Variable); zkS tate .ge t Pe n di n gI n pu ts (co nte x t .ge t From()).s trea m() .map(ZkClosed :: ge t Id) . f orEach(zkS tate :: dele te Pe n di n gI n pu t ); re turn s tate ; } @Override public Wi nner o n Compu te Comple te ( ZkCo ntra c t Co nte x t co nte x t , ZkS tate <S tate Void , RealClosed<S tate Void>> zkS tate , Wi nner s tate , Lis t <I nte ger> crea te dVariables) { zkS tate .ope n Variables(crea te dVariables); re turn s tate ; } @Override public Wi nner o n VariablesOpe ne d( ZkCo ntra c t Co nte x t co nte x t , ZkS tate <S tate Void , RealClosed<S tate Void>> zkS tate , Wi nner s tate , Lis t <I nte ger> ope ne dVariables) { RealClosed<S tate Void> wi nner Variable = zkS tate .ge t Variable(ope ne dVariables.ge t ( 0 )); RealClosed<S tate Void> priceVariable = zkS tate .ge t Variable(ope ne dVariables.ge t ( 1 )); by te [] ope n Wi nner Value = packBi t ArrayI nt oBy te Array(wi nner Variable.ge t Ope n Value()); ShareReader wi nner Reader = ShareReader.crea te (ope n Wi nner Value , wi nner Variable.ge t ShareBi t Le n g t hs().ge t ( 0 )); i nt wi nner Id = (i nt ) wi nner Reader.readLo n g( 32 ); Blockchai n Address wi nner Address = zkS tate .ge t Variable(wi nner Id).ge t Ow ner (); by te [] ope n PriceValue = packBi t ArrayI nt oBy te Array(priceVariable.ge t Ope n Value()); ShareReader priceReader = ShareReader.crea te (ope n PriceValue , priceVariable.ge t ShareBi t Le n g t hs().ge t ( 0 )); i nt wi nner Price = (i nt ) priceReader.readLo n g( 32 ); zkS tate .co ntra c t Do ne (); re turn ne w Wi nner (wi nner Address , wi nner Price); } // Pack a little endian bit array into a little endian byte array priva te by te [] packBi t ArrayI nt oBy te Array(by te [] bi ts ) { i nt by te Le n g t h = ZkClosed.ge t By te Le n g t h(bi ts .le n g t h); by te [] resul t = ne w by te [ by te Le n g t h ] ; i nt by te I n dex = 0 ; i nt bi t I n dex = 0 ; f or (by te bi t : bi ts ) { resul t [ by te I n dex ] = (by te ) (resul t [ by te I n dex ] | ((bi t & 1 ) << bi t I n dex)); bi t I n dex++; i f (bi t I n dex == By te .SIZE) { bi t I n dex = 0 ; by te I n dex++; } } re turn resul t ; } @Immu ta ble s tat ic f i nal class Wi nner impleme nts S tate Serializable { f i nal Blockchai n Address bidder; f i nal i nt price; public Wi nner () { bidder = null ; price = 0 ; } Wi nner (Blockchai n Address bidder , i nt price) { t his.bidder = bidder; t his.price = price; } boolea n hasWi nner () { re turn t his.bidder != null ; } } } This Java version of the zero knowledge contract has already been run and tested on the TestNet. But, for security reasons the deployable version on MainNet will have to be developed in a Rust like environment.","title":"Example of a zero knowledge smart contract on PBC - Vickrey Auction"},{"location":"voting-contract-source.html","text":"Voting Smart Contract Rust Source Code See Voting Contract Explained #![allow(unused_variables)] extern crate create_type_derive ; #[macro_use] extern crate pbc_contract_codegen ; extern crate pbc_contract_common ; use std :: collections :: { BTreeMap , BTreeSet }; use std :: io :: { Read , Write }; use pbc_contract_common :: address :: Address ; use pbc_contract_common :: context :: ContractContext ; use pbc_traits :: * ; #[state] pub struct VotingContractState { proposal_id : u64 , mp_addresses : Vec < Address > , votes : BTreeMap < Address , u8 > , closed : u8 , } impl VotingContractState { fn register_vote ( & mut self , address : Address , vote : u8 ) { self . votes . insert ( address , vote ); } fn close_if_finished ( & mut self ) { if self . votes . len () == self . mp_addresses . len () { self . closed = 1 ; }; } } #[action] pub fn vote ( context : ContractContext , state : VotingContractState , vote : u8 ) -> VotingContractState { assert_eq! ( state . closed , 0 , \"The poll is closed\" ); assert! ( state . mp_addresses . contains ( & context . sender ), \"Only members of the parliament can vote\" ); assert! ( vote == 0 || vote == 1 , \"Only \\\" yes \\\" and \\\" no \\\" votes are allowed\" ); let mut new_state = state ; new_state . register_vote ( context . sender , vote ); new_state . close_if_finished (); new_state } #[init] pub fn initialize ( _ctx : ContractContext , proposal_id : u64 , mp_addresses : Vec < Address > , ) -> VotingContractState { assert_ne! ( mp_addresses . len (), 0 , \"Cannot start a poll without parliament members\" ); let mut address_set = BTreeSet :: new (); for mp_address in mp_addresses . iter () { address_set . insert ( * mp_address ); } assert_eq! ( mp_addresses . len (), address_set . len (), \"Duplicate MP address in input\" ); VotingContractState { proposal_id , mp_addresses , votes : BTreeMap :: new (), closed : 0 , } }","title":"Voting Smart Contract Rust Source Code"},{"location":"voting-contract-source.html#voting-smart-contract-rust-source-code","text":"See Voting Contract Explained #![allow(unused_variables)] extern crate create_type_derive ; #[macro_use] extern crate pbc_contract_codegen ; extern crate pbc_contract_common ; use std :: collections :: { BTreeMap , BTreeSet }; use std :: io :: { Read , Write }; use pbc_contract_common :: address :: Address ; use pbc_contract_common :: context :: ContractContext ; use pbc_traits :: * ; #[state] pub struct VotingContractState { proposal_id : u64 , mp_addresses : Vec < Address > , votes : BTreeMap < Address , u8 > , closed : u8 , } impl VotingContractState { fn register_vote ( & mut self , address : Address , vote : u8 ) { self . votes . insert ( address , vote ); } fn close_if_finished ( & mut self ) { if self . votes . len () == self . mp_addresses . len () { self . closed = 1 ; }; } } #[action] pub fn vote ( context : ContractContext , state : VotingContractState , vote : u8 ) -> VotingContractState { assert_eq! ( state . closed , 0 , \"The poll is closed\" ); assert! ( state . mp_addresses . contains ( & context . sender ), \"Only members of the parliament can vote\" ); assert! ( vote == 0 || vote == 1 , \"Only \\\" yes \\\" and \\\" no \\\" votes are allowed\" ); let mut new_state = state ; new_state . register_vote ( context . sender , vote ); new_state . close_if_finished (); new_state } #[init] pub fn initialize ( _ctx : ContractContext , proposal_id : u64 , mp_addresses : Vec < Address > , ) -> VotingContractState { assert_ne! ( mp_addresses . len (), 0 , \"Cannot start a poll without parliament members\" ); let mut address_set = BTreeSet :: new (); for mp_address in mp_addresses . iter () { address_set . insert ( * mp_address ); } assert_eq! ( mp_addresses . len (), address_set . len (), \"Duplicate MP address in input\" ); VotingContractState { proposal_id , mp_addresses , votes : BTreeMap :: new (), closed : 0 , } }","title":"Voting Smart Contract Rust Source Code"},{"location":"voting-contract.html","text":"Create a smart contract for a specific scenario e.g. transparency in parliament Case - Voting record of MPs as a means to strengthen democracy and transparency The newly founded republic of Faraway is plagued by corruption. To ensure transparency and public mandate behind the parliamentary process the voting record of the elected MPs is added to the blockchain via smart contracts. Using smart contracts enables the public to see how MPs exercise their mandate. Laws that are passed through the smart contract are added to the immutable record, giving all citizens access to the official legal code. The setup of our scenario The parliament has 197 MPs. Each MP has a key set. The public key enables the public to follow the MP\u2019s voting record on the blockchain. The private key is known only by the individual MP and is used to sign their vote. Each time the parliament votes on an issue they do it through a smart contract vote. Laws that passed are therefore also added to the immutable record. NB. No ZK computation is necessary since the both individual votes and voting results are supposed to be public. How to program the voting smart contract in Rust In the following the different parts of a smart contract implementing the voting scenario is explained. You can see the complete Rust source code of the contract here . 1) Importing libraries First we need to include a few libraries to get access to the functions and types needed for programming a smart contract. It is not necessary to understand exactly what the includes here do in order to create your own smart contracts. #![allow(unused_variables)] extern crate create_type_derive ; #[macro_use] extern crate pbc_contract_codegen ; extern crate pbc_contract_common ; use std :: collections :: { BTreeMap , BTreeSet }; use std :: io :: { Read , Write }; use pbc_contract_common :: address :: Address ; use pbc_contract_common :: context :: ContractContext ; use pbc_traits :: * ; 2) Defining the contract state When programming a smart contract we have to define the state of the contract. We do this in Rust by creating a struct and marking it with #[state] . For our voting contract the contract state has the following parts: proposal_id A proposal id, so you can identify what proposal the vote is concerned with. mp_addresses The list of people that are allowed to vote on the proposal. Only people with voting rights in the parliament should be allowed to vote, so the contract also needs a list of MP addresses. votes The actual votes cast are contained in a map pairing each person with their vote. closed Finally, when the voting ends people must no longer be able to change their vote. Therefore, the contract the state also includes information about whether the voting is open or closed. We can also define methods associated with the state struct that read or write to the state. In Rust these methods are defined inside an impl block associated with the state struct. For our voting contract we have defined two state methods: register_vote When an MP cast her vote, it is recorded in the votes map. close_if_finished_vote The voting process automatically closes after everybody has voted. We could have chosen to make closing the vote depend on when the majority was reached, or to make an action where the chairman of the parliament closes the vote after some deadline. We could also add a result to the contract state if we want to make the contract more informative. The idea here was a simple voting record, so what we have now will suffice. #[state] pub struct VotingContractState { proposal_id : u64 , mp_addresses : Vec < Address > , votes : BTreeMap < Address , u8 > , closed : u8 , } impl VotingContractState { fn register_vote ( & mut self , address : Address , vote : u8 ) { self . votes . insert ( address , vote ); } fn close_if_finished ( & mut self ) { if self . votes . len () == self . mp_addresses . len () { self . closed = 1 ; }; } } 3) Defining the initialization of the contract When deploying a smart contract on the blockchain the state of the contract has to be initialized properly. When programming the smart contract in Rust we can define how the initialization takes place by creating a function and marking it with #[init] To initialize our voting contract the user deploying the contract has to supply the proposal id and the list of people eligible to vote. Our initialization code checks that the supplied input is valid (i.e. the list of people allowed to vote has at least one person and has no duplicates) and creates the initial state object for the contract from the input. After successful initialization, the contract state becomes live on the blockchain. #[init] pub fn initialize ( _ctx : ContractContext , proposal_id : u64 , mp_addresses : Vec < Address > , ) -> VotingContractState { assert_ne! ( mp_addresses . len (), 0 , \"Cannot start a poll without parliament members\" ); let mut address_set = BTreeSet :: new (); for mp_address in mp_addresses . iter () { address_set . insert ( * mp_address ); } assert_eq! ( mp_addresses . len (), address_set . len (), \"Duplicate MP address in input\" ); VotingContractState { proposal_id , mp_addresses , votes : BTreeMap :: new (), closed : 0 , } } 4) Defining the actions of the contract When a smart contract is live on the blockchain, people can interact with the contract by creating a transaction that initiate execution of an action of the smart contract. The only way of changing the state of a smart contract is through the defined actions. The smart contract actions hereby define the exact conditions and rules for changing the contract state. A smart contract can have multiple defined actions. In Rust, you define a smart contract action by coding a function and marking it with #[action] . The function receives the existing state and the inputs from the user initiating the action, and it can then produce and return a new updated state reflecting the changes. For our voting contract the only action users can perform is to cast their vote. The code starts by checking that the voting is still open, that the sender is among the people allowed to vote and that the delivered vote is one of the allowed voting options. If the checks succeed the code creates a new state where the vote of the sender is registered in the vote map. Also, if this vote was the last one and everyone has now voted, then voting is closed. #[action] pub fn vote ( context : ContractContext , state : VotingContractState , vote : u8 ) -> VotingContractState { assert_eq! ( state . closed , 0 , \"The poll is closed\" ); assert! ( state . mp_addresses . contains ( & context . sender ), \"Only members of the parliament can vote\" ); assert! ( vote == 0 || vote == 1 , \"Only \\\" yes \\\" and \\\" no \\\" votes are allowed\" ); let mut new_state = state ; new_state . register_vote ( context . sender , vote ); new_state . close_if_finished (); new_state } Building and testing the voting contract The process is the same for the voting contract as it is for the token contract. The instructions can be found here .","title":"Create a smart contract for a specific scenario"},{"location":"voting-contract.html#create-a-smart-contract-for-a-specific-scenario-eg-transparency-in-parliament","text":"","title":"Create a smart contract for a specific scenario e.g. transparency in parliament"},{"location":"voting-contract.html#case-voting-record-of-mps-as-a-means-to-strengthen-democracy-and-transparency","text":"The newly founded republic of Faraway is plagued by corruption. To ensure transparency and public mandate behind the parliamentary process the voting record of the elected MPs is added to the blockchain via smart contracts. Using smart contracts enables the public to see how MPs exercise their mandate. Laws that are passed through the smart contract are added to the immutable record, giving all citizens access to the official legal code. The setup of our scenario The parliament has 197 MPs. Each MP has a key set. The public key enables the public to follow the MP\u2019s voting record on the blockchain. The private key is known only by the individual MP and is used to sign their vote. Each time the parliament votes on an issue they do it through a smart contract vote. Laws that passed are therefore also added to the immutable record. NB. No ZK computation is necessary since the both individual votes and voting results are supposed to be public.","title":"Case - Voting record of MPs as a means to strengthen democracy and transparency"},{"location":"voting-contract.html#how-to-program-the-voting-smart-contract-in-rust","text":"In the following the different parts of a smart contract implementing the voting scenario is explained. You can see the complete Rust source code of the contract here .","title":"How to program the voting smart contract in Rust"},{"location":"voting-contract.html#1-importing-libraries","text":"First we need to include a few libraries to get access to the functions and types needed for programming a smart contract. It is not necessary to understand exactly what the includes here do in order to create your own smart contracts. #![allow(unused_variables)] extern crate create_type_derive ; #[macro_use] extern crate pbc_contract_codegen ; extern crate pbc_contract_common ; use std :: collections :: { BTreeMap , BTreeSet }; use std :: io :: { Read , Write }; use pbc_contract_common :: address :: Address ; use pbc_contract_common :: context :: ContractContext ; use pbc_traits :: * ;","title":"1) Importing libraries"},{"location":"voting-contract.html#2-defining-the-contract-state","text":"When programming a smart contract we have to define the state of the contract. We do this in Rust by creating a struct and marking it with #[state] . For our voting contract the contract state has the following parts: proposal_id A proposal id, so you can identify what proposal the vote is concerned with. mp_addresses The list of people that are allowed to vote on the proposal. Only people with voting rights in the parliament should be allowed to vote, so the contract also needs a list of MP addresses. votes The actual votes cast are contained in a map pairing each person with their vote. closed Finally, when the voting ends people must no longer be able to change their vote. Therefore, the contract the state also includes information about whether the voting is open or closed. We can also define methods associated with the state struct that read or write to the state. In Rust these methods are defined inside an impl block associated with the state struct. For our voting contract we have defined two state methods: register_vote When an MP cast her vote, it is recorded in the votes map. close_if_finished_vote The voting process automatically closes after everybody has voted. We could have chosen to make closing the vote depend on when the majority was reached, or to make an action where the chairman of the parliament closes the vote after some deadline. We could also add a result to the contract state if we want to make the contract more informative. The idea here was a simple voting record, so what we have now will suffice. #[state] pub struct VotingContractState { proposal_id : u64 , mp_addresses : Vec < Address > , votes : BTreeMap < Address , u8 > , closed : u8 , } impl VotingContractState { fn register_vote ( & mut self , address : Address , vote : u8 ) { self . votes . insert ( address , vote ); } fn close_if_finished ( & mut self ) { if self . votes . len () == self . mp_addresses . len () { self . closed = 1 ; }; } }","title":"2) Defining the contract state"},{"location":"voting-contract.html#3-defining-the-initialization-of-the-contract","text":"When deploying a smart contract on the blockchain the state of the contract has to be initialized properly. When programming the smart contract in Rust we can define how the initialization takes place by creating a function and marking it with #[init] To initialize our voting contract the user deploying the contract has to supply the proposal id and the list of people eligible to vote. Our initialization code checks that the supplied input is valid (i.e. the list of people allowed to vote has at least one person and has no duplicates) and creates the initial state object for the contract from the input. After successful initialization, the contract state becomes live on the blockchain. #[init] pub fn initialize ( _ctx : ContractContext , proposal_id : u64 , mp_addresses : Vec < Address > , ) -> VotingContractState { assert_ne! ( mp_addresses . len (), 0 , \"Cannot start a poll without parliament members\" ); let mut address_set = BTreeSet :: new (); for mp_address in mp_addresses . iter () { address_set . insert ( * mp_address ); } assert_eq! ( mp_addresses . len (), address_set . len (), \"Duplicate MP address in input\" ); VotingContractState { proposal_id , mp_addresses , votes : BTreeMap :: new (), closed : 0 , } }","title":"3) Defining the initialization of the contract"},{"location":"voting-contract.html#4-defining-the-actions-of-the-contract","text":"When a smart contract is live on the blockchain, people can interact with the contract by creating a transaction that initiate execution of an action of the smart contract. The only way of changing the state of a smart contract is through the defined actions. The smart contract actions hereby define the exact conditions and rules for changing the contract state. A smart contract can have multiple defined actions. In Rust, you define a smart contract action by coding a function and marking it with #[action] . The function receives the existing state and the inputs from the user initiating the action, and it can then produce and return a new updated state reflecting the changes. For our voting contract the only action users can perform is to cast their vote. The code starts by checking that the voting is still open, that the sender is among the people allowed to vote and that the delivered vote is one of the allowed voting options. If the checks succeed the code creates a new state where the vote of the sender is registered in the vote map. Also, if this vote was the last one and everyone has now voted, then voting is closed. #[action] pub fn vote ( context : ContractContext , state : VotingContractState , vote : u8 ) -> VotingContractState { assert_eq! ( state . closed , 0 , \"The poll is closed\" ); assert! ( state . mp_addresses . contains ( & context . sender ), \"Only members of the parliament can vote\" ); assert! ( vote == 0 || vote == 1 , \"Only \\\" yes \\\" and \\\" no \\\" votes are allowed\" ); let mut new_state = state ; new_state . register_vote ( context . sender , vote ); new_state . close_if_finished (); new_state }","title":"4) Defining the actions of the contract"},{"location":"voting-contract.html#building-and-testing-the-voting-contract","text":"The process is the same for the voting contract as it is for the token contract. The instructions can be found here .","title":"Building and testing the voting contract"},{"location":"whatisano.html","text":"The Node Operator What is a Node Nodes are the computers in the blockchain network. They perform services for the users of the blockchain, foremost they facilitate the transactions that happens on the blockchain. From the transaction costs paid by users, the node operator can make revenue. PBC has four types of nodes: Reader node: A node that only reads the information on the chain and does not perform paid services. Baker Node: A node that produces and validates blocks. Revenue is generated from user payment on transactions in the blocks produced and validated by the node. ZK Node: A node that performs zero knowledge computations in addition to baker node services. Oracle Node: A node that performs oracle services in addition to ZK and baker services. Requirements of a Node Operator The Stake If you want to be a node operator you are required to have a stake in the network. A stake is basically a deposit strengthening the security and user confidence of the network. The stake means that the node operator has something to lose, if they try to cheat or damage the network. Staking means that the node operator buy the required stake of MPC Tokens. Services have a hierarchy of cost and security as well as payment. Therefore, higher paid services require a higher stake. To acquire MPC Tokens go through this contact page . The current stakes are: Reader Node is free, since it does not perform paid services. Baker Node 10,000 $ in MPC Tokens. ZK Node 25,000 $ in MPC Tokens. Oracle Node 100,000 $ in MPC Tokens. The Machine In addition to the stake you need a computer to run the node. Most node operators rent a server, but some keep the machine running the node in their own home. Machine Specs are in the section about running the node. The Keys When a block of transactions is validated, the node signs off on it with a unique digital signature. The signature is created with the node owner's private key. The signature is verifiable from the public version of the signing key. The different keys play different roles. One keypair references your account with the stake, another refers to your identity on the network and in the PBC internal register. A full description of the keys you will need kan be found in this section . The Skills Setting up the node require some technical skills. You need to be able to configure and run your node, or alternatively pay someone you trust to help you with the setup and upkeep of the node. The following sections take you through the signup process. If you do not yet have MPC tokens or an appropriate server for running a node you can still complete the firs part of the guide showing you how to run a reader node. A reader node is free. When you have completed the introduction , first and second step, then you should know if you have the skills required to run a node performing services on Partisia Blockchain. If you want to buy MPC Tokens, you can follow this link for information about sale.","title":"What is a node operator"},{"location":"whatisano.html#the-node-operator","text":"","title":"The Node Operator"},{"location":"whatisano.html#what-is-a-node","text":"Nodes are the computers in the blockchain network. They perform services for the users of the blockchain, foremost they facilitate the transactions that happens on the blockchain. From the transaction costs paid by users, the node operator can make revenue. PBC has four types of nodes: Reader node: A node that only reads the information on the chain and does not perform paid services. Baker Node: A node that produces and validates blocks. Revenue is generated from user payment on transactions in the blocks produced and validated by the node. ZK Node: A node that performs zero knowledge computations in addition to baker node services. Oracle Node: A node that performs oracle services in addition to ZK and baker services.","title":"What is a Node"},{"location":"whatisano.html#requirements-of-a-node-operator","text":"The Stake If you want to be a node operator you are required to have a stake in the network. A stake is basically a deposit strengthening the security and user confidence of the network. The stake means that the node operator has something to lose, if they try to cheat or damage the network. Staking means that the node operator buy the required stake of MPC Tokens. Services have a hierarchy of cost and security as well as payment. Therefore, higher paid services require a higher stake. To acquire MPC Tokens go through this contact page . The current stakes are: Reader Node is free, since it does not perform paid services. Baker Node 10,000 $ in MPC Tokens. ZK Node 25,000 $ in MPC Tokens. Oracle Node 100,000 $ in MPC Tokens. The Machine In addition to the stake you need a computer to run the node. Most node operators rent a server, but some keep the machine running the node in their own home. Machine Specs are in the section about running the node. The Keys When a block of transactions is validated, the node signs off on it with a unique digital signature. The signature is created with the node owner's private key. The signature is verifiable from the public version of the signing key. The different keys play different roles. One keypair references your account with the stake, another refers to your identity on the network and in the PBC internal register. A full description of the keys you will need kan be found in this section . The Skills Setting up the node require some technical skills. You need to be able to configure and run your node, or alternatively pay someone you trust to help you with the setup and upkeep of the node. The following sections take you through the signup process. If you do not yet have MPC tokens or an appropriate server for running a node you can still complete the firs part of the guide showing you how to run a reader node. A reader node is free. When you have completed the introduction , first and second step, then you should know if you have the skills required to run a node performing services on Partisia Blockchain. If you want to buy MPC Tokens, you can follow this link for information about sale.","title":"Requirements of a Node Operator"}]}